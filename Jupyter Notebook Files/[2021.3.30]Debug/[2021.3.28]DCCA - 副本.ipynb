{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import numpy\n",
    "import random\n",
    "torch.manual_seed(2)\n",
    "np.random.seed(2)\n",
    "random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 生成两个数据集，各有200个数据，X^1是维度为2，X^2维度为10，其中每个数据中前100个标签为0，后100个标签为1。\n",
    "X1, y1 = make_moons(200, noise=0.2, shuffle=False, random_state=7)\n",
    "X2, y2 = make_blobs(n_samples=200, n_features=10, shuffle=False, centers=2, center_box=(-10, 10), random_state=7)\n",
    "\n",
    "# 对两个数据集进行降维，用KMeans，聚为两类\n",
    "km1 = KMeans(n_clusters=2, random_state=0)\n",
    "km2 = KMeans(n_clusters=2, random_state=0)\n",
    "a1 = km1.fit(X1)\n",
    "a2 = km2.fit(X2)\n",
    "\n",
    "# 这是每个聚类的中心\n",
    "X1_center_1 = km1.cluster_centers_[0, :]\n",
    "X1_center_2 = km1.cluster_centers_[1, :]\n",
    "X2_center_1 = km2.cluster_centers_[0, :]\n",
    "X2_center_2 = km2.cluster_centers_[1, :]\n",
    "\n",
    "# 用聚类后每个点到聚类中心的欧式距离来算出属于某聚类的概率，从而生成A矩阵\n",
    "def create_A_matrix(X, center1, center2):\n",
    "    A = np.zeros((200, 2))\n",
    "\n",
    "    for i in range(200):\n",
    "        dis1 = np.sqrt(np.sum(np.square(X[i, :] - center1)))\n",
    "        dis2 = np.sqrt(np.sum(np.square(X[i, :] - center2)))\n",
    "        A[i, 0] = dis1 / (dis1 + dis2)\n",
    "        A[i, 1] = dis2 / (dis1 + dis2)\n",
    "\n",
    "    return A\n",
    "\n",
    "# 生成A矩阵\n",
    "A1 = np.mat(create_A_matrix(X1, X1_center_1, X1_center_2))\n",
    "A2 = np.mat(create_A_matrix(X2, X2_center_1, X2_center_2))\n",
    "\n",
    "#将矩阵变为tensor\n",
    "X1 = torch.from_numpy(X1).double()\n",
    "X2 = torch.from_numpy(X2).double()\n",
    "A1 = torch.from_numpy(A1).double()\n",
    "A2 = torch.from_numpy(A2).double()\n",
    "\n",
    "y = y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#搭建感知机网络\n",
    "class MlpNet(nn.Module):\n",
    "    def __init__(self, layer_sizes, input_size):\n",
    "        super(MlpNet, self).__init__()\n",
    "        layers = []\n",
    "        layer_sizes = [input_size] + layer_sizes\n",
    "        for l_id in range(len(layer_sizes) - 1):\n",
    "            if l_id == len(layer_sizes) - 2:\n",
    "                layers.append(nn.Sequential(\n",
    "                    nn.BatchNorm1d(num_features=layer_sizes[l_id], affine=False, track_running_stats=True),\n",
    "                    nn.Linear(layer_sizes[l_id], layer_sizes[l_id + 1]),\n",
    "                ))\n",
    "            else:\n",
    "                layers.append(nn.Sequential(\n",
    "                    nn.Linear(layer_sizes[l_id], layer_sizes[l_id + 1]),\n",
    "                    nn.Sigmoid(),\n",
    "                    nn.BatchNorm1d(num_features=layer_sizes[l_id + 1], affine=False, track_running_stats=True),\n",
    "                ))\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#搭建深度模型\n",
    "class DeepCCA(nn.Module):\n",
    "    def __init__(self, layer_sizes1, layer_sizes2, input_size1, input_size2, outdim_size, use_all_singular_values, device=torch.device('cpu')):\n",
    "        super(DeepCCA, self).__init__()\n",
    "        self.model1 = MlpNet(layer_sizes1, input_size1).double()\n",
    "        self.model2 = MlpNet(layer_sizes2, input_size2).double()\n",
    "\n",
    "        self.loss = cca_loss(outdim_size, use_all_singular_values, device).loss\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # feature * batch_size\n",
    "        output1 = self.model1(x1)\n",
    "        output2 = self.model2(x2)\n",
    "\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Loss(Corr)\n",
    "class cca_loss():\n",
    "    def __init__(self, outdim_size, use_all_singular_values, device):\n",
    "        self.outdim_size = outdim_size\n",
    "        self.use_all_singular_values = use_all_singular_values\n",
    "        self.device = device\n",
    "        print(device)\n",
    "\n",
    "    def loss(self, H1, H2):\n",
    "\n",
    "        r1 = 1e-3\n",
    "        r2 = 1e-3\n",
    "        eps = 1e-9\n",
    "\n",
    "        H1, H2 = H1.t(), H2.t()\n",
    "        o1 = o2 = H1.size(0)\n",
    "\n",
    "        m = H1.size(1)\n",
    "\n",
    "        H1bar = H1 - H1.mean(dim=1).unsqueeze(dim=1)\n",
    "        H2bar = H2 - H2.mean(dim=1).unsqueeze(dim=1)\n",
    "\n",
    "\n",
    "        SigmaHat12 = (1.0 / (m - 1)) * torch.mm(H1bar, H2bar.t())\n",
    "        SigmaHat11 = (1.0 / (m - 1)) * torch.mm(H1bar, H1bar.t()) + r1 * torch.eye(o1, device=self.device)\n",
    "        SigmaHat22 = (1.0 / (m - 1)) * torch.mm(H2bar, H2bar.t()) + r2 * torch.eye(o2, device=self.device)\n",
    "     \n",
    "        [D1, V1] = torch.symeig(SigmaHat11, eigenvectors=True)\n",
    "        [D2, V2] = torch.symeig(SigmaHat22, eigenvectors=True)\n",
    "     \n",
    "        # Added to increase stability\n",
    "        posInd1 = torch.gt(D1, eps).nonzero()[:, 0]\n",
    "        D1 = D1[posInd1]\n",
    "        V1 = V1[:, posInd1]\n",
    "        posInd2 = torch.gt(D2, eps).nonzero()[:, 0]\n",
    "        D2 = D2[posInd2]\n",
    "        V2 = V2[:, posInd2]\n",
    "\n",
    "        SigmaHat11RootInv = torch.mm(torch.mm(V1, torch.diag(D1 ** -0.5)), V1.t())\n",
    "        SigmaHat22RootInv = torch.mm(torch.mm(V2, torch.diag(D2 ** -0.5)), V2.t())\n",
    "\n",
    "        Tval = torch.mm(torch.mm(SigmaHat11RootInv,\n",
    "                                         SigmaHat12), SigmaHat22RootInv)\n",
    "\n",
    "\n",
    "        if self.use_all_singular_values:\n",
    "            # all singular values are used to calculate the correlation\n",
    "            tmp = torch.mm(Tval.t(), Tval)\n",
    "            corr = torch.trace(torch.sqrt(tmp))\n",
    "            # assert torch.isnan(corr).item() == 0\n",
    "        else:\n",
    "            # just the top self.outdim_size singular values are used\n",
    "            trace_TT = torch.mm(Tval.t(), Tval)\n",
    "            trace_TT = torch.add(trace_TT, (torch.eye(trace_TT.shape[0])*r1).to(self.device)) # regularization for more stability\n",
    "            U, V = torch.symeig(trace_TT, eigenvectors=True)\n",
    "            U = torch.where(U>eps, U, (torch.ones(U.shape).double()*eps).to(self.device))\n",
    "            U = U.topk(self.outdim_size)[0]\n",
    "            corr = torch.sum(torch.sqrt(U))\n",
    "\n",
    "\n",
    "\n",
    "        return -corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Solver():\n",
    "    def __init__(self, model, outdim_size, epoch_num, learning_rate, reg_par,\n",
    "                 device=torch.device('cpu')):\n",
    "        self.model = nn.DataParallel(model)\n",
    "        self.model.to(device)\n",
    "        self.epoch_num = epoch_num\n",
    "        self.loss = model.loss\n",
    "        self.optimizer = torch.optim.RMSprop(\n",
    "            self.model.parameters(), lr=learning_rate, weight_decay=reg_par)\n",
    "        self.device = device\n",
    "        self.outdim_size = outdim_size\n",
    "\n",
    "\n",
    "    def fit(self, x1, x2, tst1 = None, tst2 = None):\n",
    "        \n",
    "        x1.to(self.device)\n",
    "        x2.to(self.device)\n",
    "        \n",
    "        if tst1 is not None and tst2 is not None:\n",
    "            tst1.to(self.device)\n",
    "            tst2.to(self.device)\n",
    "\n",
    "        train_losses = []\n",
    "        for epoch in range(self.epoch_num):\n",
    "            self.model.train()\n",
    "            self.optimizer.zero_grad()\n",
    "            batch_x1 = x1\n",
    "            batch_x2 = x2\n",
    "            o1, o2 = self.model(batch_x1, batch_x2)\n",
    "            loss = self.loss(o1, o2)\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            train_loss = np.mean(train_losses)\n",
    "            print('Epoch:', epoch + 1, '    Loss:', train_loss)\n",
    "            if epoch % 100 == 0:\n",
    "                o1_ = o1.cpu().detach().numpy()\n",
    "                o2_ = o2.cpu().detach().numpy()\n",
    "                #visualization_LR(o1_, y, 'View 1')\n",
    "                #visualization_LR(o2_, y, 'View 2')\n",
    "\n",
    "\n",
    "    def test(self, x1, x2, use_linear_cca=False):\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            self.model.eval()\n",
    "            losses = []\n",
    "            outputs1 = []\n",
    "            outputs2 = []\n",
    "            o1, o2 = self.model(x1, x2)\n",
    "            outputs1.append(o1)\n",
    "            outputs2.append(o2)\n",
    "            loss = self.loss(o1,o2)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        outputs = [torch.cat(outputs1, dim=0).cpu().numpy(),\n",
    "                   torch.cat(outputs2, dim=0).cpu().numpy()]\n",
    "        return losses, outputs\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "#精确度分析\n",
    "def acc(y_pred, y_true):\n",
    "    return accuracy_score(y_true, y_pred, normalize=True)\n",
    "\n",
    "# 线性分类器\n",
    "def LR(X_train, y_train, y_test=None):\n",
    "    clf = LogisticRegression(penalty='l2')\n",
    "    clf.fit(X_train, y_train)  \n",
    "    return clf.coef_, clf.intercept_, clf.predict(X_train)\n",
    "\n",
    "#预留20%为测试集，在测试集上的精度\n",
    "def LR_2(Train_x, Train_y):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(Train_x, Train_y, test_size=0.2, random_state=2)\n",
    "    clf1 = LogisticRegression(penalty='l2')\n",
    "    clf1.fit(train_x, train_y)\n",
    "    pred_y = clf1.predict(test_x)\n",
    "    acc = accuracy_score(test_y, pred_y, normalize=True)\n",
    "    fpr, tpr, thresholds = roc_curve(test_y, pred_y, pos_label=1)\n",
    "    auc_ = auc(fpr, tpr)\n",
    "    return acc, auc_\n",
    "\n",
    "#非线性分类器\n",
    "def svm(X_train, y_train):\n",
    "    nlc = SVC(kernel='rbf')\n",
    "    nlc.fit(X_train, y_train)\n",
    "    return nlc\n",
    "\n",
    "def svm_2(Train_x, Train_y):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(Train_x, Train_y, test_size=0.2, random_state=2)\n",
    "    nlc1 = SVC(kernel='rbf')\n",
    "    nlc1.fit(train_x, train_y)\n",
    "    pred_y = nlc1.predict(test_x)\n",
    "    acc = accuracy_score(test_y, pred_y, normalize=True)\n",
    "    fpr, tpr, thresholds = roc_curve(test_y, pred_y, pos_label=1)\n",
    "    auc_ = auc(fpr, tpr)\n",
    "    return acc, auc_\n",
    "\n",
    "\n",
    "# 可视化\n",
    "def visualization_LR(X, y, title):\n",
    "    weight = LR(X, y)[0]\n",
    "    bias = LR(X, y)[1]\n",
    "    dataArr = np.array(X)\n",
    "    xcord1 = [];\n",
    "    ycord1 = []\n",
    "    xcord2 = [];\n",
    "    ycord2 = []\n",
    "    for i in range(y.shape[0]):\n",
    "        if int(y[i]) == 1:\n",
    "            xcord1.append(dataArr[i, 0]);\n",
    "            ycord1.append(dataArr[i, 1])\n",
    "        else:\n",
    "            xcord2.append(dataArr[i, 0]);\n",
    "            ycord2.append(dataArr[i, 1])\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(xcord1, ycord1, s=30, c='red', marker='s')\n",
    "    ax.scatter(xcord2, ycord2, s=30, c='green')\n",
    "    x_1 = np.arange(-1, 2, 0.01)\n",
    "    a = -weight[0, 0] / weight[0, 1]\n",
    "    b = -bias / weight[0, 1]\n",
    "    #y_1 = a * x_1 + b\n",
    "    # -weights[0]\n",
    "    #ax.plot(x_1, y_1)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "def visualization_SVM(X, y, title):\n",
    "    xx, yy = np.meshgrid(np.linspace(-3, 3, 500), np.linspace(-3, 3, 500))\n",
    "    xy = np.vstack([xx.ravel(), yy.ravel()]).T\n",
    "    Z = svm(X, y).decision_function(xy).reshape(xx.shape)\n",
    "    #plt.imshow(Z, interpolation='nearest', extent=(xx.min(), xx.max(), yy.min(), yy.max(),), aspect='auto',\n",
    "               #origin='lower', cmap=plt.cm.PuOr_r)\n",
    "    plt.contour(xx, yy, Z, levels=[0], linewidths=2, linestyle='-')\n",
    "    plt.scatter(X[:, 0].tolist(), X[:, 1].tolist(), s=30, c=y, cmap=plt.cm.Paired, edgecolors='k')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch: 1     Loss: -0.7201978224770378\n",
      "Epoch: 2     Loss: -0.8427655168877166\n",
      "Epoch: 3     Loss: -0.9011358026001632\n",
      "Epoch: 4     Loss: -0.9390256105383943\n",
      "Epoch: 5     Loss: -0.9666786741527458\n",
      "Epoch: 6     Loss: -0.9876749729156374\n",
      "Epoch: 7     Loss: -1.0056883693984793\n",
      "Epoch: 8     Loss: -1.0071254891126609\n",
      "Epoch: 9     Loss: -1.015432542269809\n",
      "Epoch: 10     Loss: -1.0240353601095709\n",
      "Epoch: 11     Loss: -1.0318780137445305\n",
      "Epoch: 12     Loss: -1.039079973306519\n",
      "Epoch: 13     Loss: -1.0455972889964686\n",
      "Epoch: 14     Loss: -1.0520062084173456\n",
      "Epoch: 15     Loss: -1.0582309154839573\n",
      "Epoch: 16     Loss: -1.0632401405562948\n",
      "Epoch: 17     Loss: -1.06864122324968\n",
      "Epoch: 18     Loss: -1.0726471156388435\n",
      "Epoch: 19     Loss: -1.0789694300214314\n",
      "Epoch: 20     Loss: -1.0852248546600392\n",
      "Epoch: 21     Loss: -1.0902637424003156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:766.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22     Loss: -1.0952809247346027\n",
      "Epoch: 23     Loss: -1.099725519734995\n",
      "Epoch: 24     Loss: -1.1053892660664015\n",
      "Epoch: 25     Loss: -1.110259823513311\n",
      "Epoch: 26     Loss: -1.1150699055644275\n",
      "Epoch: 27     Loss: -1.1174215119226905\n",
      "Epoch: 28     Loss: -1.1214098652633182\n",
      "Epoch: 29     Loss: -1.1258932862636228\n",
      "Epoch: 30     Loss: -1.1307501569753704\n",
      "Epoch: 31     Loss: -1.1343661738993598\n",
      "Epoch: 32     Loss: -1.138497516003491\n",
      "Epoch: 33     Loss: -1.141028565525673\n",
      "Epoch: 34     Loss: -1.1431765108983005\n",
      "Epoch: 35     Loss: -1.144762273476787\n",
      "Epoch: 36     Loss: -1.1472391641053197\n",
      "Epoch: 37     Loss: -1.1496390044862044\n",
      "Epoch: 38     Loss: -1.1517548516357146\n",
      "Epoch: 39     Loss: -1.1530396830588159\n",
      "Epoch: 40     Loss: -1.155615603741558\n",
      "Epoch: 41     Loss: -1.158420197467783\n",
      "Epoch: 42     Loss: -1.1612107349739886\n",
      "Epoch: 43     Loss: -1.1639094047974081\n",
      "Epoch: 44     Loss: -1.165978264136042\n",
      "Epoch: 45     Loss: -1.1691545362875084\n",
      "Epoch: 46     Loss: -1.1724085204424342\n",
      "Epoch: 47     Loss: -1.17545168526821\n",
      "Epoch: 48     Loss: -1.1781173683276824\n",
      "Epoch: 49     Loss: -1.180142798805443\n",
      "Epoch: 50     Loss: -1.1832829196317445\n",
      "Epoch: 51     Loss: -1.1864258324274572\n",
      "Epoch: 52     Loss: -1.1891856543855115\n",
      "Epoch: 53     Loss: -1.191865079606297\n",
      "Epoch: 54     Loss: -1.193839673579247\n",
      "Epoch: 55     Loss: -1.1960896661377056\n",
      "Epoch: 56     Loss: -1.1989584370507118\n",
      "Epoch: 57     Loss: -1.2016002410241433\n",
      "Epoch: 58     Loss: -1.2043025315795528\n",
      "Epoch: 59     Loss: -1.2070217304285784\n",
      "Epoch: 60     Loss: -1.2092405842561373\n",
      "Epoch: 61     Loss: -1.2110710156505464\n",
      "Epoch: 62     Loss: -1.21314709540688\n",
      "Epoch: 63     Loss: -1.2157363675268367\n",
      "Epoch: 64     Loss: -1.2178225352713925\n",
      "Epoch: 65     Loss: -1.2206379005816552\n",
      "Epoch: 66     Loss: -1.2232713194471745\n",
      "Epoch: 67     Loss: -1.22569770793356\n",
      "Epoch: 68     Loss: -1.2250693587968156\n",
      "Epoch: 69     Loss: -1.2271397368959343\n",
      "Epoch: 70     Loss: -1.2295987502450054\n",
      "Epoch: 71     Loss: -1.2319211659428935\n",
      "Epoch: 72     Loss: -1.2342795433044227\n",
      "Epoch: 73     Loss: -1.236254692692258\n",
      "Epoch: 74     Loss: -1.2386295401661533\n",
      "Epoch: 75     Loss: -1.2407369729400357\n",
      "Epoch: 76     Loss: -1.242286361634218\n",
      "Epoch: 77     Loss: -1.244138629045204\n",
      "Epoch: 78     Loss: -1.2464164975596022\n",
      "Epoch: 79     Loss: -1.2485360848386797\n",
      "Epoch: 80     Loss: -1.2506639889151718\n",
      "Epoch: 81     Loss: -1.252596833213165\n",
      "Epoch: 82     Loss: -1.2547989562576791\n",
      "Epoch: 83     Loss: -1.2569767071989293\n",
      "Epoch: 84     Loss: -1.2590953217725982\n",
      "Epoch: 85     Loss: -1.2612223449901652\n",
      "Epoch: 86     Loss: -1.2633293603565512\n",
      "Epoch: 87     Loss: -1.2654857963286539\n",
      "Epoch: 88     Loss: -1.2675452243604355\n",
      "Epoch: 89     Loss: -1.2696781840570461\n",
      "Epoch: 90     Loss: -1.2715934027362763\n",
      "Epoch: 91     Loss: -1.2736978274156496\n",
      "Epoch: 92     Loss: -1.2753347907093522\n",
      "Epoch: 93     Loss: -1.277573835295727\n",
      "Epoch: 94     Loss: -1.279434002402727\n",
      "Epoch: 95     Loss: -1.2813317072934007\n",
      "Epoch: 96     Loss: -1.2826478277043927\n",
      "Epoch: 97     Loss: -1.284897337772641\n",
      "Epoch: 98     Loss: -1.2871810966128652\n",
      "Epoch: 99     Loss: -1.2892829943342001\n",
      "Epoch: 100     Loss: -1.2911808846495996\n",
      "Epoch: 101     Loss: -1.2923111745870846\n",
      "Epoch: 102     Loss: -1.2941923625475347\n",
      "Epoch: 103     Loss: -1.2962775371662296\n",
      "Epoch: 104     Loss: -1.298347268379983\n",
      "Epoch: 105     Loss: -1.3003755271191875\n",
      "Epoch: 106     Loss: -1.3020508810746767\n",
      "Epoch: 107     Loss: -1.3042016104363663\n",
      "Epoch: 108     Loss: -1.3062203364067424\n",
      "Epoch: 109     Loss: -1.3080574690166744\n",
      "Epoch: 110     Loss: -1.3093350585094994\n",
      "Epoch: 111     Loss: -1.3113610959908568\n",
      "Epoch: 112     Loss: -1.313445530883255\n",
      "Epoch: 113     Loss: -1.3153415042260863\n",
      "Epoch: 114     Loss: -1.3170705287687428\n",
      "Epoch: 115     Loss: -1.318439005406495\n",
      "Epoch: 116     Loss: -1.3197957736212775\n",
      "Epoch: 117     Loss: -1.3213346304839937\n",
      "Epoch: 118     Loss: -1.3230105062176234\n",
      "Epoch: 119     Loss: -1.3245455293820632\n",
      "Epoch: 120     Loss: -1.326064541032479\n",
      "Epoch: 121     Loss: -1.3274949057105305\n",
      "Epoch: 122     Loss: -1.3290396618138995\n",
      "Epoch: 123     Loss: -1.3306136448999422\n",
      "Epoch: 124     Loss: -1.3321971456475918\n",
      "Epoch: 125     Loss: -1.333708946840472\n",
      "Epoch: 126     Loss: -1.3352822265654114\n",
      "Epoch: 127     Loss: -1.3366835275061413\n",
      "Epoch: 128     Loss: -1.338348314859115\n",
      "Epoch: 129     Loss: -1.3398414853348122\n",
      "Epoch: 130     Loss: -1.3415044932228197\n",
      "Epoch: 131     Loss: -1.3428931842306255\n",
      "Epoch: 132     Loss: -1.3446659388274864\n",
      "Epoch: 133     Loss: -1.3463403401961098\n",
      "Epoch: 134     Loss: -1.3479509940886758\n",
      "Epoch: 135     Loss: -1.3491687830079855\n",
      "Epoch: 136     Loss: -1.3507933896909283\n",
      "Epoch: 137     Loss: -1.3524911671356108\n",
      "Epoch: 138     Loss: -1.3541842617211097\n",
      "Epoch: 139     Loss: -1.3556982152935362\n",
      "Epoch: 140     Loss: -1.3570088509151381\n",
      "Epoch: 141     Loss: -1.3580402548361652\n",
      "Epoch: 142     Loss: -1.3594765000325644\n",
      "Epoch: 143     Loss: -1.3610067847451663\n",
      "Epoch: 144     Loss: -1.362462231627458\n",
      "Epoch: 145     Loss: -1.3639013338056736\n",
      "Epoch: 146     Loss: -1.3652621762723733\n",
      "Epoch: 147     Loss: -1.3666330956223474\n",
      "Epoch: 148     Loss: -1.3680426039077647\n",
      "Epoch: 149     Loss: -1.3694641411301252\n",
      "Epoch: 150     Loss: -1.3708573402337183\n",
      "Epoch: 151     Loss: -1.372212497812505\n",
      "Epoch: 152     Loss: -1.3735840356630045\n",
      "Epoch: 153     Loss: -1.3750300695416382\n",
      "Epoch: 154     Loss: -1.3763192475452934\n",
      "Epoch: 155     Loss: -1.3775680352554405\n",
      "Epoch: 156     Loss: -1.3787762633730072\n",
      "Epoch: 157     Loss: -1.380235848159595\n",
      "Epoch: 158     Loss: -1.3816068735617522\n",
      "Epoch: 159     Loss: -1.382992329836476\n",
      "Epoch: 160     Loss: -1.3841410979125341\n",
      "Epoch: 161     Loss: -1.3856156112401334\n",
      "Epoch: 162     Loss: -1.3870486680692204\n",
      "Epoch: 163     Loss: -1.3883676647017111\n",
      "Epoch: 164     Loss: -1.389660548147147\n",
      "Epoch: 165     Loss: -1.3910357586090172\n",
      "Epoch: 166     Loss: -1.3922437625059836\n",
      "Epoch: 167     Loss: -1.3936370479520364\n",
      "Epoch: 168     Loss: -1.3949090458631674\n",
      "Epoch: 169     Loss: -1.396208991017717\n",
      "Epoch: 170     Loss: -1.3972313960750942\n",
      "Epoch: 171     Loss: -1.3985510261121847\n",
      "Epoch: 172     Loss: -1.3998750342474102\n",
      "Epoch: 173     Loss: -1.4011887090212762\n",
      "Epoch: 174     Loss: -1.402360103890753\n",
      "Epoch: 175     Loss: -1.4036251985855601\n",
      "Epoch: 176     Loss: -1.4046457366857021\n",
      "Epoch: 177     Loss: -1.4058898171000107\n",
      "Epoch: 178     Loss: -1.4071408398066185\n",
      "Epoch: 179     Loss: -1.4083995483185237\n",
      "Epoch: 180     Loss: -1.4095561405889856\n",
      "Epoch: 181     Loss: -1.4107702967484712\n",
      "Epoch: 182     Loss: -1.4118230306670705\n",
      "Epoch: 183     Loss: -1.4130010593699311\n",
      "Epoch: 184     Loss: -1.4140804588397906\n",
      "Epoch: 185     Loss: -1.4150688915110832\n",
      "Epoch: 186     Loss: -1.4160972736464958\n",
      "Epoch: 187     Loss: -1.4171216157407345\n",
      "Epoch: 188     Loss: -1.418180079463898\n",
      "Epoch: 189     Loss: -1.419246393593182\n",
      "Epoch: 190     Loss: -1.4203495076229753\n",
      "Epoch: 191     Loss: -1.4213800070245315\n",
      "Epoch: 192     Loss: -1.4223840103855696\n",
      "Epoch: 193     Loss: -1.4233919162539912\n",
      "Epoch: 194     Loss: -1.4245140915385615\n",
      "Epoch: 195     Loss: -1.425540418713044\n",
      "Epoch: 196     Loss: -1.4265788200660408\n",
      "Epoch: 197     Loss: -1.427529399063237\n",
      "Epoch: 198     Loss: -1.4285279103297368\n",
      "Epoch: 199     Loss: -1.4295594720850275\n",
      "Epoch: 200     Loss: -1.4306574021703102\n",
      "Epoch: 201     Loss: -1.4317004633618398\n",
      "Epoch: 202     Loss: -1.4327596028610134\n",
      "Epoch: 203     Loss: -1.4337570410131413\n",
      "Epoch: 204     Loss: -1.4347123108671935\n",
      "Epoch: 205     Loss: -1.4357273059287017\n",
      "Epoch: 206     Loss: -1.4368040026030227\n",
      "Epoch: 207     Loss: -1.4378401758810764\n",
      "Epoch: 208     Loss: -1.4388892087976768\n",
      "Epoch: 209     Loss: -1.439872075726781\n",
      "Epoch: 210     Loss: -1.4408287603435934\n",
      "Epoch: 211     Loss: -1.441811308768008\n",
      "Epoch: 212     Loss: -1.4428419977884974\n",
      "Epoch: 213     Loss: -1.443813044577109\n",
      "Epoch: 214     Loss: -1.4447247263050194\n",
      "Epoch: 215     Loss: -1.4456799711836827\n",
      "Epoch: 216     Loss: -1.4466773451917478\n",
      "Epoch: 217     Loss: -1.44761303584968\n",
      "Epoch: 218     Loss: -1.4484780451948671\n",
      "Epoch: 219     Loss: -1.4493886890044836\n",
      "Epoch: 220     Loss: -1.4503167056190358\n",
      "Epoch: 221     Loss: -1.4512282455459549\n",
      "Epoch: 222     Loss: -1.4520650203607175\n",
      "Epoch: 223     Loss: -1.4529949940145315\n",
      "Epoch: 224     Loss: -1.4539128135489972\n",
      "Epoch: 225     Loss: -1.4548122032401736\n",
      "Epoch: 226     Loss: -1.4556173665429477\n",
      "Epoch: 227     Loss: -1.4565435063113819\n",
      "Epoch: 228     Loss: -1.4574532888095706\n",
      "Epoch: 229     Loss: -1.458365158749159\n",
      "Epoch: 230     Loss: -1.459148896842904\n",
      "Epoch: 231     Loss: -1.4600604199429008\n",
      "Epoch: 232     Loss: -1.460991622350035\n",
      "Epoch: 233     Loss: -1.4619134662680875\n",
      "Epoch: 234     Loss: -1.4627613988415564\n",
      "Epoch: 235     Loss: -1.463509572383842\n",
      "Epoch: 236     Loss: -1.4642974766890957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 237     Loss: -1.4651819053387443\n",
      "Epoch: 238     Loss: -1.466053280117299\n",
      "Epoch: 239     Loss: -1.46693419778102\n",
      "Epoch: 240     Loss: -1.4677209012021597\n",
      "Epoch: 241     Loss: -1.4686132207130067\n",
      "Epoch: 242     Loss: -1.4694955174036066\n",
      "Epoch: 243     Loss: -1.4703790896098274\n",
      "Epoch: 244     Loss: -1.4712171887796066\n",
      "Epoch: 245     Loss: -1.472035341027411\n",
      "Epoch: 246     Loss: -1.472820380614588\n",
      "Epoch: 247     Loss: -1.4736351952681062\n",
      "Epoch: 248     Loss: -1.474353229091482\n",
      "Epoch: 249     Loss: -1.4750878301420811\n",
      "Epoch: 250     Loss: -1.4758190598602372\n",
      "Epoch: 251     Loss: -1.476599546131173\n",
      "Epoch: 252     Loss: -1.4773085047421821\n",
      "Epoch: 253     Loss: -1.4779722897869003\n",
      "Epoch: 254     Loss: -1.4787156233464873\n",
      "Epoch: 255     Loss: -1.4795276626558804\n",
      "Epoch: 256     Loss: -1.4803056324327462\n",
      "Epoch: 257     Loss: -1.4810170906645153\n",
      "Epoch: 258     Loss: -1.4817821836872922\n",
      "Epoch: 259     Loss: -1.48256263047127\n",
      "Epoch: 260     Loss: -1.4833378351691824\n",
      "Epoch: 261     Loss: -1.4841138887138858\n",
      "Epoch: 262     Loss: -1.4848566250477715\n",
      "Epoch: 263     Loss: -1.4855714165496967\n",
      "Epoch: 264     Loss: -1.4863238463787292\n",
      "Epoch: 265     Loss: -1.4870920470445312\n",
      "Epoch: 266     Loss: -1.4878376467607766\n",
      "Epoch: 267     Loss: -1.4885545671670881\n",
      "Epoch: 268     Loss: -1.4892966076493346\n",
      "Epoch: 269     Loss: -1.4900580133936536\n",
      "Epoch: 270     Loss: -1.4907606405932845\n",
      "Epoch: 271     Loss: -1.4914310166174085\n",
      "Epoch: 272     Loss: -1.492100759379919\n",
      "Epoch: 273     Loss: -1.4928020390142815\n",
      "Epoch: 274     Loss: -1.4934957095368093\n",
      "Epoch: 275     Loss: -1.4941663428531862\n",
      "Epoch: 276     Loss: -1.494857989365124\n",
      "Epoch: 277     Loss: -1.4954980358998582\n",
      "Epoch: 278     Loss: -1.496197636504635\n",
      "Epoch: 279     Loss: -1.4968245943484937\n",
      "Epoch: 280     Loss: -1.4975457841936866\n",
      "Epoch: 281     Loss: -1.4982253941790649\n",
      "Epoch: 282     Loss: -1.4989216588223382\n",
      "Epoch: 283     Loss: -1.4994902504764365\n",
      "Epoch: 284     Loss: -1.5002042929388792\n",
      "Epoch: 285     Loss: -1.5009110473950866\n",
      "Epoch: 286     Loss: -1.5016120908043908\n",
      "Epoch: 287     Loss: -1.5022331759072889\n",
      "Epoch: 288     Loss: -1.5029186518385325\n",
      "Epoch: 289     Loss: -1.503603488970547\n",
      "Epoch: 290     Loss: -1.5042960326819355\n",
      "Epoch: 291     Loss: -1.504974566665182\n",
      "Epoch: 292     Loss: -1.5056243196506744\n",
      "Epoch: 293     Loss: -1.506279926840992\n",
      "Epoch: 294     Loss: -1.50695933287361\n",
      "Epoch: 295     Loss: -1.5075803020547858\n",
      "Epoch: 296     Loss: -1.5081835883856656\n",
      "Epoch: 297     Loss: -1.5088021012792527\n",
      "Epoch: 298     Loss: -1.5094690756358458\n",
      "Epoch: 299     Loss: -1.510102181872117\n",
      "Epoch: 300     Loss: -1.5107447422951483\n",
      "Epoch: 301     Loss: -1.5113616634541052\n",
      "Epoch: 302     Loss: -1.5119624082808272\n",
      "Epoch: 303     Loss: -1.5126125019470449\n",
      "Epoch: 304     Loss: -1.5132589590677588\n",
      "Epoch: 305     Loss: -1.5138941684477556\n",
      "Epoch: 306     Loss: -1.5144260275007078\n",
      "Epoch: 307     Loss: -1.5150547062707462\n",
      "Epoch: 308     Loss: -1.515652131214046\n",
      "Epoch: 309     Loss: -1.5162847397406796\n",
      "Epoch: 310     Loss: -1.5168312526772672\n",
      "Epoch: 311     Loss: -1.5174579679723703\n",
      "Epoch: 312     Loss: -1.518037006167673\n",
      "Epoch: 313     Loss: -1.518627151098496\n",
      "Epoch: 314     Loss: -1.5191564812691956\n",
      "Epoch: 315     Loss: -1.519745919016402\n",
      "Epoch: 316     Loss: -1.5203426555656492\n",
      "Epoch: 317     Loss: -1.5208957757137593\n",
      "Epoch: 318     Loss: -1.521481076995225\n",
      "Epoch: 319     Loss: -1.5220234600109934\n",
      "Epoch: 320     Loss: -1.5226275716271944\n",
      "Epoch: 321     Loss: -1.5231638212411207\n",
      "Epoch: 322     Loss: -1.523785192956991\n",
      "Epoch: 323     Loss: -1.5243657058744373\n",
      "Epoch: 324     Loss: -1.5249533319359319\n",
      "Epoch: 325     Loss: -1.5254312655247213\n",
      "Epoch: 326     Loss: -1.526029762859959\n",
      "Epoch: 327     Loss: -1.5266134009201433\n",
      "Epoch: 328     Loss: -1.5272106789442919\n",
      "Epoch: 329     Loss: -1.5277575604294436\n",
      "Epoch: 330     Loss: -1.528341290344618\n",
      "Epoch: 331     Loss: -1.528898589105237\n",
      "Epoch: 332     Loss: -1.5294824862752383\n",
      "Epoch: 333     Loss: -1.5300457262214844\n",
      "Epoch: 334     Loss: -1.5306185604436429\n",
      "Epoch: 335     Loss: -1.5311815833020777\n",
      "Epoch: 336     Loss: -1.5317318563926619\n",
      "Epoch: 337     Loss: -1.5322975456359953\n",
      "Epoch: 338     Loss: -1.5328338874987686\n",
      "Epoch: 339     Loss: -1.533343885111621\n",
      "Epoch: 340     Loss: -1.5337799385332105\n",
      "Epoch: 341     Loss: -1.5343057764207464\n",
      "Epoch: 342     Loss: -1.5348623393881244\n",
      "Epoch: 343     Loss: -1.5354022724648897\n",
      "Epoch: 344     Loss: -1.5359440785407008\n",
      "Epoch: 345     Loss: -1.5364531460792432\n",
      "Epoch: 346     Loss: -1.536976028092463\n",
      "Epoch: 347     Loss: -1.537463483976313\n",
      "Epoch: 348     Loss: -1.5380187110980177\n",
      "Epoch: 349     Loss: -1.538547655710151\n",
      "Epoch: 350     Loss: -1.5390945134009897\n",
      "Epoch: 351     Loss: -1.5395741167637462\n",
      "Epoch: 352     Loss: -1.54013838045587\n",
      "Epoch: 353     Loss: -1.540686776861469\n",
      "Epoch: 354     Loss: -1.541240742246591\n",
      "Epoch: 355     Loss: -1.5417602538670674\n",
      "Epoch: 356     Loss: -1.5423162429433463\n",
      "Epoch: 357     Loss: -1.542848106247373\n",
      "Epoch: 358     Loss: -1.5433950620992565\n",
      "Epoch: 359     Loss: -1.5439042388727764\n",
      "Epoch: 360     Loss: -1.5443586655805333\n",
      "Epoch: 361     Loss: -1.544851099412481\n",
      "Epoch: 362     Loss: -1.5453466605622186\n",
      "Epoch: 363     Loss: -1.545820744179334\n",
      "Epoch: 364     Loss: -1.5462143402883648\n",
      "Epoch: 365     Loss: -1.5466959639475024\n",
      "Epoch: 366     Loss: -1.5472001100322172\n",
      "Epoch: 367     Loss: -1.547698140061306\n",
      "Epoch: 368     Loss: -1.5481600224642573\n",
      "Epoch: 369     Loss: -1.5486616317541353\n",
      "Epoch: 370     Loss: -1.5491584522590627\n",
      "Epoch: 371     Loss: -1.5496508181953492\n",
      "Epoch: 372     Loss: -1.5501224651671026\n",
      "Epoch: 373     Loss: -1.550595185713323\n",
      "Epoch: 374     Loss: -1.5510362595948615\n",
      "Epoch: 375     Loss: -1.551496344430609\n",
      "Epoch: 376     Loss: -1.551920731593654\n",
      "Epoch: 377     Loss: -1.5524141729876328\n",
      "Epoch: 378     Loss: -1.5529075103560144\n",
      "Epoch: 379     Loss: -1.5534085886202618\n",
      "Epoch: 380     Loss: -1.5538921176026852\n",
      "Epoch: 381     Loss: -1.5543840025392999\n",
      "Epoch: 382     Loss: -1.554854035452253\n",
      "Epoch: 383     Loss: -1.5553382196387597\n",
      "Epoch: 384     Loss: -1.5557932567125574\n",
      "Epoch: 385     Loss: -1.5562707216210878\n",
      "Epoch: 386     Loss: -1.5567025181687346\n",
      "Epoch: 387     Loss: -1.5571961927090954\n",
      "Epoch: 388     Loss: -1.5576759582473474\n",
      "Epoch: 389     Loss: -1.5581666105952099\n",
      "Epoch: 390     Loss: -1.5586215535315788\n",
      "Epoch: 391     Loss: -1.5591042279865646\n",
      "Epoch: 392     Loss: -1.5595475837932555\n",
      "Epoch: 393     Loss: -1.5600300866021244\n",
      "Epoch: 394     Loss: -1.560479571966644\n",
      "Epoch: 395     Loss: -1.560954935527608\n",
      "Epoch: 396     Loss: -1.561386622236982\n",
      "Epoch: 397     Loss: -1.5618462494109209\n",
      "Epoch: 398     Loss: -1.562254994150911\n",
      "Epoch: 399     Loss: -1.562680025882739\n",
      "Epoch: 400     Loss: -1.5630996216646629\n",
      "Epoch: 401     Loss: -1.563533485922459\n",
      "Epoch: 402     Loss: -1.5639451731206455\n",
      "Epoch: 403     Loss: -1.5643958820562267\n",
      "Epoch: 404     Loss: -1.5648322554534322\n",
      "Epoch: 405     Loss: -1.5652792686558414\n",
      "Epoch: 406     Loss: -1.5656846496526375\n",
      "Epoch: 407     Loss: -1.5661377687380829\n",
      "Epoch: 408     Loss: -1.5665626485371358\n",
      "Epoch: 409     Loss: -1.5670124585733842\n",
      "Epoch: 410     Loss: -1.5674532908572318\n",
      "Epoch: 411     Loss: -1.5679025830238007\n",
      "Epoch: 412     Loss: -1.5683428394818861\n",
      "Epoch: 413     Loss: -1.568788156477619\n",
      "Epoch: 414     Loss: -1.5692262092692435\n",
      "Epoch: 415     Loss: -1.5696539163454613\n",
      "Epoch: 416     Loss: -1.5700684372171325\n",
      "Epoch: 417     Loss: -1.570459435064732\n",
      "Epoch: 418     Loss: -1.5708690782178292\n",
      "Epoch: 419     Loss: -1.571275336458435\n",
      "Epoch: 420     Loss: -1.571705786995765\n",
      "Epoch: 421     Loss: -1.572118595235361\n",
      "Epoch: 422     Loss: -1.5725388573403911\n",
      "Epoch: 423     Loss: -1.5729292454831085\n",
      "Epoch: 424     Loss: -1.5732970669395479\n",
      "Epoch: 425     Loss: -1.5736875391510627\n",
      "Epoch: 426     Loss: -1.5740884975270435\n",
      "Epoch: 427     Loss: -1.5744820626320122\n",
      "Epoch: 428     Loss: -1.5748579061459014\n",
      "Epoch: 429     Loss: -1.5752604411254227\n",
      "Epoch: 430     Loss: -1.5756531972725962\n",
      "Epoch: 431     Loss: -1.5760581102225237\n",
      "Epoch: 432     Loss: -1.576425733484818\n",
      "Epoch: 433     Loss: -1.5768419402968687\n",
      "Epoch: 434     Loss: -1.5772435397194027\n",
      "Epoch: 435     Loss: -1.5776591084219789\n",
      "Epoch: 436     Loss: -1.578047339035804\n",
      "Epoch: 437     Loss: -1.5784558787001133\n",
      "Epoch: 438     Loss: -1.5788087623181206\n",
      "Epoch: 439     Loss: -1.5792148494878357\n",
      "Epoch: 440     Loss: -1.5795997519071678\n",
      "Epoch: 441     Loss: -1.5800107187392631\n",
      "Epoch: 442     Loss: -1.5803910853294898\n",
      "Epoch: 443     Loss: -1.5808004806292866\n",
      "Epoch: 444     Loss: -1.5811837048368504\n",
      "Epoch: 445     Loss: -1.5815943287990286\n",
      "Epoch: 446     Loss: -1.5819832229747615\n",
      "Epoch: 447     Loss: -1.5823774305058054\n",
      "Epoch: 448     Loss: -1.5827308585676028\n",
      "Epoch: 449     Loss: -1.5830351472188757\n",
      "Epoch: 450     Loss: -1.5834074041452282\n",
      "Epoch: 451     Loss: -1.5838073908778074\n",
      "Epoch: 452     Loss: -1.5841939403511296\n",
      "Epoch: 453     Loss: -1.5845871821132715\n",
      "Epoch: 454     Loss: -1.5849646249516443\n",
      "Epoch: 455     Loss: -1.5853447779139203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 456     Loss: -1.5857184294225544\n",
      "Epoch: 457     Loss: -1.5860781585834867\n",
      "Epoch: 458     Loss: -1.5864589250147803\n",
      "Epoch: 459     Loss: -1.5868496362484918\n",
      "Epoch: 460     Loss: -1.5872265510573238\n",
      "Epoch: 461     Loss: -1.5875951515135878\n",
      "Epoch: 462     Loss: -1.587959122749261\n",
      "Epoch: 463     Loss: -1.5883234917187652\n",
      "Epoch: 464     Loss: -1.5886857863698847\n",
      "Epoch: 465     Loss: -1.589045389804763\n",
      "Epoch: 466     Loss: -1.5894083349202541\n",
      "Epoch: 467     Loss: -1.589772058801693\n",
      "Epoch: 468     Loss: -1.5901342092269741\n",
      "Epoch: 469     Loss: -1.5905016903503746\n",
      "Epoch: 470     Loss: -1.5908659570956056\n",
      "Epoch: 471     Loss: -1.5912367096931852\n",
      "Epoch: 472     Loss: -1.5915919885677374\n",
      "Epoch: 473     Loss: -1.5919615656257207\n",
      "Epoch: 474     Loss: -1.5922983752842914\n",
      "Epoch: 475     Loss: -1.592686014308182\n",
      "Epoch: 476     Loss: -1.5930543655704892\n",
      "Epoch: 477     Loss: -1.5934086953116946\n",
      "Epoch: 478     Loss: -1.5937558929480071\n",
      "Epoch: 479     Loss: -1.5941141830914916\n",
      "Epoch: 480     Loss: -1.5944635680390546\n",
      "Epoch: 481     Loss: -1.5948263026998857\n",
      "Epoch: 482     Loss: -1.5951810256867354\n",
      "Epoch: 483     Loss: -1.5955423805111242\n",
      "Epoch: 484     Loss: -1.5959015111826809\n",
      "Epoch: 485     Loss: -1.5962666539651342\n",
      "Epoch: 486     Loss: -1.596626391248597\n",
      "Epoch: 487     Loss: -1.596986001055576\n",
      "Epoch: 488     Loss: -1.597339789850282\n",
      "Epoch: 489     Loss: -1.597678156644163\n",
      "Epoch: 490     Loss: -1.5980358889762194\n",
      "Epoch: 491     Loss: -1.5983857658817702\n",
      "Epoch: 492     Loss: -1.5987405988061971\n",
      "Epoch: 493     Loss: -1.599078983585951\n",
      "Epoch: 494     Loss: -1.5994290847689674\n",
      "Epoch: 495     Loss: -1.5997510353614772\n",
      "Epoch: 496     Loss: -1.6000889457433185\n",
      "Epoch: 497     Loss: -1.6003906711718305\n",
      "Epoch: 498     Loss: -1.600731359418401\n",
      "Epoch: 499     Loss: -1.6010498775000772\n",
      "Epoch: 500     Loss: -1.601400467250328\n",
      "Epoch: 501     Loss: -1.6017364594975236\n",
      "Epoch: 502     Loss: -1.602092309496481\n",
      "Epoch: 503     Loss: -1.602433387000572\n",
      "Epoch: 504     Loss: -1.6027864800021396\n",
      "Epoch: 505     Loss: -1.603117345642158\n",
      "Epoch: 506     Loss: -1.6034630453796381\n",
      "Epoch: 507     Loss: -1.6037785708732584\n",
      "Epoch: 508     Loss: -1.604093093845612\n",
      "Epoch: 509     Loss: -1.6043964750761452\n",
      "Epoch: 510     Loss: -1.6046638638329822\n",
      "Epoch: 511     Loss: -1.6049316056739453\n",
      "Epoch: 512     Loss: -1.605224334017398\n",
      "Epoch: 513     Loss: -1.6055404626110714\n",
      "Epoch: 514     Loss: -1.605833635648665\n",
      "Epoch: 515     Loss: -1.606165413578311\n",
      "Epoch: 516     Loss: -1.6064892810738045\n",
      "Epoch: 517     Loss: -1.6068200862258717\n",
      "Epoch: 518     Loss: -1.6071486347649215\n",
      "Epoch: 519     Loss: -1.607482960329192\n",
      "Epoch: 520     Loss: -1.607815573552243\n",
      "Epoch: 521     Loss: -1.6081449958375191\n",
      "Epoch: 522     Loss: -1.60847981158625\n",
      "Epoch: 523     Loss: -1.6088172910643574\n",
      "Epoch: 524     Loss: -1.6091465992839769\n",
      "Epoch: 525     Loss: -1.609472834795942\n",
      "Epoch: 526     Loss: -1.6097945620783016\n",
      "Epoch: 527     Loss: -1.610118842073503\n",
      "Epoch: 528     Loss: -1.6104293246727273\n",
      "Epoch: 529     Loss: -1.6107296042765376\n",
      "Epoch: 530     Loss: -1.6110362333079709\n",
      "Epoch: 531     Loss: -1.611350455605028\n",
      "Epoch: 532     Loss: -1.6116645015898992\n",
      "Epoch: 533     Loss: -1.6119802377517072\n",
      "Epoch: 534     Loss: -1.6122991367620567\n",
      "Epoch: 535     Loss: -1.612616843833011\n",
      "Epoch: 536     Loss: -1.6129400377137324\n",
      "Epoch: 537     Loss: -1.6132606620053975\n",
      "Epoch: 538     Loss: -1.6135851437667037\n",
      "Epoch: 539     Loss: -1.6139016639689774\n",
      "Epoch: 540     Loss: -1.6142022388960098\n",
      "Epoch: 541     Loss: -1.6145321803990467\n",
      "Epoch: 542     Loss: -1.614860238150746\n",
      "Epoch: 543     Loss: -1.6151853937782301\n",
      "Epoch: 544     Loss: -1.615513194109725\n",
      "Epoch: 545     Loss: -1.6158306453751132\n",
      "Epoch: 546     Loss: -1.6161538261594344\n",
      "Epoch: 547     Loss: -1.6164632616929104\n",
      "Epoch: 548     Loss: -1.6167811792037627\n",
      "Epoch: 549     Loss: -1.6170775583498584\n",
      "Epoch: 550     Loss: -1.6173987263095069\n",
      "Epoch: 551     Loss: -1.6176872015491273\n",
      "Epoch: 552     Loss: -1.617968432997212\n",
      "Epoch: 553     Loss: -1.618209163434288\n",
      "Epoch: 554     Loss: -1.6185143970056612\n",
      "Epoch: 555     Loss: -1.6188175479882492\n",
      "Epoch: 556     Loss: -1.6191386653150384\n",
      "Epoch: 557     Loss: -1.6194496918075993\n",
      "Epoch: 558     Loss: -1.6197693745437765\n",
      "Epoch: 559     Loss: -1.620073253473486\n",
      "Epoch: 560     Loss: -1.6203801863280427\n",
      "Epoch: 561     Loss: -1.620655370953772\n",
      "Epoch: 562     Loss: -1.6209488852964336\n",
      "Epoch: 563     Loss: -1.6212139879981167\n",
      "Epoch: 564     Loss: -1.6214961149198743\n",
      "Epoch: 565     Loss: -1.6217625254310317\n",
      "Epoch: 566     Loss: -1.6220446614861546\n",
      "Epoch: 567     Loss: -1.6223260762993246\n",
      "Epoch: 568     Loss: -1.6226035907315843\n",
      "Epoch: 569     Loss: -1.622865513826651\n",
      "Epoch: 570     Loss: -1.62313824507835\n",
      "Epoch: 571     Loss: -1.6234213017824315\n",
      "Epoch: 572     Loss: -1.6236973262755006\n",
      "Epoch: 573     Loss: -1.6239951654166371\n",
      "Epoch: 574     Loss: -1.6242826598808005\n",
      "Epoch: 575     Loss: -1.6245685048847613\n",
      "Epoch: 576     Loss: -1.6248608500734814\n",
      "Epoch: 577     Loss: -1.6251549058734545\n",
      "Epoch: 578     Loss: -1.6254423734915109\n",
      "Epoch: 579     Loss: -1.625719453149872\n",
      "Epoch: 580     Loss: -1.6260178324288934\n",
      "Epoch: 581     Loss: -1.626316606524532\n",
      "Epoch: 582     Loss: -1.6266166555166144\n",
      "Epoch: 583     Loss: -1.6269119684063487\n",
      "Epoch: 584     Loss: -1.627209547185135\n",
      "Epoch: 585     Loss: -1.6274964531464835\n",
      "Epoch: 586     Loss: -1.6277879595561155\n",
      "Epoch: 587     Loss: -1.6280708391604055\n",
      "Epoch: 588     Loss: -1.628368523810003\n",
      "Epoch: 589     Loss: -1.628657149945024\n",
      "Epoch: 590     Loss: -1.6289518768363662\n",
      "Epoch: 591     Loss: -1.6292305845609742\n",
      "Epoch: 592     Loss: -1.6295133725398383\n",
      "Epoch: 593     Loss: -1.6297666366649484\n",
      "Epoch: 594     Loss: -1.6300194559771424\n",
      "Epoch: 595     Loss: -1.6302519808293798\n",
      "Epoch: 596     Loss: -1.6305087737225352\n",
      "Epoch: 597     Loss: -1.6307692884455232\n",
      "Epoch: 598     Loss: -1.6310425142674723\n",
      "Epoch: 599     Loss: -1.6313076734606773\n",
      "Epoch: 600     Loss: -1.6315809393497118\n",
      "Epoch: 601     Loss: -1.6318536285431504\n",
      "Epoch: 602     Loss: -1.6321324177890926\n",
      "Epoch: 603     Loss: -1.6324130257916636\n",
      "Epoch: 604     Loss: -1.6326982447169767\n",
      "Epoch: 605     Loss: -1.6329833865106353\n",
      "Epoch: 606     Loss: -1.6332681648211813\n",
      "Epoch: 607     Loss: -1.6335454534556209\n",
      "Epoch: 608     Loss: -1.6337971795614576\n",
      "Epoch: 609     Loss: -1.6340701417403098\n",
      "Epoch: 610     Loss: -1.6343537334957634\n",
      "Epoch: 611     Loss: -1.634628371457974\n",
      "Epoch: 612     Loss: -1.6348900076803827\n",
      "Epoch: 613     Loss: -1.6351495129660116\n",
      "Epoch: 614     Loss: -1.6354137007640088\n",
      "Epoch: 615     Loss: -1.6356600356890691\n",
      "Epoch: 616     Loss: -1.635922009775018\n",
      "Epoch: 617     Loss: -1.6361809812319767\n",
      "Epoch: 618     Loss: -1.6364479716291682\n",
      "Epoch: 619     Loss: -1.636716324527617\n",
      "Epoch: 620     Loss: -1.6369894702218324\n",
      "Epoch: 621     Loss: -1.637261457863855\n",
      "Epoch: 622     Loss: -1.637529491711274\n",
      "Epoch: 623     Loss: -1.6377953069136637\n",
      "Epoch: 624     Loss: -1.6380425204382787\n",
      "Epoch: 625     Loss: -1.6383090754013347\n",
      "Epoch: 626     Loss: -1.6385564086017932\n",
      "Epoch: 627     Loss: -1.6388133047171447\n",
      "Epoch: 628     Loss: -1.6390562105825144\n",
      "Epoch: 629     Loss: -1.6393161500826876\n",
      "Epoch: 630     Loss: -1.6395695860270547\n",
      "Epoch: 631     Loss: -1.6398378866338712\n",
      "Epoch: 632     Loss: -1.6401017113284113\n",
      "Epoch: 633     Loss: -1.640375983122841\n",
      "Epoch: 634     Loss: -1.6406385162785584\n",
      "Epoch: 635     Loss: -1.6409022663494097\n",
      "Epoch: 636     Loss: -1.6411466916745558\n",
      "Epoch: 637     Loss: -1.6414213782556293\n",
      "Epoch: 638     Loss: -1.641693387452222\n",
      "Epoch: 639     Loss: -1.6419715756022553\n",
      "Epoch: 640     Loss: -1.6422466439674157\n",
      "Epoch: 641     Loss: -1.6425210816949845\n",
      "Epoch: 642     Loss: -1.6427810110121237\n",
      "Epoch: 643     Loss: -1.643046481427982\n",
      "Epoch: 644     Loss: -1.6433023862725578\n",
      "Epoch: 645     Loss: -1.6435619365580425\n",
      "Epoch: 646     Loss: -1.6438200086925174\n",
      "Epoch: 647     Loss: -1.644072604817756\n",
      "Epoch: 648     Loss: -1.6443214763025722\n",
      "Epoch: 649     Loss: -1.6445676694550009\n",
      "Epoch: 650     Loss: -1.6448206193796813\n",
      "Epoch: 651     Loss: -1.6450648834344583\n",
      "Epoch: 652     Loss: -1.645315989281573\n",
      "Epoch: 653     Loss: -1.6455559846813967\n",
      "Epoch: 654     Loss: -1.6457975547862385\n",
      "Epoch: 655     Loss: -1.646029530264091\n",
      "Epoch: 656     Loss: -1.6462705523971783\n",
      "Epoch: 657     Loss: -1.646495924619402\n",
      "Epoch: 658     Loss: -1.646741699479225\n",
      "Epoch: 659     Loss: -1.6469811301945625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 660     Loss: -1.6472358802256588\n",
      "Epoch: 661     Loss: -1.6474860874163035\n",
      "Epoch: 662     Loss: -1.647745884691096\n",
      "Epoch: 663     Loss: -1.6479990692895312\n",
      "Epoch: 664     Loss: -1.6482516445003979\n",
      "Epoch: 665     Loss: -1.6484870688226716\n",
      "Epoch: 666     Loss: -1.6486984956373836\n",
      "Epoch: 667     Loss: -1.6489372898552908\n",
      "Epoch: 668     Loss: -1.6491963865757173\n",
      "Epoch: 669     Loss: -1.6494476881575058\n",
      "Epoch: 670     Loss: -1.649694308385193\n",
      "Epoch: 671     Loss: -1.649926771614663\n",
      "Epoch: 672     Loss: -1.650175822922495\n",
      "Epoch: 673     Loss: -1.650421657541571\n",
      "Epoch: 674     Loss: -1.6506741839910655\n",
      "Epoch: 675     Loss: -1.6509214437903998\n",
      "Epoch: 676     Loss: -1.6511699465034322\n",
      "Epoch: 677     Loss: -1.65140376521923\n",
      "Epoch: 678     Loss: -1.6516392671521214\n",
      "Epoch: 679     Loss: -1.6518597991226946\n",
      "Epoch: 680     Loss: -1.6521032630444161\n",
      "Epoch: 681     Loss: -1.6523365084365267\n",
      "Epoch: 682     Loss: -1.6525781520718081\n",
      "Epoch: 683     Loss: -1.6528111656533875\n",
      "Epoch: 684     Loss: -1.653047813729989\n",
      "Epoch: 685     Loss: -1.6532717811737898\n",
      "Epoch: 686     Loss: -1.6535061211211481\n",
      "Epoch: 687     Loss: -1.6537380537484871\n",
      "Epoch: 688     Loss: -1.6539765719631894\n",
      "Epoch: 689     Loss: -1.6542131745051312\n",
      "Epoch: 690     Loss: -1.6544486310520152\n",
      "Epoch: 691     Loss: -1.6546813690249311\n",
      "Epoch: 692     Loss: -1.6549102045525748\n",
      "Epoch: 693     Loss: -1.6551416102718912\n",
      "Epoch: 694     Loss: -1.655374723677348\n",
      "Epoch: 695     Loss: -1.6556188243563241\n",
      "Epoch: 696     Loss: -1.6558571511001585\n",
      "Epoch: 697     Loss: -1.6561009021656534\n",
      "Epoch: 698     Loss: -1.6563436778810907\n",
      "Epoch: 699     Loss: -1.6565910627546823\n",
      "Epoch: 700     Loss: -1.656832970776411\n",
      "Epoch: 701     Loss: -1.6570781334530569\n",
      "Epoch: 702     Loss: -1.6573163141056588\n",
      "Epoch: 703     Loss: -1.6575546671405375\n",
      "Epoch: 704     Loss: -1.6577828245218975\n",
      "Epoch: 705     Loss: -1.6580120024842753\n",
      "Epoch: 706     Loss: -1.658236605745706\n",
      "Epoch: 707     Loss: -1.658467301110571\n",
      "Epoch: 708     Loss: -1.6586921309205365\n",
      "Epoch: 709     Loss: -1.6589219782855558\n",
      "Epoch: 710     Loss: -1.6591471645233995\n",
      "Epoch: 711     Loss: -1.6593749171241348\n",
      "Epoch: 712     Loss: -1.659589204176756\n",
      "Epoch: 713     Loss: -1.6598256699532414\n",
      "Epoch: 714     Loss: -1.6600573328910895\n",
      "Epoch: 715     Loss: -1.6602957746951872\n",
      "Epoch: 716     Loss: -1.6605308566172428\n",
      "Epoch: 717     Loss: -1.660767119957381\n",
      "Epoch: 718     Loss: -1.6609942496351042\n",
      "Epoch: 719     Loss: -1.6612189677838136\n",
      "Epoch: 720     Loss: -1.6614297751455898\n",
      "Epoch: 721     Loss: -1.6616373745082855\n",
      "Epoch: 722     Loss: -1.661848962218376\n",
      "Epoch: 723     Loss: -1.6620673676504452\n",
      "Epoch: 724     Loss: -1.662283939022423\n",
      "Epoch: 725     Loss: -1.6625008891699866\n",
      "Epoch: 726     Loss: -1.6627211126901233\n",
      "Epoch: 727     Loss: -1.662941824653824\n",
      "Epoch: 728     Loss: -1.6631639879610465\n",
      "Epoch: 729     Loss: -1.663387845011504\n",
      "Epoch: 730     Loss: -1.663612555455397\n",
      "Epoch: 731     Loss: -1.6638403265466186\n",
      "Epoch: 732     Loss: -1.6640666626681562\n",
      "Epoch: 733     Loss: -1.664291726235913\n",
      "Epoch: 734     Loss: -1.6645019823337683\n",
      "Epoch: 735     Loss: -1.6647223917815102\n",
      "Epoch: 736     Loss: -1.6649295884180149\n",
      "Epoch: 737     Loss: -1.6651522515844708\n",
      "Epoch: 738     Loss: -1.665362410906579\n",
      "Epoch: 739     Loss: -1.6655864942564382\n",
      "Epoch: 740     Loss: -1.6657978529074964\n",
      "Epoch: 741     Loss: -1.6660225423621462\n",
      "Epoch: 742     Loss: -1.666235998928839\n",
      "Epoch: 743     Loss: -1.666465024081097\n",
      "Epoch: 744     Loss: -1.6666859842447335\n",
      "Epoch: 745     Loss: -1.6669145882727379\n",
      "Epoch: 746     Loss: -1.6671337012859104\n",
      "Epoch: 747     Loss: -1.6673579390493176\n",
      "Epoch: 748     Loss: -1.667566446489984\n",
      "Epoch: 749     Loss: -1.6677779074422836\n",
      "Epoch: 750     Loss: -1.6679934560012128\n",
      "Epoch: 751     Loss: -1.6682091976694686\n",
      "Epoch: 752     Loss: -1.6684220682809534\n",
      "Epoch: 753     Loss: -1.6686333179113422\n",
      "Epoch: 754     Loss: -1.6688458648382172\n",
      "Epoch: 755     Loss: -1.6690467184061897\n",
      "Epoch: 756     Loss: -1.669256151414422\n",
      "Epoch: 757     Loss: -1.6694521893463259\n",
      "Epoch: 758     Loss: -1.6696661208405281\n",
      "Epoch: 759     Loss: -1.669869244807252\n",
      "Epoch: 760     Loss: -1.6700869536224296\n",
      "Epoch: 761     Loss: -1.670294890890889\n",
      "Epoch: 762     Loss: -1.670510667378211\n",
      "Epoch: 763     Loss: -1.6707198472890612\n",
      "Epoch: 764     Loss: -1.6709355177623706\n",
      "Epoch: 765     Loss: -1.6711403882149367\n",
      "Epoch: 766     Loss: -1.671355577189194\n",
      "Epoch: 767     Loss: -1.6715614113240964\n",
      "Epoch: 768     Loss: -1.6717794520480662\n",
      "Epoch: 769     Loss: -1.671991141912554\n",
      "Epoch: 770     Loss: -1.6722090679395842\n",
      "Epoch: 771     Loss: -1.6724221612049808\n",
      "Epoch: 772     Loss: -1.6726384871761213\n",
      "Epoch: 773     Loss: -1.672852892206764\n",
      "Epoch: 774     Loss: -1.6730659749415417\n",
      "Epoch: 775     Loss: -1.6732782163944742\n",
      "Epoch: 776     Loss: -1.6734884068005833\n",
      "Epoch: 777     Loss: -1.6736992589535458\n",
      "Epoch: 778     Loss: -1.6739063171448705\n",
      "Epoch: 779     Loss: -1.674112684042898\n",
      "Epoch: 780     Loss: -1.6743139991596416\n",
      "Epoch: 781     Loss: -1.6745196391197041\n",
      "Epoch: 782     Loss: -1.6747129345435705\n",
      "Epoch: 783     Loss: -1.6749182353461465\n",
      "Epoch: 784     Loss: -1.6751136911842082\n",
      "Epoch: 785     Loss: -1.6753200804646995\n",
      "Epoch: 786     Loss: -1.6755133451338304\n",
      "Epoch: 787     Loss: -1.675728563567985\n",
      "Epoch: 788     Loss: -1.675937912573414\n",
      "Epoch: 789     Loss: -1.6761537401026454\n",
      "Epoch: 790     Loss: -1.676361902037919\n",
      "Epoch: 791     Loss: -1.6765768958129892\n",
      "Epoch: 792     Loss: -1.676783781240896\n",
      "Epoch: 793     Loss: -1.6769976707464749\n",
      "Epoch: 794     Loss: -1.6772042899910848\n",
      "Epoch: 795     Loss: -1.677420470363482\n",
      "Epoch: 796     Loss: -1.6776312169411434\n",
      "Epoch: 797     Loss: -1.6778466467934967\n",
      "Epoch: 798     Loss: -1.6780554966180397\n",
      "Epoch: 799     Loss: -1.6782666422936716\n",
      "Epoch: 800     Loss: -1.6784665958376843\n",
      "Epoch: 801     Loss: -1.6786692327781902\n",
      "Epoch: 802     Loss: -1.6788659420874819\n",
      "Epoch: 803     Loss: -1.6790722278558603\n",
      "Epoch: 804     Loss: -1.679283602270615\n",
      "Epoch: 805     Loss: -1.6794963427236143\n",
      "Epoch: 806     Loss: -1.6797020281390038\n",
      "Epoch: 807     Loss: -1.679909226757509\n",
      "Epoch: 808     Loss: -1.68010003612042\n",
      "Epoch: 809     Loss: -1.6802737701370605\n",
      "Epoch: 810     Loss: -1.6804017971123069\n",
      "Epoch: 811     Loss: -1.6805507851248283\n",
      "Epoch: 812     Loss: -1.6807239367971216\n",
      "Epoch: 813     Loss: -1.6809107975004813\n",
      "Epoch: 814     Loss: -1.6811004738548303\n",
      "Epoch: 815     Loss: -1.6812983386801956\n",
      "Epoch: 816     Loss: -1.6814969559858783\n",
      "Epoch: 817     Loss: -1.681699415266921\n",
      "Epoch: 818     Loss: -1.6818907421887612\n",
      "Epoch: 819     Loss: -1.6820920611239087\n",
      "Epoch: 820     Loss: -1.682280078773983\n",
      "Epoch: 821     Loss: -1.6824824115082637\n",
      "Epoch: 822     Loss: -1.6826802683127235\n",
      "Epoch: 823     Loss: -1.6828826375356254\n",
      "Epoch: 824     Loss: -1.6830729882156859\n",
      "Epoch: 825     Loss: -1.6832727500003608\n",
      "Epoch: 826     Loss: -1.6834634320578716\n",
      "Epoch: 827     Loss: -1.6836612317031443\n",
      "Epoch: 828     Loss: -1.6838503538596974\n",
      "Epoch: 829     Loss: -1.6840475948590068\n",
      "Epoch: 830     Loss: -1.6842383602602684\n",
      "Epoch: 831     Loss: -1.684435456313185\n",
      "Epoch: 832     Loss: -1.684627570222737\n",
      "Epoch: 833     Loss: -1.6848246755573855\n",
      "Epoch: 834     Loss: -1.6850169499038354\n",
      "Epoch: 835     Loss: -1.6852136325676876\n",
      "Epoch: 836     Loss: -1.6854054217127767\n",
      "Epoch: 837     Loss: -1.685597845941121\n",
      "Epoch: 838     Loss: -1.68578531726527\n",
      "Epoch: 839     Loss: -1.685962168251892\n",
      "Epoch: 840     Loss: -1.686149324542567\n",
      "Epoch: 841     Loss: -1.686335249829475\n",
      "Epoch: 842     Loss: -1.6865218151122696\n",
      "Epoch: 843     Loss: -1.686706359053538\n",
      "Epoch: 844     Loss: -1.6868899871027965\n",
      "Epoch: 845     Loss: -1.6870636724241375\n",
      "Epoch: 846     Loss: -1.687247006134312\n",
      "Epoch: 847     Loss: -1.6874253093551204\n",
      "Epoch: 848     Loss: -1.6876103904624424\n",
      "Epoch: 849     Loss: -1.6877935734045058\n",
      "Epoch: 850     Loss: -1.6879831276024195\n",
      "Epoch: 851     Loss: -1.6881718277686917\n",
      "Epoch: 852     Loss: -1.6883644645651914\n",
      "Epoch: 853     Loss: -1.6885564040292333\n",
      "Epoch: 854     Loss: -1.6887515137669487\n",
      "Epoch: 855     Loss: -1.6889443917088203\n",
      "Epoch: 856     Loss: -1.6891380958933009\n",
      "Epoch: 857     Loss: -1.689327126086169\n",
      "Epoch: 858     Loss: -1.6895212033592248\n",
      "Epoch: 859     Loss: -1.6897101860498935\n",
      "Epoch: 860     Loss: -1.6899028711869737\n",
      "Epoch: 861     Loss: -1.6900863080467596\n",
      "Epoch: 862     Loss: -1.6902792038153305\n",
      "Epoch: 863     Loss: -1.6904641730624113\n",
      "Epoch: 864     Loss: -1.6906486608311866\n",
      "Epoch: 865     Loss: -1.6908241445097005\n",
      "Epoch: 866     Loss: -1.6909970657614195\n",
      "Epoch: 867     Loss: -1.6911738432280439\n",
      "Epoch: 868     Loss: -1.691337569589863\n",
      "Epoch: 869     Loss: -1.691504853066919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 870     Loss: -1.6916744561822663\n",
      "Epoch: 871     Loss: -1.6918556063837373\n",
      "Epoch: 872     Loss: -1.6920314417096765\n",
      "Epoch: 873     Loss: -1.6922157538670122\n",
      "Epoch: 874     Loss: -1.692394551575055\n",
      "Epoch: 875     Loss: -1.692578660371835\n",
      "Epoch: 876     Loss: -1.6927577698982466\n",
      "Epoch: 877     Loss: -1.6929415192995059\n",
      "Epoch: 878     Loss: -1.6931215556126964\n",
      "Epoch: 879     Loss: -1.6933051518311966\n",
      "Epoch: 880     Loss: -1.693485208177102\n",
      "Epoch: 881     Loss: -1.6936718492906484\n",
      "Epoch: 882     Loss: -1.6938589434478106\n",
      "Epoch: 883     Loss: -1.6940490114798272\n",
      "Epoch: 884     Loss: -1.6942360762012398\n",
      "Epoch: 885     Loss: -1.694424256898049\n",
      "Epoch: 886     Loss: -1.694603750498513\n",
      "Epoch: 887     Loss: -1.694787884797857\n",
      "Epoch: 888     Loss: -1.6949665156986433\n",
      "Epoch: 889     Loss: -1.6951549709829867\n",
      "Epoch: 890     Loss: -1.6953402186811497\n",
      "Epoch: 891     Loss: -1.6955265669287973\n",
      "Epoch: 892     Loss: -1.6957055972031048\n",
      "Epoch: 893     Loss: -1.695884486888844\n",
      "Epoch: 894     Loss: -1.696048575537938\n",
      "Epoch: 895     Loss: -1.6962225406387401\n",
      "Epoch: 896     Loss: -1.6963854164237915\n",
      "Epoch: 897     Loss: -1.696555391512428\n",
      "Epoch: 898     Loss: -1.6967222538583013\n",
      "Epoch: 899     Loss: -1.6968955831927037\n",
      "Epoch: 900     Loss: -1.6970699985729467\n",
      "Epoch: 901     Loss: -1.6972461816577493\n",
      "Epoch: 902     Loss: -1.697422897612367\n",
      "Epoch: 903     Loss: -1.6975921416066975\n",
      "Epoch: 904     Loss: -1.6977537035537926\n",
      "Epoch: 905     Loss: -1.6979202827657072\n",
      "Epoch: 906     Loss: -1.6980867711438048\n",
      "Epoch: 907     Loss: -1.6982531092157465\n",
      "Epoch: 908     Loss: -1.6984250847421531\n",
      "Epoch: 909     Loss: -1.6985838290096404\n",
      "Epoch: 910     Loss: -1.6987557588879885\n",
      "Epoch: 911     Loss: -1.6989224829051117\n",
      "Epoch: 912     Loss: -1.6990976950005272\n",
      "Epoch: 913     Loss: -1.6992709486712534\n",
      "Epoch: 914     Loss: -1.699451196706522\n",
      "Epoch: 915     Loss: -1.699628614083077\n",
      "Epoch: 916     Loss: -1.6998100730972237\n",
      "Epoch: 917     Loss: -1.6999889455226869\n",
      "Epoch: 918     Loss: -1.7001697270657754\n",
      "Epoch: 919     Loss: -1.700348520313284\n",
      "Epoch: 920     Loss: -1.7005292332523194\n",
      "Epoch: 921     Loss: -1.7007086177809323\n",
      "Epoch: 922     Loss: -1.7008894842616993\n",
      "Epoch: 923     Loss: -1.7010643928521596\n",
      "Epoch: 924     Loss: -1.7012391392967943\n",
      "Epoch: 925     Loss: -1.7014023174855128\n",
      "Epoch: 926     Loss: -1.701564022305737\n",
      "Epoch: 927     Loss: -1.7017217244825424\n",
      "Epoch: 928     Loss: -1.7018909164366123\n",
      "Epoch: 929     Loss: -1.7020565779510515\n",
      "Epoch: 930     Loss: -1.7022255659726855\n",
      "Epoch: 931     Loss: -1.7023895623976346\n",
      "Epoch: 932     Loss: -1.7025600301108748\n",
      "Epoch: 933     Loss: -1.7027296271277998\n",
      "Epoch: 934     Loss: -1.7028983131385258\n",
      "Epoch: 935     Loss: -1.7030636668344792\n",
      "Epoch: 936     Loss: -1.7032261338187185\n",
      "Epoch: 937     Loss: -1.7033849885709673\n",
      "Epoch: 938     Loss: -1.7035476779300178\n",
      "Epoch: 939     Loss: -1.7037150774696002\n",
      "Epoch: 940     Loss: -1.7038810490740735\n",
      "Epoch: 941     Loss: -1.7040511258757058\n",
      "Epoch: 942     Loss: -1.7042187546904322\n",
      "Epoch: 943     Loss: -1.7043839158910832\n",
      "Epoch: 944     Loss: -1.704543693204302\n",
      "Epoch: 945     Loss: -1.7047074198003915\n",
      "Epoch: 946     Loss: -1.7048680639075886\n",
      "Epoch: 947     Loss: -1.7050273545080998\n",
      "Epoch: 948     Loss: -1.7051833831467555\n",
      "Epoch: 949     Loss: -1.7053386969754525\n",
      "Epoch: 950     Loss: -1.7055011690260329\n",
      "Epoch: 951     Loss: -1.705661507534668\n",
      "Epoch: 952     Loss: -1.705825829588624\n",
      "Epoch: 953     Loss: -1.7059902912336737\n",
      "Epoch: 954     Loss: -1.7061556150105353\n",
      "Epoch: 955     Loss: -1.7063229737056174\n",
      "Epoch: 956     Loss: -1.7064901061394402\n",
      "Epoch: 957     Loss: -1.7066588386977053\n",
      "Epoch: 958     Loss: -1.706824456422345\n",
      "Epoch: 959     Loss: -1.7069929867373876\n",
      "Epoch: 960     Loss: -1.70715528421182\n",
      "Epoch: 961     Loss: -1.7073239422709963\n",
      "Epoch: 962     Loss: -1.7074858491799272\n",
      "Epoch: 963     Loss: -1.7076546260908085\n",
      "Epoch: 964     Loss: -1.7078155365829306\n",
      "Epoch: 965     Loss: -1.7079799383355037\n",
      "Epoch: 966     Loss: -1.7081328060771426\n",
      "Epoch: 967     Loss: -1.7082923930962144\n",
      "Epoch: 968     Loss: -1.7084368950544913\n",
      "Epoch: 969     Loss: -1.7085890601460694\n",
      "Epoch: 970     Loss: -1.708732233103399\n",
      "Epoch: 971     Loss: -1.7088907147232808\n",
      "Epoch: 972     Loss: -1.7090497843714156\n",
      "Epoch: 973     Loss: -1.7092168373032914\n",
      "Epoch: 974     Loss: -1.709382342787734\n",
      "Epoch: 975     Loss: -1.7095521420787618\n",
      "Epoch: 976     Loss: -1.709718891656266\n",
      "Epoch: 977     Loss: -1.7098874971122826\n",
      "Epoch: 978     Loss: -1.710049205074014\n",
      "Epoch: 979     Loss: -1.71021532098756\n",
      "Epoch: 980     Loss: -1.7103746240496758\n",
      "Epoch: 981     Loss: -1.710537086624518\n",
      "Epoch: 982     Loss: -1.7106916270727026\n",
      "Epoch: 983     Loss: -1.7108538336858625\n",
      "Epoch: 984     Loss: -1.7110082821241481\n",
      "Epoch: 985     Loss: -1.7111640879035175\n",
      "Epoch: 986     Loss: -1.7113111895545432\n",
      "Epoch: 987     Loss: -1.7114650935160949\n",
      "Epoch: 988     Loss: -1.7116145904725573\n",
      "Epoch: 989     Loss: -1.7117655215200385\n",
      "Epoch: 990     Loss: -1.711918788305585\n",
      "Epoch: 991     Loss: -1.7120736872558333\n",
      "Epoch: 992     Loss: -1.7122335554587476\n",
      "Epoch: 993     Loss: -1.7123906977853978\n",
      "Epoch: 994     Loss: -1.7125524507084349\n",
      "Epoch: 995     Loss: -1.712709331088453\n",
      "Epoch: 996     Loss: -1.7128707897997781\n",
      "Epoch: 997     Loss: -1.7130250072314746\n",
      "Epoch: 998     Loss: -1.7131843166352736\n",
      "Epoch: 999     Loss: -1.713336444069803\n",
      "Epoch: 1000     Loss: -1.7134953531520534\n",
      "Epoch: 1001     Loss: -1.7136432546052727\n",
      "Epoch: 1002     Loss: -1.7138033972553157\n",
      "Epoch: 1003     Loss: -1.7139554251643716\n",
      "Epoch: 1004     Loss: -1.7141181701800725\n",
      "Epoch: 1005     Loss: -1.714273424772312\n",
      "Epoch: 1006     Loss: -1.7144374668730407\n",
      "Epoch: 1007     Loss: -1.7145951411849536\n",
      "Epoch: 1008     Loss: -1.7147599494414447\n",
      "Epoch: 1009     Loss: -1.714919209432889\n",
      "Epoch: 1010     Loss: -1.7150840726823386\n",
      "Epoch: 1011     Loss: -1.7152440866745342\n",
      "Epoch: 1012     Loss: -1.7154084603241961\n",
      "Epoch: 1013     Loss: -1.7155661598599694\n",
      "Epoch: 1014     Loss: -1.7157231807341622\n",
      "Epoch: 1015     Loss: -1.7158738092181707\n",
      "Epoch: 1016     Loss: -1.716025951367877\n",
      "Epoch: 1017     Loss: -1.7161806326538875\n",
      "Epoch: 1018     Loss: -1.7163390587596123\n",
      "Epoch: 1019     Loss: -1.7164933642542854\n",
      "Epoch: 1020     Loss: -1.716651325693293\n",
      "Epoch: 1021     Loss: -1.7168062726906381\n",
      "Epoch: 1022     Loss: -1.7169612791370892\n",
      "Epoch: 1023     Loss: -1.7171155865909344\n",
      "Epoch: 1024     Loss: -1.717269854232268\n",
      "Epoch: 1025     Loss: -1.7174235950800543\n",
      "Epoch: 1026     Loss: -1.7175744556084067\n",
      "Epoch: 1027     Loss: -1.717726559530955\n",
      "Epoch: 1028     Loss: -1.7178777843744284\n",
      "Epoch: 1029     Loss: -1.7180283161215604\n",
      "Epoch: 1030     Loss: -1.7181776510262763\n",
      "Epoch: 1031     Loss: -1.7183251491408222\n",
      "Epoch: 1032     Loss: -1.7184681208563741\n",
      "Epoch: 1033     Loss: -1.7186054133200261\n",
      "Epoch: 1034     Loss: -1.7187421166380163\n",
      "Epoch: 1035     Loss: -1.7188799298185236\n",
      "Epoch: 1036     Loss: -1.7190240779598636\n",
      "Epoch: 1037     Loss: -1.7191688561371075\n",
      "Epoch: 1038     Loss: -1.7193190369123665\n",
      "Epoch: 1039     Loss: -1.7194663116142943\n",
      "Epoch: 1040     Loss: -1.719614805664207\n",
      "Epoch: 1041     Loss: -1.719754745793466\n",
      "Epoch: 1042     Loss: -1.7198843183749815\n",
      "Epoch: 1043     Loss: -1.720022595214097\n",
      "Epoch: 1044     Loss: -1.720167288368306\n",
      "Epoch: 1045     Loss: -1.7203097610672122\n",
      "Epoch: 1046     Loss: -1.720452393341021\n",
      "Epoch: 1047     Loss: -1.7206037987564722\n",
      "Epoch: 1048     Loss: -1.7207565455027378\n",
      "Epoch: 1049     Loss: -1.7209109601101784\n",
      "Epoch: 1050     Loss: -1.7210632234171932\n",
      "Epoch: 1051     Loss: -1.7212172151970786\n",
      "Epoch: 1052     Loss: -1.7213682256956262\n",
      "Epoch: 1053     Loss: -1.721523514049892\n",
      "Epoch: 1054     Loss: -1.7216753385062593\n",
      "Epoch: 1055     Loss: -1.721826786668499\n",
      "Epoch: 1056     Loss: -1.721973571205981\n",
      "Epoch: 1057     Loss: -1.722121966439046\n",
      "Epoch: 1058     Loss: -1.7222671857700724\n",
      "Epoch: 1059     Loss: -1.7224169886128307\n",
      "Epoch: 1060     Loss: -1.722565778914569\n",
      "Epoch: 1061     Loss: -1.7227176031983287\n",
      "Epoch: 1062     Loss: -1.7228656830533486\n",
      "Epoch: 1063     Loss: -1.7230138194313247\n",
      "Epoch: 1064     Loss: -1.7231540335481637\n",
      "Epoch: 1065     Loss: -1.723299480518473\n",
      "Epoch: 1066     Loss: -1.7234402364135668\n",
      "Epoch: 1067     Loss: -1.723584276819462\n",
      "Epoch: 1068     Loss: -1.7237195272597587\n",
      "Epoch: 1069     Loss: -1.723861008276027\n",
      "Epoch: 1070     Loss: -1.7240028692686928\n",
      "Epoch: 1071     Loss: -1.7241489175588889\n",
      "Epoch: 1072     Loss: -1.724293421025109\n",
      "Epoch: 1073     Loss: -1.7244424900473883\n",
      "Epoch: 1074     Loss: -1.7245908701263641\n",
      "Epoch: 1075     Loss: -1.7247414680149415\n",
      "Epoch: 1076     Loss: -1.7248897374600318\n",
      "Epoch: 1077     Loss: -1.7250398727764535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1078     Loss: -1.7251864093478964\n",
      "Epoch: 1079     Loss: -1.7253348274206322\n",
      "Epoch: 1080     Loss: -1.725478281227124\n",
      "Epoch: 1081     Loss: -1.7256241111515769\n",
      "Epoch: 1082     Loss: -1.725766317480244\n",
      "Epoch: 1083     Loss: -1.7259127851499705\n",
      "Epoch: 1084     Loss: -1.7260586607721848\n",
      "Epoch: 1085     Loss: -1.726208169534482\n",
      "Epoch: 1086     Loss: -1.7263535056647281\n",
      "Epoch: 1087     Loss: -1.7264991385621804\n",
      "Epoch: 1088     Loss: -1.7266438512698472\n",
      "Epoch: 1089     Loss: -1.726790081770068\n",
      "Epoch: 1090     Loss: -1.7269322325385181\n",
      "Epoch: 1091     Loss: -1.727076837445426\n",
      "Epoch: 1092     Loss: -1.7272195806846813\n",
      "Epoch: 1093     Loss: -1.7273629340485415\n",
      "Epoch: 1094     Loss: -1.7275059098350882\n",
      "Epoch: 1095     Loss: -1.7276481761332252\n",
      "Epoch: 1096     Loss: -1.7277877185456845\n",
      "Epoch: 1097     Loss: -1.7279210130060727\n",
      "Epoch: 1098     Loss: -1.7280548953611992\n",
      "Epoch: 1099     Loss: -1.72818411579971\n",
      "Epoch: 1100     Loss: -1.728318914034983\n",
      "Epoch: 1101     Loss: -1.7284497823973242\n",
      "Epoch: 1102     Loss: -1.7285862723197776\n",
      "Epoch: 1103     Loss: -1.7287186524346763\n",
      "Epoch: 1104     Loss: -1.7288532163672878\n",
      "Epoch: 1105     Loss: -1.7289761605099931\n",
      "Epoch: 1106     Loss: -1.7290960621610318\n",
      "Epoch: 1107     Loss: -1.7292341190392841\n",
      "Epoch: 1108     Loss: -1.7293721990590778\n",
      "Epoch: 1109     Loss: -1.7295102211204474\n",
      "Epoch: 1110     Loss: -1.7296485703189814\n",
      "Epoch: 1111     Loss: -1.7297884854891705\n",
      "Epoch: 1112     Loss: -1.729927982952433\n",
      "Epoch: 1113     Loss: -1.730070367112802\n",
      "Epoch: 1114     Loss: -1.7302063153930998\n",
      "Epoch: 1115     Loss: -1.7303514810544542\n",
      "Epoch: 1116     Loss: -1.730492300481257\n",
      "Epoch: 1117     Loss: -1.7306382551559292\n",
      "Epoch: 1118     Loss: -1.7307821078222347\n",
      "Epoch: 1119     Loss: -1.730927455615336\n",
      "Epoch: 1120     Loss: -1.731067910467812\n",
      "Epoch: 1121     Loss: -1.7312100104058419\n",
      "Epoch: 1122     Loss: -1.731346817960423\n",
      "Epoch: 1123     Loss: -1.7314842687055003\n",
      "Epoch: 1124     Loss: -1.731614665231469\n",
      "Epoch: 1125     Loss: -1.7317432738150524\n",
      "Epoch: 1126     Loss: -1.7318748189421669\n",
      "Epoch: 1127     Loss: -1.7320110003946283\n",
      "Epoch: 1128     Loss: -1.732151258394691\n",
      "Epoch: 1129     Loss: -1.7322932291044961\n",
      "Epoch: 1130     Loss: -1.7324367699062728\n",
      "Epoch: 1131     Loss: -1.732579876316631\n",
      "Epoch: 1132     Loss: -1.7327226784823533\n",
      "Epoch: 1133     Loss: -1.7328639864468744\n",
      "Epoch: 1134     Loss: -1.7330047350040643\n",
      "Epoch: 1135     Loss: -1.7331438743588017\n",
      "Epoch: 1136     Loss: -1.7332819520862766\n",
      "Epoch: 1137     Loss: -1.733415704281887\n",
      "Epoch: 1138     Loss: -1.733548935916765\n",
      "Epoch: 1139     Loss: -1.733681928541995\n",
      "Epoch: 1140     Loss: -1.73381684254727\n",
      "Epoch: 1141     Loss: -1.7339466453558157\n",
      "Epoch: 1142     Loss: -1.734079953271241\n",
      "Epoch: 1143     Loss: -1.7342143056239305\n",
      "Epoch: 1144     Loss: -1.7343488168806374\n",
      "Epoch: 1145     Loss: -1.7344821862941624\n",
      "Epoch: 1146     Loss: -1.7346150999820982\n",
      "Epoch: 1147     Loss: -1.7347497141466766\n",
      "Epoch: 1148     Loss: -1.7348796397819053\n",
      "Epoch: 1149     Loss: -1.73501208676948\n",
      "Epoch: 1150     Loss: -1.735134526565817\n",
      "Epoch: 1151     Loss: -1.7352632433998256\n",
      "Epoch: 1152     Loss: -1.7353815381211732\n",
      "Epoch: 1153     Loss: -1.7355136614926239\n",
      "Epoch: 1154     Loss: -1.7356452541927647\n",
      "Epoch: 1155     Loss: -1.7357819608734708\n",
      "Epoch: 1156     Loss: -1.735915610221388\n",
      "Epoch: 1157     Loss: -1.7360498073468869\n",
      "Epoch: 1158     Loss: -1.7361831075226413\n",
      "Epoch: 1159     Loss: -1.7363171750665847\n",
      "Epoch: 1160     Loss: -1.7364450180698248\n",
      "Epoch: 1161     Loss: -1.736574708548336\n",
      "Epoch: 1162     Loss: -1.7367051367532405\n",
      "Epoch: 1163     Loss: -1.736838256946464\n",
      "Epoch: 1164     Loss: -1.7369690676518106\n",
      "Epoch: 1165     Loss: -1.7371019527724283\n",
      "Epoch: 1166     Loss: -1.7372345015372228\n",
      "Epoch: 1167     Loss: -1.7373689731732416\n",
      "Epoch: 1168     Loss: -1.7375036282754164\n",
      "Epoch: 1169     Loss: -1.7376397928350393\n",
      "Epoch: 1170     Loss: -1.7377759846998944\n",
      "Epoch: 1171     Loss: -1.7379127878539429\n",
      "Epoch: 1172     Loss: -1.7380469565698577\n",
      "Epoch: 1173     Loss: -1.738179947260075\n",
      "Epoch: 1174     Loss: -1.7383063603120026\n",
      "Epoch: 1175     Loss: -1.7384321475322624\n",
      "Epoch: 1176     Loss: -1.7385521755889113\n",
      "Epoch: 1177     Loss: -1.7386790098888998\n",
      "Epoch: 1178     Loss: -1.7388030443402103\n",
      "Epoch: 1179     Loss: -1.7389306694964528\n",
      "Epoch: 1180     Loss: -1.7390569706460237\n",
      "Epoch: 1181     Loss: -1.7391837338724803\n",
      "Epoch: 1182     Loss: -1.739310235854883\n",
      "Epoch: 1183     Loss: -1.7394364765842063\n",
      "Epoch: 1184     Loss: -1.7395581828584727\n",
      "Epoch: 1185     Loss: -1.7396821041336197\n",
      "Epoch: 1186     Loss: -1.7398036336682503\n",
      "Epoch: 1187     Loss: -1.7399310674031898\n",
      "Epoch: 1188     Loss: -1.7400572388133484\n",
      "Epoch: 1189     Loss: -1.7401870230797079\n",
      "Epoch: 1190     Loss: -1.740317819280417\n",
      "Epoch: 1191     Loss: -1.7404500887077468\n",
      "Epoch: 1192     Loss: -1.7405821472673304\n",
      "Epoch: 1193     Loss: -1.7407153801427866\n",
      "Epoch: 1194     Loss: -1.7408487198786742\n",
      "Epoch: 1195     Loss: -1.7409809279776591\n",
      "Epoch: 1196     Loss: -1.7411122974287025\n",
      "Epoch: 1197     Loss: -1.7412423263273915\n",
      "Epoch: 1198     Loss: -1.74137476665792\n",
      "Epoch: 1199     Loss: -1.7415051862942776\n",
      "Epoch: 1200     Loss: -1.7416356961357276\n",
      "Epoch: 1201     Loss: -1.7417619548415426\n",
      "Epoch: 1202     Loss: -1.7418908460193994\n",
      "Epoch: 1203     Loss: -1.7420155468662981\n",
      "Epoch: 1204     Loss: -1.7421399975719842\n",
      "Epoch: 1205     Loss: -1.7422621769811044\n",
      "Epoch: 1206     Loss: -1.7423860905161894\n",
      "Epoch: 1207     Loss: -1.7425106743711933\n",
      "Epoch: 1208     Loss: -1.7426357761854134\n",
      "Epoch: 1209     Loss: -1.7427633318839293\n",
      "Epoch: 1210     Loss: -1.74289177153543\n",
      "Epoch: 1211     Loss: -1.743022535975429\n",
      "Epoch: 1212     Loss: -1.7431519458071705\n",
      "Epoch: 1213     Loss: -1.7432817151032036\n",
      "Epoch: 1214     Loss: -1.7434072071311812\n",
      "Epoch: 1215     Loss: -1.7435330560876308\n",
      "Epoch: 1216     Loss: -1.743656949420647\n",
      "Epoch: 1217     Loss: -1.7437830158700425\n",
      "Epoch: 1218     Loss: -1.7439053928113855\n",
      "Epoch: 1219     Loss: -1.7440344054926789\n",
      "Epoch: 1220     Loss: -1.7441588402047563\n",
      "Epoch: 1221     Loss: -1.7442873520813225\n",
      "Epoch: 1222     Loss: -1.744412988304178\n",
      "Epoch: 1223     Loss: -1.744544334701551\n",
      "Epoch: 1224     Loss: -1.7446715528963483\n",
      "Epoch: 1225     Loss: -1.7448003502767877\n",
      "Epoch: 1226     Loss: -1.7449257424958025\n",
      "Epoch: 1227     Loss: -1.7450546107839144\n",
      "Epoch: 1228     Loss: -1.7451775238348517\n",
      "Epoch: 1229     Loss: -1.7453001941979918\n",
      "Epoch: 1230     Loss: -1.7454160289748797\n",
      "Epoch: 1231     Loss: -1.7455311966967355\n",
      "Epoch: 1232     Loss: -1.7456373816121769\n",
      "Epoch: 1233     Loss: -1.7457533934213454\n",
      "Epoch: 1234     Loss: -1.745871794796787\n",
      "Epoch: 1235     Loss: -1.7459972668393822\n",
      "Epoch: 1236     Loss: -1.7461225631731094\n",
      "Epoch: 1237     Loss: -1.7462512180570513\n",
      "Epoch: 1238     Loss: -1.7463782158488022\n",
      "Epoch: 1239     Loss: -1.7465064495087368\n",
      "Epoch: 1240     Loss: -1.7466314303528399\n",
      "Epoch: 1241     Loss: -1.7467587222052805\n",
      "Epoch: 1242     Loss: -1.7468828859715753\n",
      "Epoch: 1243     Loss: -1.7470108791481949\n",
      "Epoch: 1244     Loss: -1.7471358106365245\n",
      "Epoch: 1245     Loss: -1.7472635705783772\n",
      "Epoch: 1246     Loss: -1.7473864055158987\n",
      "Epoch: 1247     Loss: -1.7475109096209525\n",
      "Epoch: 1248     Loss: -1.7476272893978404\n",
      "Epoch: 1249     Loss: -1.747745266439661\n",
      "Epoch: 1250     Loss: -1.7478536160061777\n",
      "Epoch: 1251     Loss: -1.747967711299505\n",
      "Epoch: 1252     Loss: -1.7480753300210043\n",
      "Epoch: 1253     Loss: -1.7481921696467873\n",
      "Epoch: 1254     Loss: -1.7483078415711866\n",
      "Epoch: 1255     Loss: -1.748428908302283\n",
      "Epoch: 1256     Loss: -1.7485498116779823\n",
      "Epoch: 1257     Loss: -1.7486720262805067\n",
      "Epoch: 1258     Loss: -1.7487932434345779\n",
      "Epoch: 1259     Loss: -1.7489155526394282\n",
      "Epoch: 1260     Loss: -1.7490389286389905\n",
      "Epoch: 1261     Loss: -1.7491626887133334\n",
      "Epoch: 1262     Loss: -1.7492870578089112\n",
      "Epoch: 1263     Loss: -1.7494102919999595\n",
      "Epoch: 1264     Loss: -1.7495344304534235\n",
      "Epoch: 1265     Loss: -1.7496573785117924\n",
      "Epoch: 1266     Loss: -1.7497834624336708\n",
      "Epoch: 1267     Loss: -1.7499080721697693\n",
      "Epoch: 1268     Loss: -1.7500340545622137\n",
      "Epoch: 1269     Loss: -1.7501569361886609\n",
      "Epoch: 1270     Loss: -1.750278947316199\n",
      "Epoch: 1271     Loss: -1.7503988512346633\n",
      "Epoch: 1272     Loss: -1.7505170168488264\n",
      "Epoch: 1273     Loss: -1.750635548740707\n",
      "Epoch: 1274     Loss: -1.75075700030795\n",
      "Epoch: 1275     Loss: -1.750875777776034\n",
      "Epoch: 1276     Loss: -1.7509969765268356\n",
      "Epoch: 1277     Loss: -1.7511158246668375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1278     Loss: -1.7512356309700148\n",
      "Epoch: 1279     Loss: -1.7513495227985671\n",
      "Epoch: 1280     Loss: -1.7514648624378837\n",
      "Epoch: 1281     Loss: -1.7515754112395545\n",
      "Epoch: 1282     Loss: -1.751691109838026\n",
      "Epoch: 1283     Loss: -1.7518040125844743\n",
      "Epoch: 1284     Loss: -1.7519213815098416\n",
      "Epoch: 1285     Loss: -1.7520376096596533\n",
      "Epoch: 1286     Loss: -1.7521563807146217\n",
      "Epoch: 1287     Loss: -1.7522758176324156\n",
      "Epoch: 1288     Loss: -1.752398023237621\n",
      "Epoch: 1289     Loss: -1.7525187867389207\n",
      "Epoch: 1290     Loss: -1.7526419170361827\n",
      "Epoch: 1291     Loss: -1.7527630701383223\n",
      "Epoch: 1292     Loss: -1.7528872866037963\n",
      "Epoch: 1293     Loss: -1.7530085011601275\n",
      "Epoch: 1294     Loss: -1.7531294098388461\n",
      "Epoch: 1295     Loss: -1.753248116083868\n",
      "Epoch: 1296     Loss: -1.7533679501930919\n",
      "Epoch: 1297     Loss: -1.7534849412511402\n",
      "Epoch: 1298     Loss: -1.7536011136951124\n",
      "Epoch: 1299     Loss: -1.7537111127333784\n",
      "Epoch: 1300     Loss: -1.753819498723183\n",
      "Epoch: 1301     Loss: -1.7539275328735164\n",
      "Epoch: 1302     Loss: -1.754037000571653\n",
      "Epoch: 1303     Loss: -1.7541514624666985\n",
      "Epoch: 1304     Loss: -1.7542656013706486\n",
      "Epoch: 1305     Loss: -1.754383617402151\n",
      "Epoch: 1306     Loss: -1.7544989189548397\n",
      "Epoch: 1307     Loss: -1.7546172947013863\n",
      "Epoch: 1308     Loss: -1.7547327355577131\n",
      "Epoch: 1309     Loss: -1.754851058714237\n",
      "Epoch: 1310     Loss: -1.7549653827463307\n",
      "Epoch: 1311     Loss: -1.7550785673707043\n",
      "Epoch: 1312     Loss: -1.7551916516909298\n",
      "Epoch: 1313     Loss: -1.755301984037816\n",
      "Epoch: 1314     Loss: -1.7554152860158447\n",
      "Epoch: 1315     Loss: -1.7555262758206485\n",
      "Epoch: 1316     Loss: -1.755638017360777\n",
      "Epoch: 1317     Loss: -1.755749785738537\n",
      "Epoch: 1318     Loss: -1.7558631057294287\n",
      "Epoch: 1319     Loss: -1.7559755665805927\n",
      "Epoch: 1320     Loss: -1.7560837930099211\n",
      "Epoch: 1321     Loss: -1.756192996207064\n",
      "Epoch: 1322     Loss: -1.7563024207142883\n",
      "Epoch: 1323     Loss: -1.756414156561505\n",
      "Epoch: 1324     Loss: -1.75652334199799\n",
      "Epoch: 1325     Loss: -1.7566368890849735\n",
      "Epoch: 1326     Loss: -1.7567456190405402\n",
      "Epoch: 1327     Loss: -1.7568595955031843\n",
      "Epoch: 1328     Loss: -1.7569684117412963\n",
      "Epoch: 1329     Loss: -1.7570837605199663\n",
      "Epoch: 1330     Loss: -1.7571964607341926\n",
      "Epoch: 1331     Loss: -1.7573134320429202\n",
      "Epoch: 1332     Loss: -1.7574276981372063\n",
      "Epoch: 1333     Loss: -1.7575446085641264\n",
      "Epoch: 1334     Loss: -1.757660364891314\n",
      "Epoch: 1335     Loss: -1.7577780592353622\n",
      "Epoch: 1336     Loss: -1.757893880780868\n",
      "Epoch: 1337     Loss: -1.7580109746837465\n",
      "Epoch: 1338     Loss: -1.7581279491849355\n",
      "Epoch: 1339     Loss: -1.758242797761363\n",
      "Epoch: 1340     Loss: -1.7583548808204545\n",
      "Epoch: 1341     Loss: -1.7584634292978576\n",
      "Epoch: 1342     Loss: -1.758578883825347\n",
      "Epoch: 1343     Loss: -1.7586917228419194\n",
      "Epoch: 1344     Loss: -1.758805753134751\n",
      "Epoch: 1345     Loss: -1.758915670659823\n",
      "Epoch: 1346     Loss: -1.7590289191066708\n",
      "Epoch: 1347     Loss: -1.7591395792184361\n",
      "Epoch: 1348     Loss: -1.7592533251198268\n",
      "Epoch: 1349     Loss: -1.759365330276681\n",
      "Epoch: 1350     Loss: -1.7594784334718134\n",
      "Epoch: 1351     Loss: -1.7595881843295167\n",
      "Epoch: 1352     Loss: -1.7596927702234784\n",
      "Epoch: 1353     Loss: -1.7598009961862295\n",
      "Epoch: 1354     Loss: -1.7599094077778652\n",
      "Epoch: 1355     Loss: -1.7600206807970735\n",
      "Epoch: 1356     Loss: -1.7601338781317781\n",
      "Epoch: 1357     Loss: -1.7602470195337019\n",
      "Epoch: 1358     Loss: -1.760360704036856\n",
      "Epoch: 1359     Loss: -1.76047336665557\n",
      "Epoch: 1360     Loss: -1.7605848122664551\n",
      "Epoch: 1361     Loss: -1.7606946470430578\n",
      "Epoch: 1362     Loss: -1.7608019706134623\n",
      "Epoch: 1363     Loss: -1.7609081852690627\n",
      "Epoch: 1364     Loss: -1.7610102622624544\n",
      "Epoch: 1365     Loss: -1.7611130833767707\n",
      "Epoch: 1366     Loss: -1.7612134281122376\n",
      "Epoch: 1367     Loss: -1.7613163084697845\n",
      "Epoch: 1368     Loss: -1.76142017767772\n",
      "Epoch: 1369     Loss: -1.761528297624847\n",
      "Epoch: 1370     Loss: -1.7616369213407368\n",
      "Epoch: 1371     Loss: -1.7617476376936858\n",
      "Epoch: 1372     Loss: -1.7618581209206456\n",
      "Epoch: 1373     Loss: -1.7619704852197242\n",
      "Epoch: 1374     Loss: -1.7620831821410166\n",
      "Epoch: 1375     Loss: -1.7621960431649402\n",
      "Epoch: 1376     Loss: -1.7623072845075218\n",
      "Epoch: 1377     Loss: -1.762417108888721\n",
      "Epoch: 1378     Loss: -1.7625281239448858\n",
      "Epoch: 1379     Loss: -1.762635144495895\n",
      "Epoch: 1380     Loss: -1.7627455617857117\n",
      "Epoch: 1381     Loss: -1.7628543315991632\n",
      "Epoch: 1382     Loss: -1.7629672088908692\n",
      "Epoch: 1383     Loss: -1.763076209423921\n",
      "Epoch: 1384     Loss: -1.7631862565191567\n",
      "Epoch: 1385     Loss: -1.7632929333517926\n",
      "Epoch: 1386     Loss: -1.7634029749781628\n",
      "Epoch: 1387     Loss: -1.7635088819118496\n",
      "Epoch: 1388     Loss: -1.7636177108267275\n",
      "Epoch: 1389     Loss: -1.7637228534481304\n",
      "Epoch: 1390     Loss: -1.7638297214236596\n",
      "Epoch: 1391     Loss: -1.7639324817314994\n",
      "Epoch: 1392     Loss: -1.7640386049858596\n",
      "Epoch: 1393     Loss: -1.7641449767877042\n",
      "Epoch: 1394     Loss: -1.7642535398213472\n",
      "Epoch: 1395     Loss: -1.7643620276487955\n",
      "Epoch: 1396     Loss: -1.764470322910897\n",
      "Epoch: 1397     Loss: -1.7645783719721868\n",
      "Epoch: 1398     Loss: -1.7646879624853689\n",
      "Epoch: 1399     Loss: -1.7647975748844071\n",
      "Epoch: 1400     Loss: -1.7649063325230054\n",
      "Epoch: 1401     Loss: -1.7650148218456574\n",
      "Epoch: 1402     Loss: -1.7651228377145778\n",
      "Epoch: 1403     Loss: -1.7652290039682044\n",
      "Epoch: 1404     Loss: -1.7653311768400095\n",
      "Epoch: 1405     Loss: -1.7654314197684555\n",
      "Epoch: 1406     Loss: -1.7655302999152362\n",
      "Epoch: 1407     Loss: -1.7656294021149124\n",
      "Epoch: 1408     Loss: -1.7657275234372114\n",
      "Epoch: 1409     Loss: -1.7658264788506066\n",
      "Epoch: 1410     Loss: -1.7659259615239373\n",
      "Epoch: 1411     Loss: -1.7660284810241953\n",
      "Epoch: 1412     Loss: -1.7661300279060987\n",
      "Epoch: 1413     Loss: -1.766235052199669\n",
      "Epoch: 1414     Loss: -1.7663403434155398\n",
      "Epoch: 1415     Loss: -1.7664459299253834\n",
      "Epoch: 1416     Loss: -1.7665517753158224\n",
      "Epoch: 1417     Loss: -1.7666588284772975\n",
      "Epoch: 1418     Loss: -1.766766760234052\n",
      "Epoch: 1419     Loss: -1.7668731290698514\n",
      "Epoch: 1420     Loss: -1.7669811246641827\n",
      "Epoch: 1421     Loss: -1.7670877286638615\n",
      "Epoch: 1422     Loss: -1.7671961814436385\n",
      "Epoch: 1423     Loss: -1.7673031813598095\n",
      "Epoch: 1424     Loss: -1.7674114746385985\n",
      "Epoch: 1425     Loss: -1.7675182354964656\n",
      "Epoch: 1426     Loss: -1.7676255430810772\n",
      "Epoch: 1427     Loss: -1.767730846243376\n",
      "Epoch: 1428     Loss: -1.7678369395419307\n",
      "Epoch: 1429     Loss: -1.767942121161941\n",
      "Epoch: 1430     Loss: -1.768048044391499\n",
      "Epoch: 1431     Loss: -1.768151578910988\n",
      "Epoch: 1432     Loss: -1.76825493997254\n",
      "Epoch: 1433     Loss: -1.7683541900294901\n",
      "Epoch: 1434     Loss: -1.7684582696905375\n",
      "Epoch: 1435     Loss: -1.7685580776422842\n",
      "Epoch: 1436     Loss: -1.7686587749985878\n",
      "Epoch: 1437     Loss: -1.768755658459138\n",
      "Epoch: 1438     Loss: -1.7688589888855748\n",
      "Epoch: 1439     Loss: -1.7689586232173586\n",
      "Epoch: 1440     Loss: -1.76905883553731\n",
      "Epoch: 1441     Loss: -1.769158152998612\n",
      "Epoch: 1442     Loss: -1.7692611211304525\n",
      "Epoch: 1443     Loss: -1.7693638538372016\n",
      "Epoch: 1444     Loss: -1.7694707364090578\n",
      "Epoch: 1445     Loss: -1.7695777056135764\n",
      "Epoch: 1446     Loss: -1.7696860500898515\n",
      "Epoch: 1447     Loss: -1.7697938940616877\n",
      "Epoch: 1448     Loss: -1.7699011636919757\n",
      "Epoch: 1449     Loss: -1.7700074217394701\n",
      "Epoch: 1450     Loss: -1.770111632909862\n",
      "Epoch: 1451     Loss: -1.770214885763228\n",
      "Epoch: 1452     Loss: -1.770315890156385\n",
      "Epoch: 1453     Loss: -1.7704162532054246\n",
      "Epoch: 1454     Loss: -1.7705153291559805\n",
      "Epoch: 1455     Loss: -1.7706158809437524\n",
      "Epoch: 1456     Loss: -1.7707160636047417\n",
      "Epoch: 1457     Loss: -1.7708183470466095\n",
      "Epoch: 1458     Loss: -1.770919944903327\n",
      "Epoch: 1459     Loss: -1.7710240759173308\n",
      "Epoch: 1460     Loss: -1.7711270209512215\n",
      "Epoch: 1461     Loss: -1.771231840517041\n",
      "Epoch: 1462     Loss: -1.7713347889722675\n",
      "Epoch: 1463     Loss: -1.771438592654976\n",
      "Epoch: 1464     Loss: -1.7715391371437206\n",
      "Epoch: 1465     Loss: -1.7716387833692957\n",
      "Epoch: 1466     Loss: -1.7717332938729637\n",
      "Epoch: 1467     Loss: -1.7718274457367527\n",
      "Epoch: 1468     Loss: -1.7719184739969651\n",
      "Epoch: 1469     Loss: -1.7720129278346854\n",
      "Epoch: 1470     Loss: -1.772110139217956\n",
      "Epoch: 1471     Loss: -1.7722075404028608\n",
      "Epoch: 1472     Loss: -1.7723044019237633\n",
      "Epoch: 1473     Loss: -1.7724019580288706\n",
      "Epoch: 1474     Loss: -1.7724996904958867\n",
      "Epoch: 1475     Loss: -1.7725950672916495\n",
      "Epoch: 1476     Loss: -1.772692553373292\n",
      "Epoch: 1477     Loss: -1.7727901927936436\n",
      "Epoch: 1478     Loss: -1.7728916983284628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1479     Loss: -1.7729931307027935\n",
      "Epoch: 1480     Loss: -1.773097022791218\n",
      "Epoch: 1481     Loss: -1.773200173811111\n",
      "Epoch: 1482     Loss: -1.7733046176755243\n",
      "Epoch: 1483     Loss: -1.773407606388429\n",
      "Epoch: 1484     Loss: -1.7735109638904611\n",
      "Epoch: 1485     Loss: -1.7736120762466017\n",
      "Epoch: 1486     Loss: -1.7737128859724145\n",
      "Epoch: 1487     Loss: -1.7738111492640118\n",
      "Epoch: 1488     Loss: -1.773909573939954\n",
      "Epoch: 1489     Loss: -1.7740064884034634\n",
      "Epoch: 1490     Loss: -1.7741048201185068\n",
      "Epoch: 1491     Loss: -1.774202211104007\n",
      "Epoch: 1492     Loss: -1.7743013276468422\n",
      "Epoch: 1493     Loss: -1.7743987930861629\n",
      "Epoch: 1494     Loss: -1.774498262970647\n",
      "Epoch: 1495     Loss: -1.774594975042474\n",
      "Epoch: 1496     Loss: -1.7746945919863397\n",
      "Epoch: 1497     Loss: -1.7747905154864476\n",
      "Epoch: 1498     Loss: -1.7748901325458513\n",
      "Epoch: 1499     Loss: -1.7749856870330618\n",
      "Epoch: 1500     Loss: -1.7750850058214516\n",
      "Epoch: 1501     Loss: -1.7751799879799326\n",
      "Epoch: 1502     Loss: -1.775279192096279\n",
      "Epoch: 1503     Loss: -1.775374232335574\n",
      "Epoch: 1504     Loss: -1.7754738470454863\n",
      "Epoch: 1505     Loss: -1.7755699249241443\n",
      "Epoch: 1506     Loss: -1.7756698554410442\n",
      "Epoch: 1507     Loss: -1.775764993910847\n",
      "Epoch: 1508     Loss: -1.7758630359527239\n",
      "Epoch: 1509     Loss: -1.7759574783498853\n",
      "Epoch: 1510     Loss: -1.7760564492433164\n",
      "Epoch: 1511     Loss: -1.7761520974303378\n",
      "Epoch: 1512     Loss: -1.7762495581084514\n",
      "Epoch: 1513     Loss: -1.7763457240564602\n",
      "Epoch: 1514     Loss: -1.7764443532086678\n",
      "Epoch: 1515     Loss: -1.776541100007076\n",
      "Epoch: 1516     Loss: -1.776637536821958\n",
      "Epoch: 1517     Loss: -1.7767322657017108\n",
      "Epoch: 1518     Loss: -1.7768253654440347\n",
      "Epoch: 1519     Loss: -1.7769199679371284\n",
      "Epoch: 1520     Loss: -1.7770158060218708\n",
      "Epoch: 1521     Loss: -1.7771118619072332\n",
      "Epoch: 1522     Loss: -1.777209468859469\n",
      "Epoch: 1523     Loss: -1.7773054763460077\n",
      "Epoch: 1524     Loss: -1.7774013120264882\n",
      "Epoch: 1525     Loss: -1.7774955876009273\n",
      "Epoch: 1526     Loss: -1.7775909871385198\n",
      "Epoch: 1527     Loss: -1.7776857146136582\n",
      "Epoch: 1528     Loss: -1.7777825205584235\n",
      "Epoch: 1529     Loss: -1.7778792233986995\n",
      "Epoch: 1530     Loss: -1.77797680506911\n",
      "Epoch: 1531     Loss: -1.7780746539455317\n",
      "Epoch: 1532     Loss: -1.77817320880044\n",
      "Epoch: 1533     Loss: -1.778271669325153\n",
      "Epoch: 1534     Loss: -1.7783702413470144\n",
      "Epoch: 1535     Loss: -1.7784681685149009\n",
      "Epoch: 1536     Loss: -1.7785660526430345\n",
      "Epoch: 1537     Loss: -1.7786627924589866\n",
      "Epoch: 1538     Loss: -1.7787578962257815\n",
      "Epoch: 1539     Loss: -1.7788539053196146\n",
      "Epoch: 1540     Loss: -1.7789507722857034\n",
      "Epoch: 1541     Loss: -1.7790480813900706\n",
      "Epoch: 1542     Loss: -1.7791431423569735\n",
      "Epoch: 1543     Loss: -1.779239853220179\n",
      "Epoch: 1544     Loss: -1.7793351038695613\n",
      "Epoch: 1545     Loss: -1.7794332869840397\n",
      "Epoch: 1546     Loss: -1.7795287069358197\n",
      "Epoch: 1547     Loss: -1.7796254522142165\n",
      "Epoch: 1548     Loss: -1.7797190256670912\n",
      "Epoch: 1549     Loss: -1.7798148459307925\n",
      "Epoch: 1550     Loss: -1.779906265754042\n",
      "Epoch: 1551     Loss: -1.7799995444804366\n",
      "Epoch: 1552     Loss: -1.7800892038299505\n",
      "Epoch: 1553     Loss: -1.780180779856637\n",
      "Epoch: 1554     Loss: -1.7802696269349954\n",
      "Epoch: 1555     Loss: -1.7803597243244655\n",
      "Epoch: 1556     Loss: -1.7804490858150552\n",
      "Epoch: 1557     Loss: -1.7805402135523263\n",
      "Epoch: 1558     Loss: -1.780633020286101\n",
      "Epoch: 1559     Loss: -1.7807263500724717\n",
      "Epoch: 1560     Loss: -1.78082041629047\n",
      "Epoch: 1561     Loss: -1.7809136853731702\n",
      "Epoch: 1562     Loss: -1.7810072968639246\n",
      "Epoch: 1563     Loss: -1.7810997545009215\n",
      "Epoch: 1564     Loss: -1.7811915048205111\n",
      "Epoch: 1565     Loss: -1.7812814672517199\n",
      "Epoch: 1566     Loss: -1.7813716225382297\n",
      "Epoch: 1567     Loss: -1.7814629478046962\n",
      "Epoch: 1568     Loss: -1.7815547051587834\n",
      "Epoch: 1569     Loss: -1.7816458085665074\n",
      "Epoch: 1570     Loss: -1.7817386475350006\n",
      "Epoch: 1571     Loss: -1.7818334161840996\n",
      "Epoch: 1572     Loss: -1.781928497180965\n",
      "Epoch: 1573     Loss: -1.7820231991453472\n",
      "Epoch: 1574     Loss: -1.7821186557196447\n",
      "Epoch: 1575     Loss: -1.7822147031573048\n",
      "Epoch: 1576     Loss: -1.7823098816926808\n",
      "Epoch: 1577     Loss: -1.7824034130953719\n",
      "Epoch: 1578     Loss: -1.782496711925919\n",
      "Epoch: 1579     Loss: -1.7825904739264713\n",
      "Epoch: 1580     Loss: -1.7826822233990163\n",
      "Epoch: 1581     Loss: -1.7827722479663572\n",
      "Epoch: 1582     Loss: -1.7828653142401802\n",
      "Epoch: 1583     Loss: -1.7829601180610222\n",
      "Epoch: 1584     Loss: -1.783054471525987\n",
      "Epoch: 1585     Loss: -1.783150166058998\n",
      "Epoch: 1586     Loss: -1.7832439838392755\n",
      "Epoch: 1587     Loss: -1.7833377010071647\n",
      "Epoch: 1588     Loss: -1.7834301949470148\n",
      "Epoch: 1589     Loss: -1.7835227220744767\n",
      "Epoch: 1590     Loss: -1.7836145835047568\n",
      "Epoch: 1591     Loss: -1.7837060101862434\n",
      "Epoch: 1592     Loss: -1.7837963697469477\n",
      "Epoch: 1593     Loss: -1.7838856873969395\n",
      "Epoch: 1594     Loss: -1.7839746037584685\n",
      "Epoch: 1595     Loss: -1.7840614885942447\n",
      "Epoch: 1596     Loss: -1.7841495902907465\n",
      "Epoch: 1597     Loss: -1.784235494220624\n",
      "Epoch: 1598     Loss: -1.7843241613092102\n",
      "Epoch: 1599     Loss: -1.7844112330175035\n",
      "Epoch: 1600     Loss: -1.784499064421893\n",
      "Epoch: 1601     Loss: -1.7845901773869022\n",
      "Epoch: 1602     Loss: -1.7846808991321703\n",
      "Epoch: 1603     Loss: -1.7847734573394152\n",
      "Epoch: 1604     Loss: -1.7848657079132288\n",
      "Epoch: 1605     Loss: -1.7849590945958067\n",
      "Epoch: 1606     Loss: -1.7850518942488613\n",
      "Epoch: 1607     Loss: -1.785144570974873\n",
      "Epoch: 1608     Loss: -1.785236045297261\n",
      "Epoch: 1609     Loss: -1.7853264169774739\n",
      "Epoch: 1610     Loss: -1.7854132471070034\n",
      "Epoch: 1611     Loss: -1.7855004899968507\n",
      "Epoch: 1612     Loss: -1.785586615645807\n",
      "Epoch: 1613     Loss: -1.7856739707977536\n",
      "Epoch: 1614     Loss: -1.7857631162240306\n",
      "Epoch: 1615     Loss: -1.785849649431948\n",
      "Epoch: 1616     Loss: -1.7859382081802138\n",
      "Epoch: 1617     Loss: -1.7860244297114336\n",
      "Epoch: 1618     Loss: -1.7861146384313449\n",
      "Epoch: 1619     Loss: -1.7862035885621055\n",
      "Epoch: 1620     Loss: -1.7862951702952155\n",
      "Epoch: 1621     Loss: -1.7863855066987973\n",
      "Epoch: 1622     Loss: -1.7864777888086656\n",
      "Epoch: 1623     Loss: -1.7865689749540052\n",
      "Epoch: 1624     Loss: -1.7866618883813077\n",
      "Epoch: 1625     Loss: -1.7867537216910092\n",
      "Epoch: 1626     Loss: -1.7868475589809634\n",
      "Epoch: 1627     Loss: -1.7869401629431496\n",
      "Epoch: 1628     Loss: -1.7870341932058038\n",
      "Epoch: 1629     Loss: -1.787126902635124\n",
      "Epoch: 1630     Loss: -1.7872205421975853\n",
      "Epoch: 1631     Loss: -1.7873123623254847\n",
      "Epoch: 1632     Loss: -1.7874041513717367\n",
      "Epoch: 1633     Loss: -1.7874932747123098\n",
      "Epoch: 1634     Loss: -1.7875809775569422\n",
      "Epoch: 1635     Loss: -1.7876655103503123\n",
      "Epoch: 1636     Loss: -1.7877473029380746\n",
      "Epoch: 1637     Loss: -1.7878285161986085\n",
      "Epoch: 1638     Loss: -1.7879082935675554\n",
      "Epoch: 1639     Loss: -1.7879920872681279\n",
      "Epoch: 1640     Loss: -1.788076594261689\n",
      "Epoch: 1641     Loss: -1.7881646747825573\n",
      "Epoch: 1642     Loss: -1.788253107539489\n",
      "Epoch: 1643     Loss: -1.7883432323937907\n",
      "Epoch: 1644     Loss: -1.7884324594431613\n",
      "Epoch: 1645     Loss: -1.7885225333059545\n",
      "Epoch: 1646     Loss: -1.7886113108391402\n",
      "Epoch: 1647     Loss: -1.788699829820559\n",
      "Epoch: 1648     Loss: -1.788786285284765\n",
      "Epoch: 1649     Loss: -1.788871694933606\n",
      "Epoch: 1650     Loss: -1.7889552758589107\n",
      "Epoch: 1651     Loss: -1.7890383830991243\n",
      "Epoch: 1652     Loss: -1.7891207720664841\n",
      "Epoch: 1653     Loss: -1.7892040460923844\n",
      "Epoch: 1654     Loss: -1.7892868559886301\n",
      "Epoch: 1655     Loss: -1.7893708035139915\n",
      "Epoch: 1656     Loss: -1.7894530945967757\n",
      "Epoch: 1657     Loss: -1.7895353255661133\n",
      "Epoch: 1658     Loss: -1.7896153739994107\n",
      "Epoch: 1659     Loss: -1.7896945194761675\n",
      "Epoch: 1660     Loss: -1.7897764863994896\n",
      "Epoch: 1661     Loss: -1.789860870782116\n",
      "Epoch: 1662     Loss: -1.7899457536122723\n",
      "Epoch: 1663     Loss: -1.7900319528920146\n",
      "Epoch: 1664     Loss: -1.790119035898613\n",
      "Epoch: 1665     Loss: -1.790207926687018\n",
      "Epoch: 1666     Loss: -1.7902956796752474\n",
      "Epoch: 1667     Loss: -1.790383311573477\n",
      "Epoch: 1668     Loss: -1.7904699157293087\n",
      "Epoch: 1669     Loss: -1.7905584848297422\n",
      "Epoch: 1670     Loss: -1.790645118037078\n",
      "Epoch: 1671     Loss: -1.7907317480818812\n",
      "Epoch: 1672     Loss: -1.790818124985744\n",
      "Epoch: 1673     Loss: -1.790906881752106\n",
      "Epoch: 1674     Loss: -1.790994484015027\n",
      "Epoch: 1675     Loss: -1.791082120931883\n",
      "Epoch: 1676     Loss: -1.791167896034121\n",
      "Epoch: 1677     Loss: -1.79125337406019\n",
      "Epoch: 1678     Loss: -1.791337645261441\n",
      "Epoch: 1679     Loss: -1.791422714186433\n",
      "Epoch: 1680     Loss: -1.7915088280441183\n",
      "Epoch: 1681     Loss: -1.7915958872159716\n",
      "Epoch: 1682     Loss: -1.791684021824802\n",
      "Epoch: 1683     Loss: -1.7917720442735003\n",
      "Epoch: 1684     Loss: -1.7918604896496193\n",
      "Epoch: 1685     Loss: -1.7919478141050256\n",
      "Epoch: 1686     Loss: -1.7920346482468976\n",
      "Epoch: 1687     Loss: -1.792119744287083\n",
      "Epoch: 1688     Loss: -1.7922036813186195\n",
      "Epoch: 1689     Loss: -1.7922869971993336\n",
      "Epoch: 1690     Loss: -1.7923691790344476\n",
      "Epoch: 1691     Loss: -1.792452096732196\n",
      "Epoch: 1692     Loss: -1.7925347633213944\n",
      "Epoch: 1693     Loss: -1.7926180002888044\n",
      "Epoch: 1694     Loss: -1.792699655375428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1695     Loss: -1.7927819308871402\n",
      "Epoch: 1696     Loss: -1.7928639507933626\n",
      "Epoch: 1697     Loss: -1.7929476572066154\n",
      "Epoch: 1698     Loss: -1.7930316838844467\n",
      "Epoch: 1699     Loss: -1.7931164275566862\n",
      "Epoch: 1700     Loss: -1.7932022924740347\n",
      "Epoch: 1701     Loss: -1.7932880269368976\n",
      "Epoch: 1702     Loss: -1.7933741989555372\n",
      "Epoch: 1703     Loss: -1.793459253926947\n",
      "Epoch: 1704     Loss: -1.7935441329480593\n",
      "Epoch: 1705     Loss: -1.7936265160711324\n",
      "Epoch: 1706     Loss: -1.7937094086065224\n",
      "Epoch: 1707     Loss: -1.793790096198072\n",
      "Epoch: 1708     Loss: -1.7938734421444165\n",
      "Epoch: 1709     Loss: -1.7939553445652134\n",
      "Epoch: 1710     Loss: -1.7940393172180502\n",
      "Epoch: 1711     Loss: -1.7941219304300233\n",
      "Epoch: 1712     Loss: -1.7942064156099622\n",
      "Epoch: 1713     Loss: -1.7942895360857527\n",
      "Epoch: 1714     Loss: -1.7943738153799549\n",
      "Epoch: 1715     Loss: -1.7944565196919164\n",
      "Epoch: 1716     Loss: -1.7945396999990768\n",
      "Epoch: 1717     Loss: -1.7946210200652855\n",
      "Epoch: 1718     Loss: -1.794702731756606\n",
      "Epoch: 1719     Loss: -1.7947826388255492\n",
      "Epoch: 1720     Loss: -1.7948634932848786\n",
      "Epoch: 1721     Loss: -1.794942865164957\n",
      "Epoch: 1722     Loss: -1.7950237190049492\n",
      "Epoch: 1723     Loss: -1.795103371613851\n",
      "Epoch: 1724     Loss: -1.7951843547748294\n",
      "Epoch: 1725     Loss: -1.7952649549898145\n",
      "Epoch: 1726     Loss: -1.7953465853475603\n",
      "Epoch: 1727     Loss: -1.7954276981773474\n",
      "Epoch: 1728     Loss: -1.7955101304960632\n",
      "Epoch: 1729     Loss: -1.795592704186444\n",
      "Epoch: 1730     Loss: -1.7956746801302172\n",
      "Epoch: 1731     Loss: -1.7957569934591342\n",
      "Epoch: 1732     Loss: -1.7958392039052142\n",
      "Epoch: 1733     Loss: -1.7959222819190288\n",
      "Epoch: 1734     Loss: -1.7960054132069676\n",
      "Epoch: 1735     Loss: -1.7960895457325101\n",
      "Epoch: 1736     Loss: -1.796173277491932\n",
      "Epoch: 1737     Loss: -1.7962582820770459\n",
      "Epoch: 1738     Loss: -1.7963423255701125\n",
      "Epoch: 1739     Loss: -1.796427811316374\n",
      "Epoch: 1740     Loss: -1.7965120014253955\n",
      "Epoch: 1741     Loss: -1.7965976334248106\n",
      "Epoch: 1742     Loss: -1.7966815059205488\n",
      "Epoch: 1743     Loss: -1.79676672751169\n",
      "Epoch: 1744     Loss: -1.796849576624822\n",
      "Epoch: 1745     Loss: -1.796933855064615\n",
      "Epoch: 1746     Loss: -1.7970153473536823\n",
      "Epoch: 1747     Loss: -1.7970986231175836\n",
      "Epoch: 1748     Loss: -1.7971792918001426\n",
      "Epoch: 1749     Loss: -1.7972620404168183\n",
      "Epoch: 1750     Loss: -1.7973427246161788\n",
      "Epoch: 1751     Loss: -1.7974251722421222\n",
      "Epoch: 1752     Loss: -1.7975059534325633\n",
      "Epoch: 1753     Loss: -1.7975878771600222\n",
      "Epoch: 1754     Loss: -1.7976684523043158\n",
      "Epoch: 1755     Loss: -1.7977506998819643\n",
      "Epoch: 1756     Loss: -1.797831157493604\n",
      "Epoch: 1757     Loss: -1.7979129088480033\n",
      "Epoch: 1758     Loss: -1.797992585992048\n",
      "Epoch: 1759     Loss: -1.7980727640010938\n",
      "Epoch: 1760     Loss: -1.7981505325619478\n",
      "Epoch: 1761     Loss: -1.7982279847166518\n",
      "Epoch: 1762     Loss: -1.7983028501954357\n",
      "Epoch: 1763     Loss: -1.7983772428266704\n",
      "Epoch: 1764     Loss: -1.7984531482995094\n",
      "Epoch: 1765     Loss: -1.7985274182952273\n",
      "Epoch: 1766     Loss: -1.798605469323654\n",
      "Epoch: 1767     Loss: -1.7986822829490126\n",
      "Epoch: 1768     Loss: -1.7987620664079829\n",
      "Epoch: 1769     Loss: -1.7988411340619184\n",
      "Epoch: 1770     Loss: -1.7989211027404441\n",
      "Epoch: 1771     Loss: -1.7990011570112459\n",
      "Epoch: 1772     Loss: -1.7990812020175175\n",
      "Epoch: 1773     Loss: -1.7991618218124612\n",
      "Epoch: 1774     Loss: -1.7992423018881063\n",
      "Epoch: 1775     Loss: -1.7993234981258404\n",
      "Epoch: 1776     Loss: -1.7994045367852656\n",
      "Epoch: 1777     Loss: -1.7994862056864454\n",
      "Epoch: 1778     Loss: -1.7995678013496588\n",
      "Epoch: 1779     Loss: -1.799649703842832\n",
      "Epoch: 1780     Loss: -1.7997312947530482\n",
      "Epoch: 1781     Loss: -1.7998130142176252\n",
      "Epoch: 1782     Loss: -1.7998942384241996\n",
      "Epoch: 1783     Loss: -1.7999756533885296\n",
      "Epoch: 1784     Loss: -1.800056264598439\n",
      "Epoch: 1785     Loss: -1.800137322852687\n",
      "Epoch: 1786     Loss: -1.800217072868408\n",
      "Epoch: 1787     Loss: -1.8002972941984796\n",
      "Epoch: 1788     Loss: -1.8003750423106466\n",
      "Epoch: 1789     Loss: -1.8004533428724343\n",
      "Epoch: 1790     Loss: -1.800528306471218\n",
      "Epoch: 1791     Loss: -1.800605441941455\n",
      "Epoch: 1792     Loss: -1.8006807865458403\n",
      "Epoch: 1793     Loss: -1.800758541766818\n",
      "Epoch: 1794     Loss: -1.8008342954725371\n",
      "Epoch: 1795     Loss: -1.8009134797336235\n",
      "Epoch: 1796     Loss: -1.800991692675494\n",
      "Epoch: 1797     Loss: -1.801072559798757\n",
      "Epoch: 1798     Loss: -1.8011525113598261\n",
      "Epoch: 1799     Loss: -1.8012331833588986\n",
      "Epoch: 1800     Loss: -1.8013126791271743\n",
      "Epoch: 1801     Loss: -1.8013921793117884\n",
      "Epoch: 1802     Loss: -1.8014706255581363\n",
      "Epoch: 1803     Loss: -1.8015493467704264\n",
      "Epoch: 1804     Loss: -1.8016273623218355\n",
      "Epoch: 1805     Loss: -1.8017058480310961\n",
      "Epoch: 1806     Loss: -1.801783929311425\n",
      "Epoch: 1807     Loss: -1.8018628693166343\n",
      "Epoch: 1808     Loss: -1.8019413382008391\n",
      "Epoch: 1809     Loss: -1.8020203695368369\n",
      "Epoch: 1810     Loss: -1.8020977855814504\n",
      "Epoch: 1811     Loss: -1.8021764860153755\n",
      "Epoch: 1812     Loss: -1.802254804477761\n",
      "Epoch: 1813     Loss: -1.8023342234630204\n",
      "Epoch: 1814     Loss: -1.8024130907399838\n",
      "Epoch: 1815     Loss: -1.8024924867334828\n",
      "Epoch: 1816     Loss: -1.8025715501803494\n",
      "Epoch: 1817     Loss: -1.802650536700714\n",
      "Epoch: 1818     Loss: -1.8027292921388205\n",
      "Epoch: 1819     Loss: -1.802806589503193\n",
      "Epoch: 1820     Loss: -1.8028848172823895\n",
      "Epoch: 1821     Loss: -1.8029616840815883\n",
      "Epoch: 1822     Loss: -1.8030391707116928\n",
      "Epoch: 1823     Loss: -1.803113724906404\n",
      "Epoch: 1824     Loss: -1.803189205513453\n",
      "Epoch: 1825     Loss: -1.8032603751179521\n",
      "Epoch: 1826     Loss: -1.8033345347512708\n",
      "Epoch: 1827     Loss: -1.8034056379440266\n",
      "Epoch: 1828     Loss: -1.8034817389236157\n",
      "Epoch: 1829     Loss: -1.8035558383179708\n",
      "Epoch: 1830     Loss: -1.8036328042898857\n",
      "Epoch: 1831     Loss: -1.803708172555198\n",
      "Epoch: 1832     Loss: -1.8037855817529782\n",
      "Epoch: 1833     Loss: -1.8038616510143777\n",
      "Epoch: 1834     Loss: -1.8039389446955914\n",
      "Epoch: 1835     Loss: -1.804015417434332\n",
      "Epoch: 1836     Loss: -1.8040928465402382\n",
      "Epoch: 1837     Loss: -1.804169613943715\n",
      "Epoch: 1838     Loss: -1.8042466162180708\n",
      "Epoch: 1839     Loss: -1.8043231365083412\n",
      "Epoch: 1840     Loss: -1.8043996399877809\n",
      "Epoch: 1841     Loss: -1.804474693495068\n",
      "Epoch: 1842     Loss: -1.8045494630086933\n",
      "Epoch: 1843     Loss: -1.804624196476504\n",
      "Epoch: 1844     Loss: -1.8047003520593454\n",
      "Epoch: 1845     Loss: -1.804777418582545\n",
      "Epoch: 1846     Loss: -1.8048538805500178\n",
      "Epoch: 1847     Loss: -1.804931314118858\n",
      "Epoch: 1848     Loss: -1.8050080111334819\n",
      "Epoch: 1849     Loss: -1.8050853727214422\n",
      "Epoch: 1850     Loss: -1.8051609315014756\n",
      "Epoch: 1851     Loss: -1.8052372249371333\n",
      "Epoch: 1852     Loss: -1.805312250761845\n",
      "Epoch: 1853     Loss: -1.8053879694620645\n",
      "Epoch: 1854     Loss: -1.8054628765790235\n",
      "Epoch: 1855     Loss: -1.8055377361071643\n",
      "Epoch: 1856     Loss: -1.8056120794454749\n",
      "Epoch: 1857     Loss: -1.8056861197744283\n",
      "Epoch: 1858     Loss: -1.8057600906789526\n",
      "Epoch: 1859     Loss: -1.8058336259055454\n",
      "Epoch: 1860     Loss: -1.8059074183431783\n",
      "Epoch: 1861     Loss: -1.8059807807334902\n",
      "Epoch: 1862     Loss: -1.806054162445884\n",
      "Epoch: 1863     Loss: -1.8061276762102247\n",
      "Epoch: 1864     Loss: -1.8062011724527505\n",
      "Epoch: 1865     Loss: -1.806276070138118\n",
      "Epoch: 1866     Loss: -1.806351732276633\n",
      "Epoch: 1867     Loss: -1.8064285879835476\n",
      "Epoch: 1868     Loss: -1.8065058293133496\n",
      "Epoch: 1869     Loss: -1.8065832545571785\n",
      "Epoch: 1870     Loss: -1.8066604237574537\n",
      "Epoch: 1871     Loss: -1.806737712579782\n",
      "Epoch: 1872     Loss: -1.806814324854832\n",
      "Epoch: 1873     Loss: -1.8068909588201365\n",
      "Epoch: 1874     Loss: -1.8069663671284608\n",
      "Epoch: 1875     Loss: -1.8070406922397115\n",
      "Epoch: 1876     Loss: -1.807112968752607\n",
      "Epoch: 1877     Loss: -1.8071819465934351\n",
      "Epoch: 1878     Loss: -1.8072492593495237\n",
      "Epoch: 1879     Loss: -1.807312614664118\n",
      "Epoch: 1880     Loss: -1.8073767963002743\n",
      "Epoch: 1881     Loss: -1.807441111957024\n",
      "Epoch: 1882     Loss: -1.8075099681010431\n",
      "Epoch: 1883     Loss: -1.8075797529613744\n",
      "Epoch: 1884     Loss: -1.8076519547134295\n",
      "Epoch: 1885     Loss: -1.8077257954563921\n",
      "Epoch: 1886     Loss: -1.8078016942256245\n",
      "Epoch: 1887     Loss: -1.80787799557234\n",
      "Epoch: 1888     Loss: -1.8079552567577981\n",
      "Epoch: 1889     Loss: -1.808032520064569\n",
      "Epoch: 1890     Loss: -1.8081103072624822\n",
      "Epoch: 1891     Loss: -1.8081878642581035\n",
      "Epoch: 1892     Loss: -1.8082656588121546\n",
      "Epoch: 1893     Loss: -1.8083431596912307\n",
      "Epoch: 1894     Loss: -1.8084207267825299\n",
      "Epoch: 1895     Loss: -1.8084981526980135\n",
      "Epoch: 1896     Loss: -1.8085756028448565\n",
      "Epoch: 1897     Loss: -1.808653075467064\n",
      "Epoch: 1898     Loss: -1.8087303947306375\n",
      "Epoch: 1899     Loss: -1.8088076134826194\n",
      "Epoch: 1900     Loss: -1.8088838395544553\n",
      "Epoch: 1901     Loss: -1.808959568781976\n",
      "Epoch: 1902     Loss: -1.8090329628377488\n",
      "Epoch: 1903     Loss: -1.8091063134727665\n",
      "Epoch: 1904     Loss: -1.8091766216431715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1905     Loss: -1.809247604302639\n",
      "Epoch: 1906     Loss: -1.809315184740014\n",
      "Epoch: 1907     Loss: -1.8093857148605856\n",
      "Epoch: 1908     Loss: -1.8094542128207056\n",
      "Epoch: 1909     Loss: -1.809525860797724\n",
      "Epoch: 1910     Loss: -1.80959477299948\n",
      "Epoch: 1911     Loss: -1.8096666454130559\n",
      "Epoch: 1912     Loss: -1.809735603511801\n",
      "Epoch: 1913     Loss: -1.8098077628612548\n",
      "Epoch: 1914     Loss: -1.8098788156656767\n",
      "Epoch: 1915     Loss: -1.8099522112134339\n",
      "Epoch: 1916     Loss: -1.8100248431506127\n",
      "Epoch: 1917     Loss: -1.810098667277963\n",
      "Epoch: 1918     Loss: -1.8101719207267581\n",
      "Epoch: 1919     Loss: -1.810245979012782\n",
      "Epoch: 1920     Loss: -1.8103196135009567\n",
      "Epoch: 1921     Loss: -1.810393648338092\n",
      "Epoch: 1922     Loss: -1.8104673520791201\n",
      "Epoch: 1923     Loss: -1.8105410084266644\n",
      "Epoch: 1924     Loss: -1.8106143984421859\n",
      "Epoch: 1925     Loss: -1.8106871809662297\n",
      "Epoch: 1926     Loss: -1.8107596390786607\n",
      "Epoch: 1927     Loss: -1.810830844018917\n",
      "Epoch: 1928     Loss: -1.8109015293359807\n",
      "Epoch: 1929     Loss: -1.8109699590975192\n",
      "Epoch: 1930     Loss: -1.81103840429478\n",
      "Epoch: 1931     Loss: -1.81110389963911\n",
      "Epoch: 1932     Loss: -1.8111704520926848\n",
      "Epoch: 1933     Loss: -1.811235268250304\n",
      "Epoch: 1934     Loss: -1.8113008202818697\n",
      "Epoch: 1935     Loss: -1.8113659863671296\n",
      "Epoch: 1936     Loss: -1.811431585065139\n",
      "Epoch: 1937     Loss: -1.811498333931551\n",
      "Epoch: 1938     Loss: -1.8115653459494385\n",
      "Epoch: 1939     Loss: -1.8116339958313297\n",
      "Epoch: 1940     Loss: -1.8117032176445793\n",
      "Epoch: 1941     Loss: -1.8117737817845605\n",
      "Epoch: 1942     Loss: -1.8118447886747024\n",
      "Epoch: 1943     Loss: -1.8119164178871499\n",
      "Epoch: 1944     Loss: -1.8119882540222199\n",
      "Epoch: 1945     Loss: -1.8120603560008919\n",
      "Epoch: 1946     Loss: -1.812132641036796\n",
      "Epoch: 1947     Loss: -1.8122052323062066\n",
      "Epoch: 1948     Loss: -1.812277952312684\n",
      "Epoch: 1949     Loss: -1.8123509061166039\n",
      "Epoch: 1950     Loss: -1.8124237224692528\n",
      "Epoch: 1951     Loss: -1.8124967044224092\n",
      "Epoch: 1952     Loss: -1.812569267989156\n",
      "Epoch: 1953     Loss: -1.8126419723970488\n",
      "Epoch: 1954     Loss: -1.8127140001816866\n",
      "Epoch: 1955     Loss: -1.8127861473932003\n",
      "Epoch: 1956     Loss: -1.8128574572924152\n",
      "Epoch: 1957     Loss: -1.8129288907362966\n",
      "Epoch: 1958     Loss: -1.8129994306163815\n",
      "Epoch: 1959     Loss: -1.813070048188523\n",
      "Epoch: 1960     Loss: -1.8131396353999432\n",
      "Epoch: 1961     Loss: -1.8132091025968051\n",
      "Epoch: 1962     Loss: -1.8132776834451494\n",
      "Epoch: 1963     Loss: -1.8133461831627449\n",
      "Epoch: 1964     Loss: -1.8134125179454519\n",
      "Epoch: 1965     Loss: -1.8134806243720012\n",
      "Epoch: 1966     Loss: -1.8135492650939111\n",
      "Epoch: 1967     Loss: -1.813617476521148\n",
      "Epoch: 1968     Loss: -1.81368611333463\n",
      "Epoch: 1969     Loss: -1.8137528147583373\n",
      "Epoch: 1970     Loss: -1.8138215071743726\n",
      "Epoch: 1971     Loss: -1.813888276275886\n",
      "Epoch: 1972     Loss: -1.8139567918567079\n",
      "Epoch: 1973     Loss: -1.8140249415606309\n",
      "Epoch: 1974     Loss: -1.8140937495626843\n",
      "Epoch: 1975     Loss: -1.8141620078584932\n",
      "Epoch: 1976     Loss: -1.8142298645349553\n",
      "Epoch: 1977     Loss: -1.8142976174536063\n",
      "Epoch: 1978     Loss: -1.8143646394314124\n",
      "Epoch: 1979     Loss: -1.814431921451578\n",
      "Epoch: 1980     Loss: -1.8144988467251815\n",
      "Epoch: 1981     Loss: -1.814566019303187\n",
      "Epoch: 1982     Loss: -1.8146344560734373\n",
      "Epoch: 1983     Loss: -1.8147037203844558\n",
      "Epoch: 1984     Loss: -1.81477414461158\n",
      "Epoch: 1985     Loss: -1.8148453859553044\n",
      "Epoch: 1986     Loss: -1.814916716365923\n",
      "Epoch: 1987     Loss: -1.814988629726159\n",
      "Epoch: 1988     Loss: -1.8150598019623343\n",
      "Epoch: 1989     Loss: -1.8151312533410362\n",
      "Epoch: 1990     Loss: -1.815201298933524\n",
      "Epoch: 1991     Loss: -1.815271423454898\n",
      "Epoch: 1992     Loss: -1.8153397065157995\n",
      "Epoch: 1993     Loss: -1.8154088051928134\n",
      "Epoch: 1994     Loss: -1.8154762524998391\n",
      "Epoch: 1995     Loss: -1.8155448383404318\n",
      "Epoch: 1996     Loss: -1.8156121674818217\n",
      "Epoch: 1997     Loss: -1.8156802250273643\n",
      "Epoch: 1998     Loss: -1.815747944021665\n",
      "Epoch: 1999     Loss: -1.8158165633129069\n",
      "Epoch: 2000     Loss: -1.8158844703604335\n",
      "\n",
      "**********单独在原始数据集上训练LR和SVM分类器的精度和AUC*************\n",
      "View 1(LR) ACC :  77.5 %       AUC: 0.8020833333333334\n",
      "View 2(LR) ACC :  100.0 %       AUC: 1.0\n",
      "View 1(SVM) ACC :  90.0 %       AUC: 0.9166666666666667\n",
      "View 2(SVM) ACC :  100.0 %       AUC: 1.0 \n",
      "\n",
      "**********在抽取出的共同空间上训练LR和SVM分类器的精度和AUC*************\n",
      "View 1(LR) ACC :  97.5 %       AUC: 0.9791666666666667\n",
      "View 2(LR) ACC :  100.0 %       AUC: 1.0\n",
      "View 1(SVM) ACC :  97.5 %       AUC: 0.9791666666666667\n",
      "View 2(SVM) ACC :  100.0 %       AUC: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\ipykernel_launcher.py:81: UserWarning: The following kwargs were not used by contour: 'linestyle'\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\ipykernel_launcher.py:81: UserWarning: The following kwargs were not used by contour: 'linestyle'\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "    # 输出的维度\n",
    "    outdim_size = 2\n",
    "\n",
    "    # 两个view的输入\n",
    "    input_shape1 = 2\n",
    "    input_shape2 = 10\n",
    "\n",
    "    # 网络架构设置\n",
    "    layer_sizes1 = [20, 40, 20, outdim_size]\n",
    "    layer_sizes2 = [20, 40, 20, outdim_size]\n",
    "\n",
    "    # 超参数设置\n",
    "    learning_rate = 1e-3\n",
    "    epoch_num = 2000\n",
    "    reg_par = 1e-5\n",
    "    use_all_singular_values = False\n",
    "\n",
    "    # 搭建网络\n",
    "    model = DeepCCA(layer_sizes1, layer_sizes2, input_shape1,\n",
    "                    input_shape2, outdim_size, use_all_singular_values, device=device).double()\n",
    "    solver = Solver(model, outdim_size, epoch_num, learning_rate, reg_par, device=device)\n",
    "    \n",
    "    # 训练\n",
    "    train1, train2 = X1, X2\n",
    "    solver.fit(train1, train2)\n",
    "\n",
    "    # 测试\n",
    "    loss, outputs = solver.test(train1, train2)\n",
    "    \n",
    "    print(\"\\n**********单独在原始数据集上训练LR和SVM分类器的精度和AUC*************\")\n",
    "    print(\"View 1(LR) ACC : \", LR_2(X1, y)[0] * 100, \"%       AUC:\", LR_2(X1, y)[1])\n",
    "    print(\"View 2(LR) ACC : \", LR_2(X2, y)[0] * 100, \"%       AUC:\", LR_2(X2, y)[1])\n",
    "    print(\"View 1(SVM) ACC : \", svm_2(X1, y)[0] * 100, \"%       AUC:\", svm_2(X1, y)[1])\n",
    "    print(\"View 2(SVM) ACC : \", svm_2(X2, y)[0] * 100, \"%       AUC:\", svm_2(X2, y)[1], \"\\n\")\n",
    "    \n",
    "    print(\"**********在抽取出的共同空间上训练LR和SVM分类器的精度和AUC*************\")\n",
    "    print(\"View 1(LR) ACC : \", LR_2(outputs[0], y)[0] * 100, \"%       AUC:\", LR_2(outputs[0], y)[1])\n",
    "    print(\"View 2(LR) ACC : \", LR_2(outputs[1], y)[0] * 100, \"%       AUC:\", LR_2(outputs[1], y)[1])\n",
    "    print(\"View 1(SVM) ACC : \", svm_2(outputs[0], y)[0] * 100, \"%       AUC:\", svm_2(outputs[0], y)[1])\n",
    "    print(\"View 2(SVM) ACC : \", svm_2(outputs[1], y)[0] * 100, \"%       AUC:\", svm_2(outputs[1], y)[1])\n",
    "\n",
    "    #可视化映射到隐空间中的状态，尾数1代表View 1\n",
    "    visualization_LR(outputs[0], y, 'View 1')\n",
    "    visualization_LR(outputs[1], y, 'View 2')\n",
    "    visualization_SVM(outputs[0], y, 'View 1')\n",
    "    visualization_SVM(outputs[1], y, 'View 2')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "data = pd.read_csv(\"UCI_Credit_Card.csv\")\n",
    "data.isnull().sum()\n",
    "y = data['default.payment.next.month']\n",
    "x_ori = data.drop(['ID', 'default.payment.next.month'], axis=1)\n",
    "x_ori = x_ori.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "x_ori.shape\n",
    "\n",
    "train_a1 = np.array(x_ori.iloc[:, 0:11])\n",
    "train_b1 = np.array(x_ori.iloc[:, 11:23])\n",
    "\n",
    "\n",
    "train_a = torch.from_numpy(train_a1).double()\n",
    "train_b = torch.from_numpy(train_b1).double()\n",
    "train_a1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch: 1     Loss: -0.3917498652526248\n",
      "Epoch: 2     Loss: -0.5031756282132873\n",
      "Epoch: 3     Loss: -0.6317604030164718\n",
      "Epoch: 4     Loss: -0.7109587732558\n",
      "Epoch: 5     Loss: -0.7545094786370485\n",
      "Epoch: 6     Loss: -0.7860047237100494\n",
      "Epoch: 7     Loss: -0.8166102507595961\n",
      "Epoch: 8     Loss: -0.8411534837978689\n",
      "Epoch: 9     Loss: -0.8623155591127245\n",
      "Epoch: 10     Loss: -0.8810589617355122\n",
      "Epoch: 11     Loss: -0.8975566675687978\n",
      "Epoch: 12     Loss: -0.9122053865910152\n",
      "Epoch: 13     Loss: -0.9253382292093459\n",
      "Epoch: 14     Loss: -0.93722178530089\n",
      "Epoch: 15     Loss: -0.9480238172240764\n",
      "Epoch: 16     Loss: -0.9577653081462254\n",
      "Epoch: 17     Loss: -0.9656112990367298\n",
      "Epoch: 18     Loss: -0.9706460523000092\n",
      "Epoch: 19     Loss: -0.9776728384924949\n",
      "Epoch: 20     Loss: -0.9854093763046643\n",
      "Epoch: 21     Loss: -0.9929399890109962\n",
      "Epoch: 22     Loss: -1.0002328080051586\n",
      "Epoch: 23     Loss: -1.0072271270369246\n",
      "Epoch: 24     Loss: -1.0136360745395445\n",
      "Epoch: 25     Loss: -1.0186215890301713\n",
      "Epoch: 26     Loss: -1.0221753561266875\n",
      "Epoch: 27     Loss: -1.027146474463785\n",
      "Epoch: 28     Loss: -1.0325777306803527\n",
      "Epoch: 29     Loss: -1.0379576049430506\n",
      "Epoch: 30     Loss: -1.0432451072167965\n",
      "Epoch: 31     Loss: -1.0483512167679896\n",
      "Epoch: 32     Loss: -1.053272372365936\n",
      "Epoch: 33     Loss: -1.0579800424963346\n",
      "Epoch: 34     Loss: -1.0624749024621074\n",
      "Epoch: 35     Loss: -1.0666943455742932\n",
      "Epoch: 36     Loss: -1.0703531359896445\n",
      "Epoch: 37     Loss: -1.0735972343539395\n",
      "Epoch: 38     Loss: -1.0768946739119665\n",
      "Epoch: 39     Loss: -1.0805965959132142\n",
      "Epoch: 40     Loss: -1.0843771751143572\n",
      "Epoch: 41     Loss: -1.0881457342319616\n",
      "Epoch: 42     Loss: -1.0918498274526456\n",
      "Epoch: 43     Loss: -1.0954358393710757\n",
      "Epoch: 44     Loss: -1.0988456736571877\n",
      "Epoch: 45     Loss: -1.1020440950884267\n",
      "Epoch: 46     Loss: -1.1052762943779944\n",
      "Epoch: 47     Loss: -1.1084295018844033\n",
      "Epoch: 48     Loss: -1.111540730455583\n",
      "Epoch: 49     Loss: -1.1148578817993793\n",
      "Epoch: 50     Loss: -1.1181652448637949\n",
      "Epoch: 51     Loss: -1.1215104973096255\n",
      "Epoch: 52     Loss: -1.124745054914387\n",
      "Epoch: 53     Loss: -1.1278575861143363\n",
      "Epoch: 54     Loss: -1.1309290842426052\n",
      "Epoch: 55     Loss: -1.1339937341897288\n",
      "Epoch: 56     Loss: -1.13715160882963\n",
      "Epoch: 57     Loss: -1.1402839616973601\n",
      "Epoch: 58     Loss: -1.1432170485625894\n",
      "Epoch: 59     Loss: -1.1460949619817637\n",
      "Epoch: 60     Loss: -1.148914723166564\n",
      "Epoch: 61     Loss: -1.1518025443970392\n",
      "Epoch: 62     Loss: -1.154835910146825\n",
      "Epoch: 63     Loss: -1.1578985130525432\n",
      "Epoch: 64     Loss: -1.1608649540306182\n",
      "Epoch: 65     Loss: -1.1638393508233271\n",
      "Epoch: 66     Loss: -1.1667041498157438\n",
      "Epoch: 67     Loss: -1.1694715970779235\n",
      "Epoch: 68     Loss: -1.1721902878820312\n",
      "Epoch: 69     Loss: -1.1745716688139465\n",
      "Epoch: 70     Loss: -1.1772518076750476\n",
      "Epoch: 71     Loss: -1.1799142539313017\n",
      "Epoch: 72     Loss: -1.1825135414160743\n",
      "Epoch: 73     Loss: -1.1849834276991893\n",
      "Epoch: 74     Loss: -1.1875872719138634\n",
      "Epoch: 75     Loss: -1.1901478411972222\n",
      "Epoch: 76     Loss: -1.1926909454202335\n",
      "Epoch: 77     Loss: -1.195073833856662\n",
      "Epoch: 78     Loss: -1.1975754806651566\n",
      "Epoch: 79     Loss: -1.2000166616206003\n",
      "Epoch: 80     Loss: -1.202408244563096\n",
      "Epoch: 81     Loss: -1.2046647004176654\n",
      "Epoch: 82     Loss: -1.2069746734893272\n",
      "Epoch: 83     Loss: -1.2092377290329126\n",
      "Epoch: 84     Loss: -1.211498060339537\n",
      "Epoch: 85     Loss: -1.2137075708536806\n",
      "Epoch: 86     Loss: -1.2159311546256757\n",
      "Epoch: 87     Loss: -1.2181015490575664\n",
      "Epoch: 88     Loss: -1.220276216371532\n",
      "Epoch: 89     Loss: -1.222399599257607\n",
      "Epoch: 90     Loss: -1.2245154276076224\n",
      "Epoch: 91     Loss: -1.2265805393924367\n",
      "Epoch: 92     Loss: -1.228633070406302\n",
      "Epoch: 93     Loss: -1.2306337102112608\n",
      "Epoch: 94     Loss: -1.232620790543771\n",
      "Epoch: 95     Loss: -1.2345436389906368\n",
      "Epoch: 96     Loss: -1.2364608194054139\n",
      "Epoch: 97     Loss: -1.2382916344196107\n",
      "Epoch: 98     Loss: -1.2401404420714843\n",
      "Epoch: 99     Loss: -1.2419125895123644\n",
      "Epoch: 100     Loss: -1.2436987295760287\n",
      "Epoch: 101     Loss: -1.2454267211489523\n",
      "Epoch: 102     Loss: -1.247147370203999\n",
      "Epoch: 103     Loss: -1.2488256866571292\n",
      "Epoch: 104     Loss: -1.2505291340880573\n",
      "Epoch: 105     Loss: -1.252213812269623\n",
      "Epoch: 106     Loss: -1.2539068732932959\n",
      "Epoch: 107     Loss: -1.2555732635032895\n",
      "Epoch: 108     Loss: -1.257225288901608\n",
      "Epoch: 109     Loss: -1.2588412335730763\n",
      "Epoch: 110     Loss: -1.260433672856292\n",
      "Epoch: 111     Loss: -1.2619956855764431\n",
      "Epoch: 112     Loss: -1.263546165407062\n",
      "Epoch: 113     Loss: -1.2650789925343247\n",
      "Epoch: 114     Loss: -1.2666132840430964\n",
      "Epoch: 115     Loss: -1.2681256884260843\n",
      "Epoch: 116     Loss: -1.269639501944358\n",
      "Epoch: 117     Loss: -1.271126904062621\n",
      "Epoch: 118     Loss: -1.2726124351719743\n",
      "Epoch: 119     Loss: -1.274068560939047\n",
      "Epoch: 120     Loss: -1.2755201837355294\n",
      "Epoch: 121     Loss: -1.2769382293268143\n",
      "Epoch: 122     Loss: -1.2783492035878594\n",
      "Epoch: 123     Loss: -1.2797167365519602\n",
      "Epoch: 124     Loss: -1.2810748101652267\n",
      "Epoch: 125     Loss: -1.2823714720647146\n",
      "Epoch: 126     Loss: -1.2836813494830666\n",
      "Epoch: 127     Loss: -1.2849385178655526\n",
      "Epoch: 128     Loss: -1.2862368684486698\n",
      "Epoch: 129     Loss: -1.2874962465565516\n",
      "Epoch: 130     Loss: -1.2887717831290597\n",
      "Epoch: 131     Loss: -1.2900002623736533\n",
      "Epoch: 132     Loss: -1.2912564047625077\n",
      "Epoch: 133     Loss: -1.2924860769167312\n",
      "Epoch: 134     Loss: -1.2937240027901968\n",
      "Epoch: 135     Loss: -1.2949348126864606\n",
      "Epoch: 136     Loss: -1.2961522285223925\n",
      "Epoch: 137     Loss: -1.297344445935852\n",
      "Epoch: 138     Loss: -1.2985419684340567\n",
      "Epoch: 139     Loss: -1.2997150137753717\n",
      "Epoch: 140     Loss: -1.3008926056395744\n",
      "Epoch: 141     Loss: -1.302045488778982\n",
      "Epoch: 142     Loss: -1.303202383874074\n",
      "Epoch: 143     Loss: -1.3043333706290574\n",
      "Epoch: 144     Loss: -1.305467975951149\n",
      "Epoch: 145     Loss: -1.306574174362364\n",
      "Epoch: 146     Loss: -1.3076830299466269\n",
      "Epoch: 147     Loss: -1.3087590446446473\n",
      "Epoch: 148     Loss: -1.3098363577548513\n",
      "Epoch: 149     Loss: -1.3108838472598132\n",
      "Epoch: 150     Loss: -1.3119368016123247\n",
      "Epoch: 151     Loss: -1.3129853313167776\n",
      "Epoch: 152     Loss: -1.31403793298893\n",
      "Epoch: 153     Loss: -1.3150833633205097\n",
      "Epoch: 154     Loss: -1.316126540960084\n",
      "Epoch: 155     Loss: -1.3171458861707859\n",
      "Epoch: 156     Loss: -1.318156971058155\n",
      "Epoch: 157     Loss: -1.319123654701543\n",
      "Epoch: 158     Loss: -1.3201172414666245\n",
      "Epoch: 159     Loss: -1.3210806265320154\n",
      "Epoch: 160     Loss: -1.3220697034863567\n",
      "Epoch: 161     Loss: -1.3230253870137292\n",
      "Epoch: 162     Loss: -1.3239916972940866\n",
      "Epoch: 163     Loss: -1.3249171692102755\n",
      "Epoch: 164     Loss: -1.3258598120672522\n",
      "Epoch: 165     Loss: -1.3267732362658875\n",
      "Epoch: 166     Loss: -1.327706986836854\n",
      "Epoch: 167     Loss: -1.3286230649002002\n",
      "Epoch: 168     Loss: -1.3295529831509025\n",
      "Epoch: 169     Loss: -1.3304675227125549\n",
      "Epoch: 170     Loss: -1.33138922093116\n",
      "Epoch: 171     Loss: -1.3322926349359525\n",
      "Epoch: 172     Loss: -1.3331969065164044\n",
      "Epoch: 173     Loss: -1.3340856416592783\n",
      "Epoch: 174     Loss: -1.3349791005352807\n",
      "Epoch: 175     Loss: -1.3358618480475555\n",
      "Epoch: 176     Loss: -1.3367507413115935\n",
      "Epoch: 177     Loss: -1.3376278620662811\n",
      "Epoch: 178     Loss: -1.3385066965468246\n",
      "Epoch: 179     Loss: -1.3393714250234388\n",
      "Epoch: 180     Loss: -1.3402250465641663\n",
      "Epoch: 181     Loss: -1.341056246247211\n",
      "Epoch: 182     Loss: -1.3418498147710096\n",
      "Epoch: 183     Loss: -1.3426671388400742\n",
      "Epoch: 184     Loss: -1.343480719518616\n",
      "Epoch: 185     Loss: -1.3443103397426563\n",
      "Epoch: 186     Loss: -1.3451372475980612\n",
      "Epoch: 187     Loss: -1.345957044651555\n",
      "Epoch: 188     Loss: -1.3467725235342984\n",
      "Epoch: 189     Loss: -1.3475761233248928\n",
      "Epoch: 190     Loss: -1.348377410016091\n",
      "Epoch: 191     Loss: -1.3491687350817834\n",
      "Epoch: 192     Loss: -1.3499585831248833\n",
      "Epoch: 193     Loss: -1.3507429066090175\n",
      "Epoch: 194     Loss: -1.3515255640020132\n",
      "Epoch: 195     Loss: -1.3523065082719135\n",
      "Epoch: 196     Loss: -1.3530836878761137\n",
      "Epoch: 197     Loss: -1.3538608700883457\n",
      "Epoch: 198     Loss: -1.3546307244510714\n",
      "Epoch: 199     Loss: -1.3554008812688494\n",
      "Epoch: 200     Loss: -1.3561598470750287\n",
      "Epoch: 201     Loss: -1.3569190061607528\n",
      "Epoch: 202     Loss: -1.3576649686314395\n",
      "Epoch: 203     Loss: -1.358411097463098\n",
      "Epoch: 204     Loss: -1.3591460282471564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 205     Loss: -1.3598804932473787\n",
      "Epoch: 206     Loss: -1.3606067869233682\n",
      "Epoch: 207     Loss: -1.3613311257030143\n",
      "Epoch: 208     Loss: -1.3620472203119773\n",
      "Epoch: 209     Loss: -1.3627588828102772\n",
      "Epoch: 210     Loss: -1.3634581013123488\n",
      "Epoch: 211     Loss: -1.3641511085992242\n",
      "Epoch: 212     Loss: -1.3648270906326847\n",
      "Epoch: 213     Loss: -1.3655066492197954\n",
      "Epoch: 214     Loss: -1.3661728212054938\n",
      "Epoch: 215     Loss: -1.3668562960993085\n",
      "Epoch: 216     Loss: -1.3675314864257644\n",
      "Epoch: 217     Loss: -1.3682155453022715\n",
      "Epoch: 218     Loss: -1.3688868953576887\n",
      "Epoch: 219     Loss: -1.3695543893615223\n",
      "Epoch: 220     Loss: -1.3702084174791196\n",
      "Epoch: 221     Loss: -1.3708660440931852\n",
      "Epoch: 222     Loss: -1.3715273809865056\n",
      "Epoch: 223     Loss: -1.3721930425966429\n",
      "Epoch: 224     Loss: -1.3728613553854332\n",
      "Epoch: 225     Loss: -1.3735247228438232\n",
      "Epoch: 226     Loss: -1.3741876728379359\n",
      "Epoch: 227     Loss: -1.374841839753824\n",
      "Epoch: 228     Loss: -1.3754956999967665\n",
      "Epoch: 229     Loss: -1.3761416146531869\n",
      "Epoch: 230     Loss: -1.376788061965619\n",
      "Epoch: 231     Loss: -1.3774291977975368\n",
      "Epoch: 232     Loss: -1.3780701177823773\n",
      "Epoch: 233     Loss: -1.3787067677286138\n",
      "Epoch: 234     Loss: -1.3793409749005594\n",
      "Epoch: 235     Loss: -1.3799694135764047\n",
      "Epoch: 236     Loss: -1.3805909066809794\n",
      "Epoch: 237     Loss: -1.3812034472523451\n",
      "Epoch: 238     Loss: -1.3818053975874238\n",
      "Epoch: 239     Loss: -1.382405308919416\n",
      "Epoch: 240     Loss: -1.3830027948849226\n",
      "Epoch: 241     Loss: -1.3836075022583627\n",
      "Epoch: 242     Loss: -1.3842098878976354\n",
      "Epoch: 243     Loss: -1.384817902810545\n",
      "Epoch: 244     Loss: -1.385420186764667\n",
      "Epoch: 245     Loss: -1.3860258586801997\n",
      "Epoch: 246     Loss: -1.3866249121833962\n",
      "Epoch: 247     Loss: -1.3872249465634499\n",
      "Epoch: 248     Loss: -1.3878188579997095\n",
      "Epoch: 249     Loss: -1.3884114462777137\n",
      "Epoch: 250     Loss: -1.388999327498361\n",
      "Epoch: 251     Loss: -1.3895844496722272\n",
      "Epoch: 252     Loss: -1.3901663719738127\n",
      "Epoch: 253     Loss: -1.39074398522649\n",
      "Epoch: 254     Loss: -1.3913172363771102\n",
      "Epoch: 255     Loss: -1.3918794974937176\n",
      "Epoch: 256     Loss: -1.392426957834621\n",
      "Epoch: 257     Loss: -1.392957403793684\n",
      "Epoch: 258     Loss: -1.3934587225639474\n",
      "Epoch: 259     Loss: -1.394008115917005\n",
      "Epoch: 260     Loss: -1.3945511128168309\n",
      "Epoch: 261     Loss: -1.3951114802087154\n",
      "Epoch: 262     Loss: -1.3956586163084594\n",
      "Epoch: 263     Loss: -1.396216361809275\n",
      "Epoch: 264     Loss: -1.3967590696454202\n",
      "Epoch: 265     Loss: -1.3973113862440312\n",
      "Epoch: 266     Loss: -1.3978492092267203\n",
      "Epoch: 267     Loss: -1.3983944462639157\n",
      "Epoch: 268     Loss: -1.3989252950485382\n",
      "Epoch: 269     Loss: -1.3994603974405662\n",
      "Epoch: 270     Loss: -1.399981475436728\n",
      "Epoch: 271     Loss: -1.400510266266093\n",
      "Epoch: 272     Loss: -1.4010313992909946\n",
      "Epoch: 273     Loss: -1.401564954447558\n",
      "Epoch: 274     Loss: -1.402093009861605\n",
      "Epoch: 275     Loss: -1.4026295191593117\n",
      "Epoch: 276     Loss: -1.4031591133480115\n",
      "Epoch: 277     Loss: -1.4036941373813359\n",
      "Epoch: 278     Loss: -1.4042216056589498\n",
      "Epoch: 279     Loss: -1.404753336110452\n",
      "Epoch: 280     Loss: -1.4052776793364135\n",
      "Epoch: 281     Loss: -1.4058055400177136\n",
      "Epoch: 282     Loss: -1.4063262533143215\n",
      "Epoch: 283     Loss: -1.4068494841179762\n",
      "Epoch: 284     Loss: -1.4073652520106268\n",
      "Epoch: 285     Loss: -1.4078821474585075\n",
      "Epoch: 286     Loss: -1.408390284394269\n",
      "Epoch: 287     Loss: -1.4088976184489876\n",
      "Epoch: 288     Loss: -1.4093936654947703\n",
      "Epoch: 289     Loss: -1.409887788551135\n",
      "Epoch: 290     Loss: -1.4103671184218813\n",
      "Epoch: 291     Loss: -1.4108504714302674\n",
      "Epoch: 292     Loss: -1.411315753964656\n",
      "Epoch: 293     Loss: -1.4117994658285227\n",
      "Epoch: 294     Loss: -1.4122681946978572\n",
      "Epoch: 295     Loss: -1.4127541546956335\n",
      "Epoch: 296     Loss: -1.4132264520652749\n",
      "Epoch: 297     Loss: -1.413712375600438\n",
      "Epoch: 298     Loss: -1.4141882377575854\n",
      "Epoch: 299     Loss: -1.4146758915440838\n",
      "Epoch: 300     Loss: -1.4151565530442576\n",
      "Epoch: 301     Loss: -1.4156458490075787\n",
      "Epoch: 302     Loss: -1.4161288827416438\n",
      "Epoch: 303     Loss: -1.4166174827441331\n",
      "Epoch: 304     Loss: -1.4170996133855083\n",
      "Epoch: 305     Loss: -1.417584357444763\n",
      "Epoch: 306     Loss: -1.4180620251067644\n",
      "Epoch: 307     Loss: -1.4185385109651252\n",
      "Epoch: 308     Loss: -1.4190060550309898\n",
      "Epoch: 309     Loss: -1.4194710363673997\n",
      "Epoch: 310     Loss: -1.4199300327260513\n",
      "Epoch: 311     Loss: -1.4203910564370483\n",
      "Epoch: 312     Loss: -1.4208497573707182\n",
      "Epoch: 313     Loss: -1.4212959192244528\n",
      "Epoch: 314     Loss: -1.4217524673656583\n",
      "Epoch: 315     Loss: -1.4221976789194648\n",
      "Epoch: 316     Loss: -1.4226566476538194\n",
      "Epoch: 317     Loss: -1.4231122288083444\n",
      "Epoch: 318     Loss: -1.4235717677513477\n",
      "Epoch: 319     Loss: -1.4240271333216885\n",
      "Epoch: 320     Loss: -1.424485065358468\n",
      "Epoch: 321     Loss: -1.4249378594267827\n",
      "Epoch: 322     Loss: -1.4253922557978373\n",
      "Epoch: 323     Loss: -1.4258396710764518\n",
      "Epoch: 324     Loss: -1.426287526868142\n",
      "Epoch: 325     Loss: -1.4267264964489075\n",
      "Epoch: 326     Loss: -1.4271662014644104\n",
      "Epoch: 327     Loss: -1.4275985159592885\n",
      "Epoch: 328     Loss: -1.4280353828271337\n",
      "Epoch: 329     Loss: -1.4284704950323834\n",
      "Epoch: 330     Loss: -1.4289112391001113\n",
      "Epoch: 331     Loss: -1.4293512321185766\n",
      "Epoch: 332     Loss: -1.4297943009301692\n",
      "Epoch: 333     Loss: -1.4302352371940708\n",
      "Epoch: 334     Loss: -1.4306767444541448\n",
      "Epoch: 335     Loss: -1.4311152351021583\n",
      "Epoch: 336     Loss: -1.4315519082431793\n",
      "Epoch: 337     Loss: -1.4319854465727826\n",
      "Epoch: 338     Loss: -1.4324142886646754\n",
      "Epoch: 339     Loss: -1.4328410348615328\n",
      "Epoch: 340     Loss: -1.4332601410546424\n",
      "Epoch: 341     Loss: -1.4336797066822025\n",
      "Epoch: 342     Loss: -1.4340898289309034\n",
      "Epoch: 343     Loss: -1.4345034413348734\n",
      "Epoch: 344     Loss: -1.4349062763385279\n",
      "Epoch: 345     Loss: -1.4353175725206038\n",
      "Epoch: 346     Loss: -1.4357183869566696\n",
      "Epoch: 347     Loss: -1.4361320298054563\n",
      "Epoch: 348     Loss: -1.436537616967657\n",
      "Epoch: 349     Loss: -1.436953245528461\n",
      "Epoch: 350     Loss: -1.4373617127634968\n",
      "Epoch: 351     Loss: -1.4377772044113855\n",
      "Epoch: 352     Loss: -1.4381860526923576\n",
      "Epoch: 353     Loss: -1.4386002263123356\n",
      "Epoch: 354     Loss: -1.4390084256252\n",
      "Epoch: 355     Loss: -1.439420953654622\n",
      "Epoch: 356     Loss: -1.4398282024485147\n",
      "Epoch: 357     Loss: -1.4402390376745777\n",
      "Epoch: 358     Loss: -1.4406450943019196\n",
      "Epoch: 359     Loss: -1.4410540871518274\n",
      "Epoch: 360     Loss: -1.4414585097436357\n",
      "Epoch: 361     Loss: -1.4418653230524647\n",
      "Epoch: 362     Loss: -1.442267522847786\n",
      "Epoch: 363     Loss: -1.442671726925289\n",
      "Epoch: 364     Loss: -1.4430710887485307\n",
      "Epoch: 365     Loss: -1.4434722412731016\n",
      "Epoch: 366     Loss: -1.4438680835621873\n",
      "Epoch: 367     Loss: -1.4442655700380351\n",
      "Epoch: 368     Loss: -1.444656487649406\n",
      "Epoch: 369     Loss: -1.445048449051254\n",
      "Epoch: 370     Loss: -1.4454295291453143\n",
      "Epoch: 371     Loss: -1.445809902225833\n",
      "Epoch: 372     Loss: -1.446170752961829\n",
      "Epoch: 373     Loss: -1.4465373573930131\n",
      "Epoch: 374     Loss: -1.4468927452372387\n",
      "Epoch: 375     Loss: -1.4472620158522986\n",
      "Epoch: 376     Loss: -1.447627687284331\n",
      "Epoch: 377     Loss: -1.4480004376663818\n",
      "Epoch: 378     Loss: -1.4483687810834154\n",
      "Epoch: 379     Loss: -1.4487417149966944\n",
      "Epoch: 380     Loss: -1.4491112279172553\n",
      "Epoch: 381     Loss: -1.4494846810833655\n",
      "Epoch: 382     Loss: -1.4498555556832737\n",
      "Epoch: 383     Loss: -1.450229462133158\n",
      "Epoch: 384     Loss: -1.4506004974951885\n",
      "Epoch: 385     Loss: -1.4509736525215495\n",
      "Epoch: 386     Loss: -1.4513426846136581\n",
      "Epoch: 387     Loss: -1.4517133394729356\n",
      "Epoch: 388     Loss: -1.452077944208037\n",
      "Epoch: 389     Loss: -1.4524439320019238\n",
      "Epoch: 390     Loss: -1.4528022948103092\n",
      "Epoch: 391     Loss: -1.4531614044243115\n",
      "Epoch: 392     Loss: -1.4535146942356778\n",
      "Epoch: 393     Loss: -1.453867613420427\n",
      "Epoch: 394     Loss: -1.4542187762732195\n",
      "Epoch: 395     Loss: -1.4545671244993843\n",
      "Epoch: 396     Loss: -1.45491702635219\n",
      "Epoch: 397     Loss: -1.4552628916906316\n",
      "Epoch: 398     Loss: -1.4556124812313322\n",
      "Epoch: 399     Loss: -1.4559579750622014\n",
      "Epoch: 400     Loss: -1.4563076023618575\n",
      "Epoch: 401     Loss: -1.4566532581271767\n",
      "Epoch: 402     Loss: -1.4570024222310334\n",
      "Epoch: 403     Loss: -1.4573480378824646\n",
      "Epoch: 404     Loss: -1.4576957149141148\n",
      "Epoch: 405     Loss: -1.4580400773342403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 406     Loss: -1.4583855616767738\n",
      "Epoch: 407     Loss: -1.4587282156383408\n",
      "Epoch: 408     Loss: -1.4590713076802788\n",
      "Epoch: 409     Loss: -1.4594122157491136\n",
      "Epoch: 410     Loss: -1.4597530735554822\n",
      "Epoch: 411     Loss: -1.4600923927416627\n",
      "Epoch: 412     Loss: -1.46043135339215\n",
      "Epoch: 413     Loss: -1.4607692602982028\n",
      "Epoch: 414     Loss: -1.461106629684323\n",
      "Epoch: 415     Loss: -1.4614432006154232\n",
      "Epoch: 416     Loss: -1.461779124583568\n",
      "Epoch: 417     Loss: -1.4621143101165768\n",
      "Epoch: 418     Loss: -1.4624487733234188\n",
      "Epoch: 419     Loss: -1.4627824395468099\n",
      "Epoch: 420     Loss: -1.4631153286993677\n",
      "Epoch: 421     Loss: -1.4634473077787127\n",
      "Epoch: 422     Loss: -1.463778467261339\n",
      "Epoch: 423     Loss: -1.4641085796141062\n",
      "Epoch: 424     Loss: -1.4644378209833075\n",
      "Epoch: 425     Loss: -1.4647658390931089\n",
      "Epoch: 426     Loss: -1.4650928631715288\n",
      "Epoch: 427     Loss: -1.4654183411334056\n",
      "Epoch: 428     Loss: -1.4657424644017185\n",
      "Epoch: 429     Loss: -1.4660642571195521\n",
      "Epoch: 430     Loss: -1.4663838665139888\n",
      "Epoch: 431     Loss: -1.4666996495002038\n",
      "Epoch: 432     Loss: -1.4670128865014531\n",
      "Epoch: 433     Loss: -1.4673222179159229\n",
      "Epoch: 434     Loss: -1.467631969580425\n",
      "Epoch: 435     Loss: -1.46794043907926\n",
      "Epoch: 436     Loss: -1.4682515135724497\n",
      "Epoch: 437     Loss: -1.4685613496223253\n",
      "Epoch: 438     Loss: -1.4688725675491154\n",
      "Epoch: 439     Loss: -1.469181738258777\n",
      "Epoch: 440     Loss: -1.4694902319606953\n",
      "Epoch: 441     Loss: -1.4697970051944658\n",
      "Epoch: 442     Loss: -1.4700999793826122\n",
      "Epoch: 443     Loss: -1.4704030434159945\n",
      "Epoch: 444     Loss: -1.470698719136808\n",
      "Epoch: 445     Loss: -1.4709986131812605\n",
      "Epoch: 446     Loss: -1.4712899244192676\n",
      "Epoch: 447     Loss: -1.4715896887749196\n",
      "Epoch: 448     Loss: -1.471882466341054\n",
      "Epoch: 449     Loss: -1.4721834982742663\n",
      "Epoch: 450     Loss: -1.4724789118367783\n",
      "Epoch: 451     Loss: -1.4727799155490893\n",
      "Epoch: 452     Loss: -1.4730756540717318\n",
      "Epoch: 453     Loss: -1.4733748061634122\n",
      "Epoch: 454     Loss: -1.4736687067279373\n",
      "Epoch: 455     Loss: -1.4739651645594276\n",
      "Epoch: 456     Loss: -1.4742569124022968\n",
      "Epoch: 457     Loss: -1.4745518757910063\n",
      "Epoch: 458     Loss: -1.474843305763335\n",
      "Epoch: 459     Loss: -1.4751384731332293\n",
      "Epoch: 460     Loss: -1.4754307584369115\n",
      "Epoch: 461     Loss: -1.4757262929000707\n",
      "Epoch: 462     Loss: -1.4760189291678103\n",
      "Epoch: 463     Loss: -1.4763141133353161\n",
      "Epoch: 464     Loss: -1.476606148483867\n",
      "Epoch: 465     Loss: -1.4769002456745774\n",
      "Epoch: 466     Loss: -1.477190892223115\n",
      "Epoch: 467     Loss: -1.4774833350995533\n",
      "Epoch: 468     Loss: -1.4777720292411596\n",
      "Epoch: 469     Loss: -1.4780623940582973\n",
      "Epoch: 470     Loss: -1.4783487341719002\n",
      "Epoch: 471     Loss: -1.4786366677213565\n",
      "Epoch: 472     Loss: -1.4789202810140194\n",
      "Epoch: 473     Loss: -1.4792053320858176\n",
      "Epoch: 474     Loss: -1.4794855681714827\n",
      "Epoch: 475     Loss: -1.479766910829719\n",
      "Epoch: 476     Loss: -1.4800424826320904\n",
      "Epoch: 477     Loss: -1.4803190991018516\n",
      "Epoch: 478     Loss: -1.4805889535730958\n",
      "Epoch: 479     Loss: -1.4808616824697094\n",
      "Epoch: 480     Loss: -1.4811285921086605\n",
      "Epoch: 481     Loss: -1.4814013641962853\n",
      "Epoch: 482     Loss: -1.4816707088366095\n",
      "Epoch: 483     Loss: -1.4819457085919663\n",
      "Epoch: 484     Loss: -1.4822181528742615\n",
      "Epoch: 485     Loss: -1.4824942822185692\n",
      "Epoch: 486     Loss: -1.482767710879419\n",
      "Epoch: 487     Loss: -1.4830433734198105\n",
      "Epoch: 488     Loss: -1.4833160227124815\n",
      "Epoch: 489     Loss: -1.4835900775229582\n",
      "Epoch: 490     Loss: -1.4838609534245888\n",
      "Epoch: 491     Loss: -1.4841327738540504\n",
      "Epoch: 492     Loss: -1.484401631709729\n",
      "Epoch: 493     Loss: -1.4846710867085888\n",
      "Epoch: 494     Loss: -1.4849382139046727\n",
      "Epoch: 495     Loss: -1.4852054299002122\n",
      "Epoch: 496     Loss: -1.4854711392694266\n",
      "Epoch: 497     Loss: -1.4857362595439048\n",
      "Epoch: 498     Loss: -1.4860006618572004\n",
      "Epoch: 499     Loss: -1.4862640075222524\n",
      "Epoch: 500     Loss: -1.4865272340452333\n",
      "Epoch: 501     Loss: -1.48678938486361\n",
      "Epoch: 502     Loss: -1.487051601681481\n",
      "Epoch: 503     Loss: -1.4873128885894187\n",
      "Epoch: 504     Loss: -1.487573994328753\n",
      "Epoch: 505     Loss: -1.4878341345419295\n",
      "Epoch: 506     Loss: -1.4880939060322895\n",
      "Epoch: 507     Loss: -1.4883526959124\n",
      "Epoch: 508     Loss: -1.4886113793872136\n",
      "Epoch: 509     Loss: -1.4888694582655486\n",
      "Epoch: 510     Loss: -1.4891272935624538\n",
      "Epoch: 511     Loss: -1.4893847502851365\n",
      "Epoch: 512     Loss: -1.4896415183400609\n",
      "Epoch: 513     Loss: -1.4898979046964553\n",
      "Epoch: 514     Loss: -1.4901531325331863\n",
      "Epoch: 515     Loss: -1.4904079153525154\n",
      "Epoch: 516     Loss: -1.4906610794278599\n",
      "Epoch: 517     Loss: -1.4909137693143635\n",
      "Epoch: 518     Loss: -1.4911645073510633\n",
      "Epoch: 519     Loss: -1.491414782627395\n",
      "Epoch: 520     Loss: -1.4916633068005134\n",
      "Epoch: 521     Loss: -1.491911199290676\n",
      "Epoch: 522     Loss: -1.492158154661348\n",
      "Epoch: 523     Loss: -1.4924041332026086\n",
      "Epoch: 524     Loss: -1.4926498133217179\n",
      "Epoch: 525     Loss: -1.4928945079858806\n",
      "Epoch: 526     Loss: -1.4931390363634471\n",
      "Epoch: 527     Loss: -1.493382988796478\n",
      "Epoch: 528     Loss: -1.493626582553587\n",
      "Epoch: 529     Loss: -1.4938701430440773\n",
      "Epoch: 530     Loss: -1.494112996363698\n",
      "Epoch: 531     Loss: -1.4943562083129447\n",
      "Epoch: 532     Loss: -1.4945982278668408\n",
      "Epoch: 533     Loss: -1.4948407629073641\n",
      "Epoch: 534     Loss: -1.4950813556767482\n",
      "Epoch: 535     Loss: -1.4953225407288675\n",
      "Epoch: 536     Loss: -1.4955606214061141\n",
      "Epoch: 537     Loss: -1.4957995880957888\n",
      "Epoch: 538     Loss: -1.4960340489922526\n",
      "Epoch: 539     Loss: -1.4962699631032845\n",
      "Epoch: 540     Loss: -1.4965003606034435\n",
      "Epoch: 541     Loss: -1.496733523941846\n",
      "Epoch: 542     Loss: -1.4969615201636683\n",
      "Epoch: 543     Loss: -1.497193921292673\n",
      "Epoch: 544     Loss: -1.497422106082117\n",
      "Epoch: 545     Loss: -1.497654743280825\n",
      "Epoch: 546     Loss: -1.4978837690220081\n",
      "Epoch: 547     Loss: -1.4981165837613315\n",
      "Epoch: 548     Loss: -1.4983461924525556\n",
      "Epoch: 549     Loss: -1.4985790124890475\n",
      "Epoch: 550     Loss: -1.4988088964481943\n",
      "Epoch: 551     Loss: -1.499041435650422\n",
      "Epoch: 552     Loss: -1.4992711492566824\n",
      "Epoch: 553     Loss: -1.4995029536073912\n",
      "Epoch: 554     Loss: -1.4997319242667881\n",
      "Epoch: 555     Loss: -1.4999624820564936\n",
      "Epoch: 556     Loss: -1.5001902773095028\n",
      "Epoch: 557     Loss: -1.5004194666644755\n",
      "Epoch: 558     Loss: -1.500646358407796\n",
      "Epoch: 559     Loss: -1.500874888704236\n",
      "Epoch: 560     Loss: -1.50110175703513\n",
      "Epoch: 561     Loss: -1.501330420277794\n",
      "Epoch: 562     Loss: -1.5015576199550544\n",
      "Epoch: 563     Loss: -1.5017864321891474\n",
      "Epoch: 564     Loss: -1.5020136051375044\n",
      "Epoch: 565     Loss: -1.5022421258302336\n",
      "Epoch: 566     Loss: -1.5024687389802005\n",
      "Epoch: 567     Loss: -1.5026964699555168\n",
      "Epoch: 568     Loss: -1.5029220032626875\n",
      "Epoch: 569     Loss: -1.5031484678505924\n",
      "Epoch: 570     Loss: -1.5033723944501034\n",
      "Epoch: 571     Loss: -1.503597144389813\n",
      "Epoch: 572     Loss: -1.5038189456664528\n",
      "Epoch: 573     Loss: -1.5040416244531518\n",
      "Epoch: 574     Loss: -1.5042608842581637\n",
      "Epoch: 575     Loss: -1.5044813193301236\n",
      "Epoch: 576     Loss: -1.5046978270407954\n",
      "Epoch: 577     Loss: -1.5049160083739137\n",
      "Epoch: 578     Loss: -1.505129797519813\n",
      "Epoch: 579     Loss: -1.5053457863212534\n",
      "Epoch: 580     Loss: -1.5055573084094185\n",
      "Epoch: 581     Loss: -1.5057713638892418\n",
      "Epoch: 582     Loss: -1.5059817534997129\n",
      "Epoch: 583     Loss: -1.5061944528646418\n",
      "Epoch: 584     Loss: -1.506404948934147\n",
      "Epoch: 585     Loss: -1.5066167693756372\n",
      "Epoch: 586     Loss: -1.5068273614352807\n",
      "Epoch: 587     Loss: -1.5070377519138989\n",
      "Epoch: 588     Loss: -1.5072462491839922\n",
      "Epoch: 589     Loss: -1.5074548201937559\n",
      "Epoch: 590     Loss: -1.507662224660433\n",
      "Epoch: 591     Loss: -1.5078708152419031\n",
      "Epoch: 592     Loss: -1.5080796578125333\n",
      "Epoch: 593     Loss: -1.508288352033763\n",
      "Epoch: 594     Loss: -1.5084961811664073\n",
      "Epoch: 595     Loss: -1.5087019763188796\n",
      "Epoch: 596     Loss: -1.5089070509018092\n",
      "Epoch: 597     Loss: -1.5091089978391317\n",
      "Epoch: 598     Loss: -1.509313801041809\n",
      "Epoch: 599     Loss: -1.5095171993261893\n",
      "Epoch: 600     Loss: -1.509723670239007\n",
      "Epoch: 601     Loss: -1.5099290261695562\n",
      "Epoch: 602     Loss: -1.5101364983522392\n",
      "Epoch: 603     Loss: -1.5103428044173437\n",
      "Epoch: 604     Loss: -1.5105501846584546\n",
      "Epoch: 605     Loss: -1.5107564150873345\n",
      "Epoch: 606     Loss: -1.510962965102228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 607     Loss: -1.5111685484448885\n",
      "Epoch: 608     Loss: -1.5113738031090527\n",
      "Epoch: 609     Loss: -1.5115784129084502\n",
      "Epoch: 610     Loss: -1.5117820907975408\n",
      "Epoch: 611     Loss: -1.5119855809601002\n",
      "Epoch: 612     Loss: -1.512187610100815\n",
      "Epoch: 613     Loss: -1.5123900238639347\n",
      "Epoch: 614     Loss: -1.5125906465437204\n",
      "Epoch: 615     Loss: -1.512792246073137\n",
      "Epoch: 616     Loss: -1.5129920418431453\n",
      "Epoch: 617     Loss: -1.5131932030269302\n",
      "Epoch: 618     Loss: -1.513392787139053\n",
      "Epoch: 619     Loss: -1.513593709715567\n",
      "Epoch: 620     Loss: -1.5137932585791523\n",
      "Epoch: 621     Loss: -1.5139937881583831\n",
      "Epoch: 622     Loss: -1.5141929723921461\n",
      "Epoch: 623     Loss: -1.5143926456523038\n",
      "Epoch: 624     Loss: -1.5145907624945676\n",
      "Epoch: 625     Loss: -1.5147887748026414\n",
      "Epoch: 626     Loss: -1.5149845821558607\n",
      "Epoch: 627     Loss: -1.5151796488195421\n",
      "Epoch: 628     Loss: -1.5153714546717956\n",
      "Epoch: 629     Loss: -1.5155627300374348\n",
      "Epoch: 630     Loss: -1.515750885808159\n",
      "Epoch: 631     Loss: -1.5159399310667099\n",
      "Epoch: 632     Loss: -1.5161272287119862\n",
      "Epoch: 633     Loss: -1.5163163524271888\n",
      "Epoch: 634     Loss: -1.516504311902228\n",
      "Epoch: 635     Loss: -1.5166936105916096\n",
      "Epoch: 636     Loss: -1.5168815522921646\n",
      "Epoch: 637     Loss: -1.5170698511344476\n",
      "Epoch: 638     Loss: -1.5172564699719895\n",
      "Epoch: 639     Loss: -1.5174430903316307\n",
      "Epoch: 640     Loss: -1.517628095964099\n",
      "Epoch: 641     Loss: -1.5178139145648863\n",
      "Epoch: 642     Loss: -1.5179985792143134\n",
      "Epoch: 643     Loss: -1.5181849689921452\n",
      "Epoch: 644     Loss: -1.5183704453867812\n",
      "Epoch: 645     Loss: -1.5185577027931592\n",
      "Epoch: 646     Loss: -1.5187439441118396\n",
      "Epoch: 647     Loss: -1.5189316307605598\n",
      "Epoch: 648     Loss: -1.5191180699527356\n",
      "Epoch: 649     Loss: -1.5193056644317973\n",
      "Epoch: 650     Loss: -1.519491752498113\n",
      "Epoch: 651     Loss: -1.5196788690948768\n",
      "Epoch: 652     Loss: -1.51986421847618\n",
      "Epoch: 653     Loss: -1.520050635228307\n",
      "Epoch: 654     Loss: -1.520235029550375\n",
      "Epoch: 655     Loss: -1.5204206489984766\n",
      "Epoch: 656     Loss: -1.5206040131934533\n",
      "Epoch: 657     Loss: -1.5207888038307664\n",
      "Epoch: 658     Loss: -1.5209711617435597\n",
      "Epoch: 659     Loss: -1.5211551038860234\n",
      "Epoch: 660     Loss: -1.5213365270208477\n",
      "Epoch: 661     Loss: -1.5215195732224167\n",
      "Epoch: 662     Loss: -1.5217001359830895\n",
      "Epoch: 663     Loss: -1.5218822018814502\n",
      "Epoch: 664     Loss: -1.5220619873733001\n",
      "Epoch: 665     Loss: -1.5222429772832904\n",
      "Epoch: 666     Loss: -1.522422112745384\n",
      "Epoch: 667     Loss: -1.5226019799553878\n",
      "Epoch: 668     Loss: -1.522780635560433\n",
      "Epoch: 669     Loss: -1.5229595600960157\n",
      "Epoch: 670     Loss: -1.5231380197473725\n",
      "Epoch: 671     Loss: -1.5233165049121224\n",
      "Epoch: 672     Loss: -1.5234950893421064\n",
      "Epoch: 673     Loss: -1.5236736016340704\n",
      "Epoch: 674     Loss: -1.5238523746222432\n",
      "Epoch: 675     Loss: -1.5240309505193468\n",
      "Epoch: 676     Loss: -1.5242096364209754\n",
      "Epoch: 677     Loss: -1.524387924099985\n",
      "Epoch: 678     Loss: -1.524566046951929\n",
      "Epoch: 679     Loss: -1.5247435242381482\n",
      "Epoch: 680     Loss: -1.5249206600393332\n",
      "Epoch: 681     Loss: -1.5250970194968814\n",
      "Epoch: 682     Loss: -1.525273114365231\n",
      "Epoch: 683     Loss: -1.525448632626715\n",
      "Epoch: 684     Loss: -1.5256238225193235\n",
      "Epoch: 685     Loss: -1.5257987675411375\n",
      "Epoch: 686     Loss: -1.5259731415761473\n",
      "Epoch: 687     Loss: -1.5261475608827098\n",
      "Epoch: 688     Loss: -1.5263212796025543\n",
      "Epoch: 689     Loss: -1.5264952421825637\n",
      "Epoch: 690     Loss: -1.5266685191399578\n",
      "Epoch: 691     Loss: -1.526842100359103\n",
      "Epoch: 692     Loss: -1.527015081787708\n",
      "Epoch: 693     Loss: -1.5271883318487487\n",
      "Epoch: 694     Loss: -1.5273610810332452\n",
      "Epoch: 695     Loss: -1.527534038772696\n",
      "Epoch: 696     Loss: -1.5277065770521305\n",
      "Epoch: 697     Loss: -1.5278792521141178\n",
      "Epoch: 698     Loss: -1.5280515355714677\n",
      "Epoch: 699     Loss: -1.5282238590808386\n",
      "Epoch: 700     Loss: -1.5283957414750935\n",
      "Epoch: 701     Loss: -1.5285675598574466\n",
      "Epoch: 702     Loss: -1.5287388027996465\n",
      "Epoch: 703     Loss: -1.5289098795281042\n",
      "Epoch: 704     Loss: -1.5290801045518885\n",
      "Epoch: 705     Loss: -1.5292499947627292\n",
      "Epoch: 706     Loss: -1.5294183636405625\n",
      "Epoch: 707     Loss: -1.5295859236089593\n",
      "Epoch: 708     Loss: -1.5297500611654438\n",
      "Epoch: 709     Loss: -1.5299126096341145\n",
      "Epoch: 710     Loss: -1.530068113437798\n",
      "Epoch: 711     Loss: -1.5302245863252475\n",
      "Epoch: 712     Loss: -1.5303753432832494\n",
      "Epoch: 713     Loss: -1.530532362139609\n",
      "Epoch: 714     Loss: -1.530688108589702\n",
      "Epoch: 715     Loss: -1.5308490649083066\n",
      "Epoch: 716     Loss: -1.5310093370468614\n",
      "Epoch: 717     Loss: -1.5311719782261919\n",
      "Epoch: 718     Loss: -1.5313337786576287\n",
      "Epoch: 719     Loss: -1.5314966831809282\n",
      "Epoch: 720     Loss: -1.5316584834582405\n",
      "Epoch: 721     Loss: -1.5318205606447148\n",
      "Epoch: 722     Loss: -1.5319814314210447\n",
      "Epoch: 723     Loss: -1.5321423581872207\n",
      "Epoch: 724     Loss: -1.5323022930276085\n",
      "Epoch: 725     Loss: -1.5324626364395986\n",
      "Epoch: 726     Loss: -1.5326217142345964\n",
      "Epoch: 727     Loss: -1.5327815287025748\n",
      "Epoch: 728     Loss: -1.5329389252119183\n",
      "Epoch: 729     Loss: -1.533098435768785\n",
      "Epoch: 730     Loss: -1.5332560247582272\n",
      "Epoch: 731     Loss: -1.5334156972703095\n",
      "Epoch: 732     Loss: -1.5335741500705309\n",
      "Epoch: 733     Loss: -1.5337341637008728\n",
      "Epoch: 734     Loss: -1.5338933046300742\n",
      "Epoch: 735     Loss: -1.5340535623146092\n",
      "Epoch: 736     Loss: -1.534213049653655\n",
      "Epoch: 737     Loss: -1.5343732682771398\n",
      "Epoch: 738     Loss: -1.5345326645606914\n",
      "Epoch: 739     Loss: -1.5346924964121027\n",
      "Epoch: 740     Loss: -1.5348513765837142\n",
      "Epoch: 741     Loss: -1.5350104747830422\n",
      "Epoch: 742     Loss: -1.5351684620940573\n",
      "Epoch: 743     Loss: -1.5353265114739476\n",
      "Epoch: 744     Loss: -1.535483317997341\n",
      "Epoch: 745     Loss: -1.5356400903166343\n",
      "Epoch: 746     Loss: -1.5357956251043774\n",
      "Epoch: 747     Loss: -1.5359511234959844\n",
      "Epoch: 748     Loss: -1.5361056486688565\n",
      "Epoch: 749     Loss: -1.5362602497039934\n",
      "Epoch: 750     Loss: -1.5364143133014592\n",
      "Epoch: 751     Loss: -1.536568557428034\n",
      "Epoch: 752     Loss: -1.5367225681429775\n",
      "Epoch: 753     Loss: -1.5368767152084335\n",
      "Epoch: 754     Loss: -1.5370307079707617\n",
      "Epoch: 755     Loss: -1.5371847230514797\n",
      "Epoch: 756     Loss: -1.537338543088264\n",
      "Epoch: 757     Loss: -1.537492356602719\n",
      "Epoch: 758     Loss: -1.537645843687553\n",
      "Epoch: 759     Loss: -1.5377993872582347\n",
      "Epoch: 760     Loss: -1.537952445036668\n",
      "Epoch: 761     Loss: -1.5381056384602054\n",
      "Epoch: 762     Loss: -1.538258243799445\n",
      "Epoch: 763     Loss: -1.5384110303135765\n",
      "Epoch: 764     Loss: -1.5385631996232556\n",
      "Epoch: 765     Loss: -1.538715550263422\n",
      "Epoch: 766     Loss: -1.538867305065253\n",
      "Epoch: 767     Loss: -1.5390191987321742\n",
      "Epoch: 768     Loss: -1.5391705211512188\n",
      "Epoch: 769     Loss: -1.5393218735099663\n",
      "Epoch: 770     Loss: -1.5394726005751689\n",
      "Epoch: 771     Loss: -1.5396230865696279\n",
      "Epoch: 772     Loss: -1.5397726540180172\n",
      "Epoch: 773     Loss: -1.5399213156946436\n",
      "Epoch: 774     Loss: -1.540068308548264\n",
      "Epoch: 775     Loss: -1.5402134568961805\n",
      "Epoch: 776     Loss: -1.5403563762251273\n",
      "Epoch: 777     Loss: -1.5404986878899318\n",
      "Epoch: 778     Loss: -1.5406395619586353\n",
      "Epoch: 779     Loss: -1.5407826260116544\n",
      "Epoch: 780     Loss: -1.54092446183829\n",
      "Epoch: 781     Loss: -1.5410687226279591\n",
      "Epoch: 782     Loss: -1.541211544444022\n",
      "Epoch: 783     Loss: -1.5413562904351894\n",
      "Epoch: 784     Loss: -1.5414995283575084\n",
      "Epoch: 785     Loss: -1.5416443796478785\n",
      "Epoch: 786     Loss: -1.5417877948309946\n",
      "Epoch: 787     Loss: -1.5419326685168622\n",
      "Epoch: 788     Loss: -1.5420762666231993\n",
      "Epoch: 789     Loss: -1.5422212002103926\n",
      "Epoch: 790     Loss: -1.5423650199746446\n",
      "Epoch: 791     Loss: -1.5425100089882269\n",
      "Epoch: 792     Loss: -1.5426539751783557\n",
      "Epoch: 793     Loss: -1.5427988801942738\n",
      "Epoch: 794     Loss: -1.5429427555399433\n",
      "Epoch: 795     Loss: -1.5430872809470424\n",
      "Epoch: 796     Loss: -1.5432306897300798\n",
      "Epoch: 797     Loss: -1.5433744299994803\n",
      "Epoch: 798     Loss: -1.5435169804482651\n",
      "Epoch: 799     Loss: -1.5436596548935715\n",
      "Epoch: 800     Loss: -1.543801306340095\n",
      "Epoch: 801     Loss: -1.5439432362702028\n",
      "Epoch: 802     Loss: -1.544084632502951\n",
      "Epoch: 803     Loss: -1.5442266802358813\n",
      "Epoch: 804     Loss: -1.5443685489018242\n",
      "Epoch: 805     Loss: -1.5445111800805738\n",
      "Epoch: 806     Loss: -1.5446535273611428\n",
      "Epoch: 807     Loss: -1.54479648702677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 808     Loss: -1.5449387087729975\n",
      "Epoch: 809     Loss: -1.5450813269735968\n",
      "Epoch: 810     Loss: -1.5452223509977174\n",
      "Epoch: 811     Loss: -1.5453634768115292\n",
      "Epoch: 812     Loss: -1.5455010603377464\n",
      "Epoch: 813     Loss: -1.5456401246950686\n",
      "Epoch: 814     Loss: -1.5457754206289\n",
      "Epoch: 815     Loss: -1.5459141682079407\n",
      "Epoch: 816     Loss: -1.5460512877341637\n",
      "Epoch: 817     Loss: -1.546190383245595\n",
      "Epoch: 818     Loss: -1.5463282064160535\n",
      "Epoch: 819     Loss: -1.5464672971685944\n",
      "Epoch: 820     Loss: -1.5466055178511648\n",
      "Epoch: 821     Loss: -1.5467441746114505\n",
      "Epoch: 822     Loss: -1.5468822016689963\n",
      "Epoch: 823     Loss: -1.5470202146652274\n",
      "Epoch: 824     Loss: -1.5471578564478514\n"
     ]
    }
   ],
   "source": [
    "X1 = torch.from_numpy(train_a1).double()\n",
    "X2 = torch.from_numpy(train_b1).double()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "    # 输出的维度\n",
    "    outdim_size = 2\n",
    "\n",
    "    # 两个view的输入\n",
    "    input_shape1 = 11\n",
    "    input_shape2 = 12\n",
    "\n",
    "    # 网络架构设置\n",
    "    layer_sizes1 = [25, 50, 25, outdim_size]\n",
    "    layer_sizes2 = [25, 50, 25, outdim_size]\n",
    "\n",
    "    # 超参数设置\n",
    "    learning_rate = 1e-3\n",
    "    epoch_num = 5000\n",
    "    reg_par = 1e-5\n",
    "    use_all_singular_values = False\n",
    "\n",
    "    # 搭建网络\n",
    "    model = DeepCCA(layer_sizes1, layer_sizes2, input_shape1,\n",
    "                    input_shape2, outdim_size, use_all_singular_values, device=device).double()\n",
    "    solver = Solver(model, outdim_size, epoch_num, learning_rate, reg_par, device=device)\n",
    "    \n",
    "    # 训练\n",
    "    train1, train2 = X1, X2\n",
    "    solver.fit(train1, train2)\n",
    "\n",
    "    # 测试\n",
    "    loss, outputs = solver.test(train1, train2)\n",
    "    \n",
    "    print(\"\\n**********单独在原始数据集上训练LR和SVM分类器的精度和AUC*************\")\n",
    "    print(\"View 1(LR) ACC : \", LR_2(X1, y)[0] * 100, \"%       AUC:\", LR_2(X1, y)[1])\n",
    "    print(\"View 2(LR) ACC : \", LR_2(X2, y)[0] * 100, \"%       AUC:\", LR_2(X2, y)[1])\n",
    "    print(\"View 1(SVM) ACC : \", svm_2(X1, y)[0] * 100, \"%       AUC:\", svm_2(X1, y)[1])\n",
    "    print(\"View 2(SVM) ACC : \", svm_2(X2, y)[0] * 100, \"%       AUC:\", svm_2(X2, y)[1], \"\\n\")\n",
    "    \n",
    "    print(\"**********在抽取出的共同空间上训练LR和SVM分类器的精度和AUC*************\")\n",
    "    print(\"View 1(LR) ACC : \", LR_2(outputs[0], y)[0] * 100, \"%       AUC:\", LR_2(outputs[0], y)[1])\n",
    "    print(\"View 2(LR) ACC : \", LR_2(outputs[1], y)[0] * 100, \"%       AUC:\", LR_2(outputs[1], y)[1])\n",
    "    print(\"View 1(SVM) ACC : \", svm_2(outputs[0], y)[0] * 100, \"%       AUC:\", svm_2(outputs[0], y)[1])\n",
    "    print(\"View 2(SVM) ACC : \", svm_2(outputs[1], y)[0] * 100, \"%       AUC:\", svm_2(outputs[1], y)[1])\n",
    "    \n",
    "    #可视化映射到隐空间中的状态，尾数1代表View 1\n",
    "    visualization_LR(outputs[0], y, 'View 1')\n",
    "    visualization_LR(outputs[1], y, 'View 2')\n",
    "    visualization_SVM(outputs[0], y, 'View 1')\n",
    "    visualization_SVM(outputs[1], y, 'View 2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Give Me Some Credit\n",
    "df = pd.read_csv(\"cs-training.csv\")\n",
    "df = df.drop(\"Unnamed: 0\", axis=1) # drop id column\n",
    "df = df.loc[df[\"DebtRatio\"] <= df[\"DebtRatio\"].quantile(0.975)]\n",
    "df = df.loc[(df[\"RevolvingUtilizationOfUnsecuredLines\"] >= 0) & (df[\"RevolvingUtilizationOfUnsecuredLines\"] < 13)]\n",
    "df = df.loc[df[\"NumberOfTimes90DaysLate\"] <= 17]\n",
    "dependents_mode = df[\"NumberOfDependents\"].mode()[0]\n",
    "df[\"NumberOfDependents\"] = df[\"NumberOfDependents\"].fillna(dependents_mode)\n",
    "income_median = df[\"MonthlyIncome\"].median()\n",
    "df[\"MonthlyIncome\"] = df[\"MonthlyIncome\"].fillna(income_median)\n",
    "X = df.drop(\"SeriousDlqin2yrs\", axis=1)\n",
    "Y = df[\"SeriousDlqin2yrs\"]\n",
    "train_a1 = np.array(X.iloc[:, 0:5])\n",
    "train_b1 = np.array(X.iloc[:, 5:10])\n",
    "\n",
    "y = numpy.array(Y)\n",
    "train_a1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = torch.from_numpy(train_a1).double()\n",
    "X2 = torch.from_numpy(train_b1).double()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "    # 输出的维度\n",
    "    outdim_size = 2\n",
    "\n",
    "    # 两个view的输入\n",
    "    input_shape1 = 5\n",
    "    input_shape2 = 5\n",
    "\n",
    "    # 网络架构设置\n",
    "    layer_sizes1 = [20, 40, 20, outdim_size]\n",
    "    layer_sizes2 = [20, 40, 20, outdim_size]\n",
    "\n",
    "    # 超参数设置\n",
    "    learning_rate = 1e-3\n",
    "    epoch_num = 1500\n",
    "    reg_par = 1e-5\n",
    "    use_all_singular_values = False\n",
    "\n",
    "    # 搭建网络\n",
    "    model = DeepCCA(layer_sizes1, layer_sizes2, input_shape1,\n",
    "                    input_shape2, outdim_size, use_all_singular_values, device=device).double()\n",
    "    solver = Solver(model, outdim_size, epoch_num, learning_rate, reg_par, device=device)\n",
    "    \n",
    "    # 训练\n",
    "    train1, train2 = X1, X2\n",
    "    solver.fit(train1, train2)\n",
    "\n",
    "    # 测试\n",
    "    loss, outputs = solver.test(train1, train2)\n",
    "    \n",
    "    print(\"**********单独在原始数据集上训练LR和SVM分类器的精度和AUC*************\") \n",
    "    print(\"View 1(LR) ACC : \", LR_2(X1, y)[0] * 100, \"%       AUC:\", LR_2(X1, y)[1])\n",
    "    print(\"View 2(LR) ACC : \", LR_2(X2, y)[0] * 100, \"%       AUC:\", LR_2(X2, y)[1])\n",
    "    print(\"View 1(SVM) ACC : \", svm_2(X1, y)[0] * 100, \"%       AUC:\", svm_2(X1, y)[1])\n",
    "    print(\"View 2(SVM) ACC : \", svm_2(X2, y)[0] * 100, \"%       AUC:\", svm_2(X2, y)[1])\n",
    "    \n",
    "    print(\"**********在抽取出的共同空间上训练LR和SVM分类器的精度和AUC*************\")\n",
    "    print(\"View 1(LR) ACC : \", LR_2(outputs[0], y)[0] * 100, \"%       AUC:\", LR_2(outputs[0], y)[1])\n",
    "    print(\"View 2(LR) ACC : \", LR_2(outputs[1], y)[0] * 100, \"%       AUC:\", LR_2(outputs[1], y)[1])\n",
    "    print(\"View 1(SVM) ACC : \", svm_2(outputs[0], y)[0] * 100, \"%       AUC:\", svm_2(outputs[0], y)[1])\n",
    "    print(\"View 2(SVM) ACC : \", svm_2(outputs[1], y)[0] * 100, \"%       AUC:\", svm_2(outputs[1], y)[1])\n",
    "    \n",
    "    #可视化映射到隐空间中的状态，尾数1代表View 1\n",
    "    visualization_LR(outputs[0], y, 'View 1')\n",
    "    visualization_LR(outputs[1], y, 'View 2')\n",
    "    visualization_SVM(outputs[0], y, 'View 1')\n",
    "    visualization_SVM(outputs[1], y, 'View 2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "  \n",
    "def load_mnist_train():\n",
    "  labels_path = \"train-labels.idx1-ubyte\"\n",
    "   \n",
    "  images_path = \"train-images.idx3-ubyte\"\n",
    "   \n",
    "  with open(labels_path, 'rb') as lbpath:\n",
    "    magic, n = struct.unpack('>II',lbpath.read(8))\n",
    "    labels = np.fromfile(lbpath,dtype=np.uint8) \n",
    "  \n",
    "  with open(images_path, 'rb') as imgpath:\n",
    "    magic, num, rows, cols = struct.unpack('>IIII',imgpath.read(16))\n",
    "    images = np.fromfile(imgpath,dtype=np.uint8).reshape(len(labels), 784)\n",
    "  return images, labels\n",
    "\n",
    "def load_mnist_test():\n",
    "  labels_path = \"t10k-labels.idx1-ubyte\"\n",
    "   \n",
    "  images_path = \"t10k-images.idx3-ubyte\"\n",
    "   \n",
    "  with open(labels_path, 'rb') as lbpath:\n",
    "    magic, n = struct.unpack('>II',lbpath.read(8))\n",
    "    labels = np.fromfile(lbpath,dtype=np.uint8) \n",
    "  \n",
    "  with open(images_path, 'rb') as imgpath:\n",
    "    magic, num, rows, cols = struct.unpack('>IIII',imgpath.read(16))\n",
    "    images = np.fromfile(imgpath,dtype=np.uint8).reshape(len(labels), 784)\n",
    "  return images, labels\n",
    "\n",
    "train_temp = load_mnist_train()[0]\n",
    "y = load_mnist_train()[1] % 2\n",
    "\n",
    "train_a1 = np.array(train_temp[:, 0:392])\n",
    "train_b1 = np.array(train_temp[:, 392:784])\n",
    "\n",
    "train_a1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = torch.from_numpy(train_a1).double()\n",
    "X2 = torch.from_numpy(train_b1).double()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "    # 输出的维度\n",
    "    outdim_size = 2\n",
    "\n",
    "    # 两个view的输入\n",
    "    input_shape1 = 392\n",
    "    input_shape2 = 392\n",
    "\n",
    "    # 网络架构设置\n",
    "    layer_sizes1 = [512, 1024, 512, outdim_size]\n",
    "    layer_sizes2 = [512, 1024, 512, outdim_size]\n",
    "\n",
    "    # 超参数设置\n",
    "    learning_rate = 1e-3\n",
    "    epoch_num = 2000\n",
    "    reg_par = 1e-5\n",
    "    use_all_singular_values = False\n",
    "\n",
    "    # 搭建网络\n",
    "    model = DeepCCA(layer_sizes1, layer_sizes2, input_shape1,\n",
    "                    input_shape2, outdim_size, use_all_singular_values, device=device).double()\n",
    "    solver = Solver(model, outdim_size, epoch_num, learning_rate, reg_par, device=device)\n",
    "    \n",
    "    # 训练\n",
    "    train1, train2 = X1, X2\n",
    "    solver.fit(train1, train2)\n",
    "\n",
    "    # 测试\n",
    "    loss, outputs = solver.test(train1, train2)\n",
    "  \n",
    "    print(\"**********单独在原始数据集上训练LR和SVM分类器的精度和AUC*************\")   \n",
    "    print(\"View 1(LR) ACC : \", LR_2(X1, y)[0] * 100, \"%       AUC:\", LR_2(X1, y)[1])\n",
    "    print(\"View 2(LR) ACC : \", LR_2(X2, y)[0] * 100, \"%       AUC:\", LR_2(X2, y)[1])\n",
    "    print(\"View 1(SVM) ACC : \", svm_2(X1, y)[0] * 100, \"%       AUC:\", svm_2(X1, y)[1])\n",
    "    print(\"View 2(SVM) ACC : \", svm_2(X2, y)[0] * 100, \"%       AUC:\", svm_2(X2, y)[1])\n",
    "    \n",
    "    print(\"**********在抽取出的共同空间上训练LR和SVM分类器的精度和AUC*************\") \n",
    "    print(\"View 1(LR) ACC : \", LR_2(outputs[0], y)[0] * 100, \"%       AUC:\", LR_2(outputs[0], y)[1])\n",
    "    print(\"View 2(LR) ACC : \", LR_2(outputs[1], y)[0] * 100, \"%       AUC:\", LR_2(outputs[1], y)[1])\n",
    "    print(\"View 1(SVM) ACC : \", svm_2(outputs[0], y)[0] * 100, \"%       AUC:\", svm_2(outputs[0], y)[1])\n",
    "    print(\"View 2(SVM) ACC : \", svm_2(outputs[1], y)[0] * 100, \"%       AUC:\", svm_2(outputs[1], y)[1])\n",
    "    \n",
    "    #可视化映射到隐空间中的状态，尾数1代表View 1\n",
    "    visualization_LR(outputs[0], y, 'View 1')\n",
    "    visualization_LR(outputs[1], y, 'View 2')\n",
    "    visualization_SVM(outputs[0], y, 'View 1')\n",
    "    visualization_SVM(outputs[1], y, 'View 2')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Pytorch]",
   "language": "python",
   "name": "conda-env-Pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
